{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Forecasting Service Metrics\n",
    "\n",
    "Authors: Tatiana Barrios, Anisha Anandkrishnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from pandas import concat\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Data preparation: Use one of the methods described in Project 1 (Advanced), Task 1 to pre-process the trace. Remove possible outliers. Reduce the dimensionality of the feature space to k = 16 using tree-based feature selection. Then, split the processed trace into training and test samples (x(t),y(t)) by assigning the samples with t < T to the training set and t ≥T to the test set. T is chosen so that the training set contains 70% of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task II - Using Recurrent Neural Networks (RNNs) for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_all_..usr</th>\n",
       "      <th>0_all_..sys</th>\n",
       "      <th>0_all_..iowait</th>\n",
       "      <th>0_all_..soft</th>\n",
       "      <th>0_all_..idle</th>\n",
       "      <th>0_cpu0_.usr</th>\n",
       "      <th>0_cpu0_.sys</th>\n",
       "      <th>0_cpu0_.iowait</th>\n",
       "      <th>0_cpu0_.soft</th>\n",
       "      <th>0_cpu0_.idle</th>\n",
       "      <th>...</th>\n",
       "      <th>36_RxBytes.1</th>\n",
       "      <th>36_TxBytes.1</th>\n",
       "      <th>40_RxPacktes.1</th>\n",
       "      <th>40_TxPacktes.1</th>\n",
       "      <th>40_RxBytes.1</th>\n",
       "      <th>40_TxBytes.1</th>\n",
       "      <th>41_RxPacktes.1</th>\n",
       "      <th>41_TxPacktes.1</th>\n",
       "      <th>41_RxBytes.1</th>\n",
       "      <th>41_TxBytes.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069116</td>\n",
       "      <td>1.088334</td>\n",
       "      <td>0.766004</td>\n",
       "      <td>0.573967</td>\n",
       "      <td>-0.579449</td>\n",
       "      <td>1.364018</td>\n",
       "      <td>0.977205</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>-0.355042</td>\n",
       "      <td>-2.078731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.583733</td>\n",
       "      <td>1.335871</td>\n",
       "      <td>1.090350</td>\n",
       "      <td>1.069987</td>\n",
       "      <td>1.211176</td>\n",
       "      <td>0.975349</td>\n",
       "      <td>1.053685</td>\n",
       "      <td>1.064968</td>\n",
       "      <td>0.971475</td>\n",
       "      <td>1.180097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247507</td>\n",
       "      <td>2.503497</td>\n",
       "      <td>0.377145</td>\n",
       "      <td>0.573967</td>\n",
       "      <td>-0.865816</td>\n",
       "      <td>1.364018</td>\n",
       "      <td>4.193380</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>-0.355042</td>\n",
       "      <td>-2.078731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.551250</td>\n",
       "      <td>1.485179</td>\n",
       "      <td>1.190029</td>\n",
       "      <td>1.263907</td>\n",
       "      <td>1.110672</td>\n",
       "      <td>1.287438</td>\n",
       "      <td>1.269613</td>\n",
       "      <td>1.224345</td>\n",
       "      <td>1.294599</td>\n",
       "      <td>1.157325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158311</td>\n",
       "      <td>1.421314</td>\n",
       "      <td>0.571574</td>\n",
       "      <td>-0.290273</td>\n",
       "      <td>-0.579449</td>\n",
       "      <td>1.384053</td>\n",
       "      <td>0.993448</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>-0.355042</td>\n",
       "      <td>-1.518028</td>\n",
       "      <td>...</td>\n",
       "      <td>1.636638</td>\n",
       "      <td>1.320954</td>\n",
       "      <td>1.119925</td>\n",
       "      <td>1.012137</td>\n",
       "      <td>1.234329</td>\n",
       "      <td>0.859493</td>\n",
       "      <td>1.037388</td>\n",
       "      <td>1.111521</td>\n",
       "      <td>0.901761</td>\n",
       "      <td>1.236388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.425898</td>\n",
       "      <td>1.421314</td>\n",
       "      <td>0.766004</td>\n",
       "      <td>3.382748</td>\n",
       "      <td>-1.135338</td>\n",
       "      <td>1.404089</td>\n",
       "      <td>-0.630882</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>2.626215</td>\n",
       "      <td>-0.945519</td>\n",
       "      <td>...</td>\n",
       "      <td>1.503362</td>\n",
       "      <td>1.510045</td>\n",
       "      <td>1.144023</td>\n",
       "      <td>1.126207</td>\n",
       "      <td>1.215636</td>\n",
       "      <td>1.070883</td>\n",
       "      <td>1.113167</td>\n",
       "      <td>1.141096</td>\n",
       "      <td>1.054886</td>\n",
       "      <td>1.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158311</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>5.432315</td>\n",
       "      <td>1.654267</td>\n",
       "      <td>-2.129200</td>\n",
       "      <td>2.355777</td>\n",
       "      <td>2.585292</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>-0.355042</td>\n",
       "      <td>-2.078731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.556992</td>\n",
       "      <td>1.341298</td>\n",
       "      <td>1.134713</td>\n",
       "      <td>1.095245</td>\n",
       "      <td>1.194114</td>\n",
       "      <td>1.050206</td>\n",
       "      <td>1.113574</td>\n",
       "      <td>1.146025</td>\n",
       "      <td>1.094834</td>\n",
       "      <td>1.186764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_all_..usr  0_all_..sys  0_all_..iowait  0_all_..soft  0_all_..idle  \\\n",
       "0     0.069116     1.088334        0.766004      0.573967     -0.579449   \n",
       "1     0.247507     2.503497        0.377145      0.573967     -0.865816   \n",
       "2     0.158311     1.421314        0.571574     -0.290273     -0.579449   \n",
       "3     0.425898     1.421314        0.766004      3.382748     -1.135338   \n",
       "4     0.158311     0.006151        5.432315      1.654267     -2.129200   \n",
       "\n",
       "   0_cpu0_.usr  0_cpu0_.sys  0_cpu0_.iowait  0_cpu0_.soft  0_cpu0_.idle  ...  \\\n",
       "0     1.364018     0.977205        -0.00831     -0.355042     -2.078731  ...   \n",
       "1     1.364018     4.193380        -0.00831     -0.355042     -2.078731  ...   \n",
       "2     1.384053     0.993448        -0.00831     -0.355042     -1.518028  ...   \n",
       "3     1.404089    -0.630882        -0.00831      2.626215     -0.945519  ...   \n",
       "4     2.355777     2.585292        -0.00831     -0.355042     -2.078731  ...   \n",
       "\n",
       "   36_RxBytes.1  36_TxBytes.1  40_RxPacktes.1  40_TxPacktes.1  40_RxBytes.1  \\\n",
       "0      1.583733      1.335871        1.090350        1.069987      1.211176   \n",
       "1      1.551250      1.485179        1.190029        1.263907      1.110672   \n",
       "2      1.636638      1.320954        1.119925        1.012137      1.234329   \n",
       "3      1.503362      1.510045        1.144023        1.126207      1.215636   \n",
       "4      1.556992      1.341298        1.134713        1.095245      1.194114   \n",
       "\n",
       "   40_TxBytes.1  41_RxPacktes.1  41_TxPacktes.1  41_RxBytes.1  41_TxBytes.1  \n",
       "0      0.975349        1.053685        1.064968      0.971475      1.180097  \n",
       "1      1.287438        1.269613        1.224345      1.294599      1.157325  \n",
       "2      0.859493        1.037388        1.111521      0.901761      1.236388  \n",
       "3      1.070883        1.113167        1.141096      1.054886      1.212100  \n",
       "4      1.050206        1.113574        1.146025      1.094834      1.186764  \n",
       "\n",
       "[5 rows x 1751 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('X.csv')\n",
    "Y = pd.read_csv('Y.csv')\n",
    "X.index = pd.to_datetime(X['TimeStamp'])\n",
    "Y.index = pd.to_datetime(Y['TimeStamp'])\n",
    "X_dropped = X.drop(labels=[\"Unnamed: 0\", \"TimeStamp\"], axis=1, inplace=False)\n",
    "Y_dropped = Y.drop(labels=[\"Unnamed: 0\", \"TimeStamp\"], axis=1, inplace=False)\n",
    "X_preprocessed = pd.DataFrame()\n",
    "X_tmp = preprocessing.StandardScaler().fit_transform(X_dropped)\n",
    "for i, n in enumerate(X_dropped):\n",
    "        X_preprocessed[n] = X_tmp[:, i]\n",
    "        \n",
    "X_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14481, 1751)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped samples:  136\n",
      "Stored 'X_clean' (DataFrame)\n",
      "Stored 'Y_clean' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "#converting Y_dropped to make it of the same form as X_preprocessed\n",
    "Y_new = pd.DataFrame()\n",
    "Y_tmp=Y_dropped.to_numpy()\n",
    "\n",
    "for i, n in enumerate(Y_dropped):\n",
    "        Y_new[n] = Y_tmp[:, i]  \n",
    "# outlier rejection   \n",
    "remove = []\n",
    "for i in X_preprocessed:\n",
    "    for j in range(len(X_preprocessed[i])):\n",
    "        if j not in remove and abs(X_preprocessed[i][j]) > 80:\n",
    "            remove.append(j)\n",
    "X_clean = X_preprocessed.drop(labels=remove, axis=0, inplace=False)\n",
    "Y_clean = Y_new.drop(labels=remove, axis=0, inplace=False)\n",
    "\n",
    "print(\"Number of dropped samples: \", (len(remove)))\n",
    "%store X_clean\n",
    "%store Y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14345, 1751)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X_clean.reset_index()\n",
    "Y_clean = Y_clean.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X_clean.drop(X_clean.columns[0], axis=1)\n",
    "Y_clean = Y_clean.drop(Y_clean.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_all_..usr</th>\n",
       "      <th>0_all_..sys</th>\n",
       "      <th>0_all_..iowait</th>\n",
       "      <th>0_all_..soft</th>\n",
       "      <th>0_all_..idle</th>\n",
       "      <th>0_cpu0_.usr</th>\n",
       "      <th>0_cpu0_.sys</th>\n",
       "      <th>0_cpu0_.iowait</th>\n",
       "      <th>0_cpu0_.soft</th>\n",
       "      <th>0_cpu0_.idle</th>\n",
       "      <th>...</th>\n",
       "      <th>36_RxBytes.1</th>\n",
       "      <th>36_TxBytes.1</th>\n",
       "      <th>40_RxPacktes.1</th>\n",
       "      <th>40_TxPacktes.1</th>\n",
       "      <th>40_RxBytes.1</th>\n",
       "      <th>40_TxBytes.1</th>\n",
       "      <th>41_RxPacktes.1</th>\n",
       "      <th>41_TxPacktes.1</th>\n",
       "      <th>41_RxBytes.1</th>\n",
       "      <th>41_TxBytes.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069116</td>\n",
       "      <td>1.088334</td>\n",
       "      <td>0.766004</td>\n",
       "      <td>0.573967</td>\n",
       "      <td>-0.579449</td>\n",
       "      <td>1.364018</td>\n",
       "      <td>0.977205</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>-0.355042</td>\n",
       "      <td>-2.078731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.583733</td>\n",
       "      <td>1.335871</td>\n",
       "      <td>1.090350</td>\n",
       "      <td>1.069987</td>\n",
       "      <td>1.211176</td>\n",
       "      <td>0.975349</td>\n",
       "      <td>1.053685</td>\n",
       "      <td>1.064968</td>\n",
       "      <td>0.971475</td>\n",
       "      <td>1.180097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247507</td>\n",
       "      <td>2.503497</td>\n",
       "      <td>0.377145</td>\n",
       "      <td>0.573967</td>\n",
       "      <td>-0.865816</td>\n",
       "      <td>1.364018</td>\n",
       "      <td>4.193380</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>-0.355042</td>\n",
       "      <td>-2.078731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.551250</td>\n",
       "      <td>1.485179</td>\n",
       "      <td>1.190029</td>\n",
       "      <td>1.263907</td>\n",
       "      <td>1.110672</td>\n",
       "      <td>1.287438</td>\n",
       "      <td>1.269613</td>\n",
       "      <td>1.224345</td>\n",
       "      <td>1.294599</td>\n",
       "      <td>1.157325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158311</td>\n",
       "      <td>1.421314</td>\n",
       "      <td>0.571574</td>\n",
       "      <td>-0.290273</td>\n",
       "      <td>-0.579449</td>\n",
       "      <td>1.384053</td>\n",
       "      <td>0.993448</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>-0.355042</td>\n",
       "      <td>-1.518028</td>\n",
       "      <td>...</td>\n",
       "      <td>1.636638</td>\n",
       "      <td>1.320954</td>\n",
       "      <td>1.119925</td>\n",
       "      <td>1.012137</td>\n",
       "      <td>1.234329</td>\n",
       "      <td>0.859493</td>\n",
       "      <td>1.037388</td>\n",
       "      <td>1.111521</td>\n",
       "      <td>0.901761</td>\n",
       "      <td>1.236388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.425898</td>\n",
       "      <td>1.421314</td>\n",
       "      <td>0.766004</td>\n",
       "      <td>3.382748</td>\n",
       "      <td>-1.135338</td>\n",
       "      <td>1.404089</td>\n",
       "      <td>-0.630882</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>2.626215</td>\n",
       "      <td>-0.945519</td>\n",
       "      <td>...</td>\n",
       "      <td>1.503362</td>\n",
       "      <td>1.510045</td>\n",
       "      <td>1.144023</td>\n",
       "      <td>1.126207</td>\n",
       "      <td>1.215636</td>\n",
       "      <td>1.070883</td>\n",
       "      <td>1.113167</td>\n",
       "      <td>1.141096</td>\n",
       "      <td>1.054886</td>\n",
       "      <td>1.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158311</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>5.432315</td>\n",
       "      <td>1.654267</td>\n",
       "      <td>-2.129200</td>\n",
       "      <td>2.355777</td>\n",
       "      <td>2.585292</td>\n",
       "      <td>-0.00831</td>\n",
       "      <td>-0.355042</td>\n",
       "      <td>-2.078731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.556992</td>\n",
       "      <td>1.341298</td>\n",
       "      <td>1.134713</td>\n",
       "      <td>1.095245</td>\n",
       "      <td>1.194114</td>\n",
       "      <td>1.050206</td>\n",
       "      <td>1.113574</td>\n",
       "      <td>1.146025</td>\n",
       "      <td>1.094834</td>\n",
       "      <td>1.186764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_all_..usr  0_all_..sys  0_all_..iowait  0_all_..soft  0_all_..idle  \\\n",
       "0     0.069116     1.088334        0.766004      0.573967     -0.579449   \n",
       "1     0.247507     2.503497        0.377145      0.573967     -0.865816   \n",
       "2     0.158311     1.421314        0.571574     -0.290273     -0.579449   \n",
       "3     0.425898     1.421314        0.766004      3.382748     -1.135338   \n",
       "4     0.158311     0.006151        5.432315      1.654267     -2.129200   \n",
       "\n",
       "   0_cpu0_.usr  0_cpu0_.sys  0_cpu0_.iowait  0_cpu0_.soft  0_cpu0_.idle  ...  \\\n",
       "0     1.364018     0.977205        -0.00831     -0.355042     -2.078731  ...   \n",
       "1     1.364018     4.193380        -0.00831     -0.355042     -2.078731  ...   \n",
       "2     1.384053     0.993448        -0.00831     -0.355042     -1.518028  ...   \n",
       "3     1.404089    -0.630882        -0.00831      2.626215     -0.945519  ...   \n",
       "4     2.355777     2.585292        -0.00831     -0.355042     -2.078731  ...   \n",
       "\n",
       "   36_RxBytes.1  36_TxBytes.1  40_RxPacktes.1  40_TxPacktes.1  40_RxBytes.1  \\\n",
       "0      1.583733      1.335871        1.090350        1.069987      1.211176   \n",
       "1      1.551250      1.485179        1.190029        1.263907      1.110672   \n",
       "2      1.636638      1.320954        1.119925        1.012137      1.234329   \n",
       "3      1.503362      1.510045        1.144023        1.126207      1.215636   \n",
       "4      1.556992      1.341298        1.134713        1.095245      1.194114   \n",
       "\n",
       "   40_TxBytes.1  41_RxPacktes.1  41_TxPacktes.1  41_RxBytes.1  41_TxBytes.1  \n",
       "0      0.975349        1.053685        1.064968      0.971475      1.180097  \n",
       "1      1.287438        1.269613        1.224345      1.294599      1.157325  \n",
       "2      0.859493        1.037388        1.111521      0.901761      1.236388  \n",
       "3      1.070883        1.113167        1.141096      1.054886      1.212100  \n",
       "4      1.050206        1.113574        1.146025      1.094834      1.186764  \n",
       "\n",
       "[5 rows x 1751 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReadsAvg</th>\n",
       "      <th>WritesAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.1331</td>\n",
       "      <td>118.7723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.8588</td>\n",
       "      <td>118.4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.8251</td>\n",
       "      <td>116.8042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.8154</td>\n",
       "      <td>128.3462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.4993</td>\n",
       "      <td>118.2260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReadsAvg  WritesAvg\n",
       "0   59.1331   118.7723\n",
       "1   59.8588   118.4950\n",
       "2   57.8251   116.8042\n",
       "3   63.8154   128.3462\n",
       "4   57.4993   118.2260"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReadsAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.1331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.8588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.4993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReadsAvg\n",
       "0   59.1331\n",
       "1   59.8588\n",
       "2   57.8251\n",
       "3   63.8154\n",
       "4   57.4993"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r X_clean\n",
    "%store -r Y_clean\n",
    "\n",
    "#Reduce the dimensionality of the feature space \n",
    "tree = ExtraTreesRegressor(n_estimators=100, n_jobs=20)\n",
    "tree = tree.fit(X_clean, Y_clean)\n",
    "model = SelectFromModel(tree,prefit=True,max_features=16,threshold=-np.inf)\n",
    "X_fs = model.transform(X_clean)\n",
    "top_features = []\n",
    "get_feat = model.get_support()\n",
    "for i, n in enumerate(X_clean):\n",
    "    if get_feat[i]:\n",
    "        top_features.append(n)\n",
    "feature_name = []\n",
    "for i in range(16):\n",
    "    feature_name.append('feature'+str(i+1)+\" : \"+top_features[i])\n",
    "X_latest = pd.DataFrame(data = X_fs,columns= feature_name)\n",
    "Y_latest = pd.DataFrame(data = Y_clean,columns= Y_dropped.columns)\n",
    "Y_latest = Y_latest.drop(labels=[\"WritesAvg\"], axis=1, inplace=False)\n",
    "X_latest.head()\n",
    "Y_latest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1 : 1_i127_intr.s</th>\n",
       "      <th>feature2 : 5_campg.s</th>\n",
       "      <th>feature3 : 4_TxPacktes</th>\n",
       "      <th>feature4 : 15_TxBytes</th>\n",
       "      <th>feature5 : 17_TxPacktes</th>\n",
       "      <th>feature6 : 17_RxBytes</th>\n",
       "      <th>feature7 : 30_RxBytes</th>\n",
       "      <th>feature8 : 41_TxPacktes</th>\n",
       "      <th>feature9 : 41_TxBytes</th>\n",
       "      <th>feature10 : 4_RxPacktes.1</th>\n",
       "      <th>feature11 : 4_TxPacktes.1</th>\n",
       "      <th>feature12 : 4_TxBytes.1</th>\n",
       "      <th>feature13 : 17_RxPacktes.1</th>\n",
       "      <th>feature14 : 17_TxPacktes.1</th>\n",
       "      <th>feature15 : 17_RxBytes.1</th>\n",
       "      <th>feature16 : 40_RxPacktes.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.119895</td>\n",
       "      <td>0.019228</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>1.184277</td>\n",
       "      <td>1.034312</td>\n",
       "      <td>1.187491</td>\n",
       "      <td>1.122090</td>\n",
       "      <td>1.064968</td>\n",
       "      <td>1.180097</td>\n",
       "      <td>1.039869</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>1.214220</td>\n",
       "      <td>1.035805</td>\n",
       "      <td>1.034312</td>\n",
       "      <td>1.187491</td>\n",
       "      <td>1.090350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.855128</td>\n",
       "      <td>0.051963</td>\n",
       "      <td>1.238908</td>\n",
       "      <td>1.219757</td>\n",
       "      <td>1.238812</td>\n",
       "      <td>1.215445</td>\n",
       "      <td>1.194057</td>\n",
       "      <td>1.224345</td>\n",
       "      <td>1.157325</td>\n",
       "      <td>1.299455</td>\n",
       "      <td>1.238908</td>\n",
       "      <td>1.194544</td>\n",
       "      <td>1.299794</td>\n",
       "      <td>1.238812</td>\n",
       "      <td>1.215445</td>\n",
       "      <td>1.190029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.879198</td>\n",
       "      <td>0.043744</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>1.105230</td>\n",
       "      <td>1.077493</td>\n",
       "      <td>1.071862</td>\n",
       "      <td>1.230830</td>\n",
       "      <td>1.111521</td>\n",
       "      <td>1.236388</td>\n",
       "      <td>1.025629</td>\n",
       "      <td>1.115817</td>\n",
       "      <td>1.240098</td>\n",
       "      <td>0.974463</td>\n",
       "      <td>1.077493</td>\n",
       "      <td>1.071862</td>\n",
       "      <td>1.119925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566292</td>\n",
       "      <td>0.022571</td>\n",
       "      <td>1.127852</td>\n",
       "      <td>1.172840</td>\n",
       "      <td>1.135340</td>\n",
       "      <td>1.178959</td>\n",
       "      <td>1.193328</td>\n",
       "      <td>1.141096</td>\n",
       "      <td>1.212100</td>\n",
       "      <td>1.138740</td>\n",
       "      <td>1.127852</td>\n",
       "      <td>1.187528</td>\n",
       "      <td>1.117959</td>\n",
       "      <td>1.135340</td>\n",
       "      <td>1.178959</td>\n",
       "      <td>1.144023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.939372</td>\n",
       "      <td>0.048202</td>\n",
       "      <td>0.980143</td>\n",
       "      <td>1.167679</td>\n",
       "      <td>1.125563</td>\n",
       "      <td>1.129069</td>\n",
       "      <td>1.225559</td>\n",
       "      <td>1.146025</td>\n",
       "      <td>1.186764</td>\n",
       "      <td>1.112293</td>\n",
       "      <td>0.980143</td>\n",
       "      <td>1.005623</td>\n",
       "      <td>1.111387</td>\n",
       "      <td>1.125563</td>\n",
       "      <td>1.129069</td>\n",
       "      <td>1.134713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1 : 1_i127_intr.s  feature2 : 5_campg.s  feature3 : 4_TxPacktes  \\\n",
       "0                  1.119895              0.019228                1.088463   \n",
       "1                  0.855128              0.051963                1.238908   \n",
       "2                  0.879198              0.043744                1.115817   \n",
       "3                  0.566292              0.022571                1.127852   \n",
       "4                  0.939372              0.048202                0.980143   \n",
       "\n",
       "   feature4 : 15_TxBytes  feature5 : 17_TxPacktes  feature6 : 17_RxBytes  \\\n",
       "0               1.184277                 1.034312               1.187491   \n",
       "1               1.219757                 1.238812               1.215445   \n",
       "2               1.105230                 1.077493               1.071862   \n",
       "3               1.172840                 1.135340               1.178959   \n",
       "4               1.167679                 1.125563               1.129069   \n",
       "\n",
       "   feature7 : 30_RxBytes  feature8 : 41_TxPacktes  feature9 : 41_TxBytes  \\\n",
       "0               1.122090                 1.064968               1.180097   \n",
       "1               1.194057                 1.224345               1.157325   \n",
       "2               1.230830                 1.111521               1.236388   \n",
       "3               1.193328                 1.141096               1.212100   \n",
       "4               1.225559                 1.146025               1.186764   \n",
       "\n",
       "   feature10 : 4_RxPacktes.1  feature11 : 4_TxPacktes.1  \\\n",
       "0                   1.039869                   1.088463   \n",
       "1                   1.299455                   1.238908   \n",
       "2                   1.025629                   1.115817   \n",
       "3                   1.138740                   1.127852   \n",
       "4                   1.112293                   0.980143   \n",
       "\n",
       "   feature12 : 4_TxBytes.1  feature13 : 17_RxPacktes.1  \\\n",
       "0                 1.214220                    1.035805   \n",
       "1                 1.194544                    1.299794   \n",
       "2                 1.240098                    0.974463   \n",
       "3                 1.187528                    1.117959   \n",
       "4                 1.005623                    1.111387   \n",
       "\n",
       "   feature14 : 17_TxPacktes.1  feature15 : 17_RxBytes.1  \\\n",
       "0                    1.034312                  1.187491   \n",
       "1                    1.238812                  1.215445   \n",
       "2                    1.077493                  1.071862   \n",
       "3                    1.135340                  1.178959   \n",
       "4                    1.125563                  1.129069   \n",
       "\n",
       "   feature16 : 40_RxPacktes.1  \n",
       "0                    1.090350  \n",
       "1                    1.190029  \n",
       "2                    1.119925  \n",
       "3                    1.144023  \n",
       "4                    1.134713  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_latest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14345, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_latest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReadsAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14476</th>\n",
       "      <td>55.6183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14477</th>\n",
       "      <td>52.6730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14478</th>\n",
       "      <td>52.1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14479</th>\n",
       "      <td>52.1671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14480</th>\n",
       "      <td>52.6722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ReadsAvg\n",
       "14476   55.6183\n",
       "14477   52.6730\n",
       "14478   52.1335\n",
       "14479   52.1671\n",
       "14480   52.6722"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_latest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_latest = Y_latest.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_latest = Y_latest.drop(Y_latest.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReadsAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>55.6183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14341</th>\n",
       "      <td>52.6730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>52.1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14343</th>\n",
       "      <td>52.1671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14344</th>\n",
       "      <td>52.6722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ReadsAvg\n",
       "14340   55.6183\n",
       "14341   52.6730\n",
       "14342   52.1335\n",
       "14343   52.1671\n",
       "14344   52.6722"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_latest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_latest.to_excel(\"Xlatest.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_latest.to_excel(\"Ylatest.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10041, 16) (70% of the samples in training set and 16 features)\n"
     ]
    }
   ],
   "source": [
    "#splitting the processed trace into training and test samples and time index sorting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_latest, Y_latest, test_size=0.3, shuffle = False)\n",
    "print(X_train.shape,\"(70% of the samples in training set and 16 features)\")\n",
    "X_train = X_train.sort_index(axis = 0)\n",
    "X_test = X_test.sort_index(axis = 0)\n",
    "Y_train = Y_train.sort_index(axis = 0)\n",
    "Y_test = Y_test.sort_index(axis = 0)\n",
    "\n",
    "\n",
    "## T is the index 9285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1 : 1_i127_intr.s</th>\n",
       "      <th>feature2 : 5_campg.s</th>\n",
       "      <th>feature3 : 4_RxPacktes</th>\n",
       "      <th>feature4 : 4_TxBytes</th>\n",
       "      <th>feature5 : 15_RxPacktes</th>\n",
       "      <th>feature6 : 15_TxBytes</th>\n",
       "      <th>feature7 : 29_TxBytes</th>\n",
       "      <th>feature8 : 30_TxPacktes</th>\n",
       "      <th>feature9 : 30_RxBytes</th>\n",
       "      <th>feature10 : 4_RxPacktes.1</th>\n",
       "      <th>feature11 : 4_TxPacktes.1</th>\n",
       "      <th>feature12 : 4_TxBytes.1</th>\n",
       "      <th>feature13 : 15_RxPacktes.1</th>\n",
       "      <th>feature14 : 40_RxBytes.1</th>\n",
       "      <th>feature15 : 41_RxPacktes.1</th>\n",
       "      <th>feature16 : 41_TxBytes.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10036</th>\n",
       "      <td>1.083791</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>0.890140</td>\n",
       "      <td>0.921023</td>\n",
       "      <td>0.860309</td>\n",
       "      <td>0.847371</td>\n",
       "      <td>0.930262</td>\n",
       "      <td>0.834460</td>\n",
       "      <td>0.914904</td>\n",
       "      <td>0.890140</td>\n",
       "      <td>0.862522</td>\n",
       "      <td>0.921023</td>\n",
       "      <td>0.860309</td>\n",
       "      <td>0.921636</td>\n",
       "      <td>0.888683</td>\n",
       "      <td>0.941195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037</th>\n",
       "      <td>0.999547</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.870610</td>\n",
       "      <td>0.905672</td>\n",
       "      <td>0.887601</td>\n",
       "      <td>0.845140</td>\n",
       "      <td>0.898441</td>\n",
       "      <td>0.844646</td>\n",
       "      <td>0.895319</td>\n",
       "      <td>0.870610</td>\n",
       "      <td>0.846657</td>\n",
       "      <td>0.905672</td>\n",
       "      <td>0.887601</td>\n",
       "      <td>0.901021</td>\n",
       "      <td>0.813719</td>\n",
       "      <td>0.907049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10038</th>\n",
       "      <td>0.975477</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.833584</td>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.874158</td>\n",
       "      <td>0.873696</td>\n",
       "      <td>0.900591</td>\n",
       "      <td>0.858092</td>\n",
       "      <td>0.895825</td>\n",
       "      <td>0.833584</td>\n",
       "      <td>0.861975</td>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.874158</td>\n",
       "      <td>0.922267</td>\n",
       "      <td>0.860164</td>\n",
       "      <td>0.922680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>1.107860</td>\n",
       "      <td>0.042908</td>\n",
       "      <td>0.879968</td>\n",
       "      <td>0.925998</td>\n",
       "      <td>0.786581</td>\n",
       "      <td>0.913781</td>\n",
       "      <td>0.919159</td>\n",
       "      <td>0.843831</td>\n",
       "      <td>0.916544</td>\n",
       "      <td>0.879968</td>\n",
       "      <td>0.880576</td>\n",
       "      <td>0.925998</td>\n",
       "      <td>0.786581</td>\n",
       "      <td>0.924969</td>\n",
       "      <td>0.832460</td>\n",
       "      <td>0.935334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10040</th>\n",
       "      <td>1.023616</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.860438</td>\n",
       "      <td>0.884023</td>\n",
       "      <td>0.971512</td>\n",
       "      <td>0.911640</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>0.911468</td>\n",
       "      <td>0.899255</td>\n",
       "      <td>0.860438</td>\n",
       "      <td>0.870728</td>\n",
       "      <td>0.884023</td>\n",
       "      <td>0.971512</td>\n",
       "      <td>0.878415</td>\n",
       "      <td>0.867905</td>\n",
       "      <td>0.892267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature1 : 1_i127_intr.s  feature2 : 5_campg.s  feature3 : 4_RxPacktes  \\\n",
       "10036                  1.083791              0.006552                0.890140   \n",
       "10037                  0.999547              0.024800                0.870610   \n",
       "10038                  0.975477              0.008223                0.833584   \n",
       "10039                  1.107860              0.042908                0.879968   \n",
       "10040                  1.023616              0.006970                0.860438   \n",
       "\n",
       "       feature4 : 4_TxBytes  feature5 : 15_RxPacktes  feature6 : 15_TxBytes  \\\n",
       "10036              0.921023                 0.860309               0.847371   \n",
       "10037              0.905672                 0.887601               0.845140   \n",
       "10038              0.919101                 0.874158               0.873696   \n",
       "10039              0.925998                 0.786581               0.913781   \n",
       "10040              0.884023                 0.971512               0.911640   \n",
       "\n",
       "       feature7 : 29_TxBytes  feature8 : 30_TxPacktes  feature9 : 30_RxBytes  \\\n",
       "10036               0.930262                 0.834460               0.914904   \n",
       "10037               0.898441                 0.844646               0.895319   \n",
       "10038               0.900591                 0.858092               0.895825   \n",
       "10039               0.919159                 0.843831               0.916544   \n",
       "10040               0.914619                 0.911468               0.899255   \n",
       "\n",
       "       feature10 : 4_RxPacktes.1  feature11 : 4_TxPacktes.1  \\\n",
       "10036                   0.890140                   0.862522   \n",
       "10037                   0.870610                   0.846657   \n",
       "10038                   0.833584                   0.861975   \n",
       "10039                   0.879968                   0.880576   \n",
       "10040                   0.860438                   0.870728   \n",
       "\n",
       "       feature12 : 4_TxBytes.1  feature13 : 15_RxPacktes.1  \\\n",
       "10036                 0.921023                    0.860309   \n",
       "10037                 0.905672                    0.887601   \n",
       "10038                 0.919101                    0.874158   \n",
       "10039                 0.925998                    0.786581   \n",
       "10040                 0.884023                    0.971512   \n",
       "\n",
       "       feature14 : 40_RxBytes.1  feature15 : 41_RxPacktes.1  \\\n",
       "10036                  0.921636                    0.888683   \n",
       "10037                  0.901021                    0.813719   \n",
       "10038                  0.922267                    0.860164   \n",
       "10039                  0.924969                    0.832460   \n",
       "10040                  0.878415                    0.867905   \n",
       "\n",
       "       feature16 : 41_TxBytes.1  \n",
       "10036                  0.941195  \n",
       "10037                  0.907049  \n",
       "10038                  0.922680  \n",
       "10039                  0.935334  \n",
       "10040                  0.892267  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1 : 1_i127_intr.s</th>\n",
       "      <th>feature2 : 5_campg.s</th>\n",
       "      <th>feature3 : 4_RxPacktes</th>\n",
       "      <th>feature4 : 4_TxBytes</th>\n",
       "      <th>feature5 : 15_RxPacktes</th>\n",
       "      <th>feature6 : 15_TxBytes</th>\n",
       "      <th>feature7 : 29_TxBytes</th>\n",
       "      <th>feature8 : 30_TxPacktes</th>\n",
       "      <th>feature9 : 30_RxBytes</th>\n",
       "      <th>feature10 : 4_RxPacktes.1</th>\n",
       "      <th>feature11 : 4_TxPacktes.1</th>\n",
       "      <th>feature12 : 4_TxBytes.1</th>\n",
       "      <th>feature13 : 15_RxPacktes.1</th>\n",
       "      <th>feature14 : 40_RxBytes.1</th>\n",
       "      <th>feature15 : 41_RxPacktes.1</th>\n",
       "      <th>feature16 : 41_TxBytes.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10041</th>\n",
       "      <td>1.119895</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.860438</td>\n",
       "      <td>0.926773</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>0.933630</td>\n",
       "      <td>0.932650</td>\n",
       "      <td>0.842609</td>\n",
       "      <td>0.915612</td>\n",
       "      <td>0.860438</td>\n",
       "      <td>0.841733</td>\n",
       "      <td>0.926773</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>0.915406</td>\n",
       "      <td>0.792127</td>\n",
       "      <td>0.933608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>1.180069</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.862879</td>\n",
       "      <td>0.907818</td>\n",
       "      <td>0.868456</td>\n",
       "      <td>0.920929</td>\n",
       "      <td>0.912441</td>\n",
       "      <td>0.789640</td>\n",
       "      <td>0.910127</td>\n",
       "      <td>0.862879</td>\n",
       "      <td>0.872369</td>\n",
       "      <td>0.907818</td>\n",
       "      <td>0.868456</td>\n",
       "      <td>0.903517</td>\n",
       "      <td>0.852831</td>\n",
       "      <td>0.910287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10043</th>\n",
       "      <td>1.119895</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>0.856776</td>\n",
       "      <td>0.882061</td>\n",
       "      <td>0.912855</td>\n",
       "      <td>0.883211</td>\n",
       "      <td>0.868774</td>\n",
       "      <td>0.912691</td>\n",
       "      <td>0.864257</td>\n",
       "      <td>0.856776</td>\n",
       "      <td>0.919418</td>\n",
       "      <td>0.882061</td>\n",
       "      <td>0.912855</td>\n",
       "      <td>0.881764</td>\n",
       "      <td>0.933091</td>\n",
       "      <td>0.888634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10044</th>\n",
       "      <td>0.975477</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.833177</td>\n",
       "      <td>0.947562</td>\n",
       "      <td>0.811021</td>\n",
       "      <td>0.950526</td>\n",
       "      <td>0.957691</td>\n",
       "      <td>0.847498</td>\n",
       "      <td>0.958589</td>\n",
       "      <td>0.833177</td>\n",
       "      <td>0.894252</td>\n",
       "      <td>0.947562</td>\n",
       "      <td>0.811021</td>\n",
       "      <td>0.941499</td>\n",
       "      <td>0.874831</td>\n",
       "      <td>0.949711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10045</th>\n",
       "      <td>0.951407</td>\n",
       "      <td>0.043326</td>\n",
       "      <td>0.877120</td>\n",
       "      <td>0.919461</td>\n",
       "      <td>0.870492</td>\n",
       "      <td>0.898870</td>\n",
       "      <td>0.891108</td>\n",
       "      <td>0.835275</td>\n",
       "      <td>0.882917</td>\n",
       "      <td>0.877120</td>\n",
       "      <td>0.851581</td>\n",
       "      <td>0.919461</td>\n",
       "      <td>0.870492</td>\n",
       "      <td>0.906844</td>\n",
       "      <td>0.842646</td>\n",
       "      <td>0.922233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature1 : 1_i127_intr.s  feature2 : 5_campg.s  feature3 : 4_RxPacktes  \\\n",
       "10041                  1.119895              0.007527                0.860438   \n",
       "10042                  1.180069              0.006830                0.862879   \n",
       "10043                  1.119895              0.008502                0.856776   \n",
       "10044                  0.975477              0.007248                0.833177   \n",
       "10045                  0.951407              0.043326                0.877120   \n",
       "\n",
       "       feature4 : 4_TxBytes  feature5 : 15_RxPacktes  feature6 : 15_TxBytes  \\\n",
       "10041              0.926773                 0.818353               0.933630   \n",
       "10042              0.907818                 0.868456               0.920929   \n",
       "10043              0.882061                 0.912855               0.883211   \n",
       "10044              0.947562                 0.811021               0.950526   \n",
       "10045              0.919461                 0.870492               0.898870   \n",
       "\n",
       "       feature7 : 29_TxBytes  feature8 : 30_TxPacktes  feature9 : 30_RxBytes  \\\n",
       "10041               0.932650                 0.842609               0.915612   \n",
       "10042               0.912441                 0.789640               0.910127   \n",
       "10043               0.868774                 0.912691               0.864257   \n",
       "10044               0.957691                 0.847498               0.958589   \n",
       "10045               0.891108                 0.835275               0.882917   \n",
       "\n",
       "       feature10 : 4_RxPacktes.1  feature11 : 4_TxPacktes.1  \\\n",
       "10041                   0.860438                   0.841733   \n",
       "10042                   0.862879                   0.872369   \n",
       "10043                   0.856776                   0.919418   \n",
       "10044                   0.833177                   0.894252   \n",
       "10045                   0.877120                   0.851581   \n",
       "\n",
       "       feature12 : 4_TxBytes.1  feature13 : 15_RxPacktes.1  \\\n",
       "10041                 0.926773                    0.818353   \n",
       "10042                 0.907818                    0.868456   \n",
       "10043                 0.882061                    0.912855   \n",
       "10044                 0.947562                    0.811021   \n",
       "10045                 0.919461                    0.870492   \n",
       "\n",
       "       feature14 : 40_RxBytes.1  feature15 : 41_RxPacktes.1  \\\n",
       "10041                  0.915406                    0.792127   \n",
       "10042                  0.903517                    0.852831   \n",
       "10043                  0.881764                    0.933091   \n",
       "10044                  0.941499                    0.874831   \n",
       "10045                  0.906844                    0.842646   \n",
       "\n",
       "       feature16 : 41_TxBytes.1  \n",
       "10041                  0.933608  \n",
       "10042                  0.910287  \n",
       "10043                  0.888634  \n",
       "10044                  0.949711  \n",
       "10045                  0.922233  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReadsAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10041</th>\n",
       "      <td>59.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>59.7941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10043</th>\n",
       "      <td>59.6689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10044</th>\n",
       "      <td>58.4393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10045</th>\n",
       "      <td>57.2402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ReadsAvg\n",
       "10041   59.4228\n",
       "10042   59.7941\n",
       "10043   59.6689\n",
       "10044   58.4393\n",
       "10045   57.2402"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The goal of this task is to find a non-linear, LSTM model to forecast the target variable at specific\n",
    "   points in time. Similar to step 3 of Task I, we define a model on the sequence of inputs x with lag size\n",
    "   l which predicts the sequence of outputs with time horizon h. Similar to step 4, 5 and 6 of Task I we\n",
    "   create the training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Similar to step 7 of Task I, for values of l = 0,...,10 and h = 0,...,10 train LSTM models. Evaluate\n",
    "   the models by computing the error (NMAE) on the test set. Display the results in a table with rows\n",
    "   representing the time horizon h = 0,...,10 and columns representing the lag l = 0,...,10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The size of the output for your neural network will be the same as the time steps in your LSTM which is equal to lag but the output should be the same as the horizon (and lag and horizon are independent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMAE function\n",
    "def nmae_get(y, y_hat):\n",
    "    y_av = np.mean(y)\n",
    "    y_sum = np.sum(np.abs(y - y_hat))\n",
    "    return y_sum/(len(y)*y_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMAE for h=0:::10\n",
    "def nmaes_array(df_test, df_pre, h):\n",
    "    nmaes = []\n",
    "    for i in range(0, h+1):\n",
    "        y_predict_i = df_pre[:, i]\n",
    "        y_test_o = df_test.iloc[:, i].to_numpy()\n",
    "        nmaes.append(nmae_get(y_test_o, y_predict_i))\n",
    "        \n",
    "    return nmaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rnn_reshape(samples, time_step, features):\n",
    "    X = samples.to_numpy()\n",
    "    X = X.reshape(X.shape[0], time_step, features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input,LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def LSTM_model(input_X, input_Y, l, h, n_features):\n",
    "    X = Rnn_reshape(input_X, l, n_features)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu',dropout=0.3,return_sequences=True, input_shape=(l, n_features)))\n",
    "    model.add(LSTM(50, activation='relu',dropout=0.2))\n",
    "    model.add(Dense(h))\n",
    "    opt = Adam(lr=0.01)\n",
    "    model.compile(optimizer=opt, loss='mae',metrics=['accuracy'])\n",
    "    model.fit(X, input_Y, epochs=50, verbose=1, batch_size=32,validation_split=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning batch size l=1\n",
    "b_s = [32, 64, 128]\n",
    "def LSTM_tune_bs(input_X, input_Y,test_X,test_Y, l, h, n_features):\n",
    "    for i in range(len(b_s)):\n",
    "        X = Rnn_reshape(input_X, 1, n_features)\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(80, activation='relu',dropout=0.3,return_sequences=True, input_shape=(l, n_features)))\n",
    "        model.add(LSTM(80, activation='relu',dropout=0.2))\n",
    "        model.add(Dense(h))\n",
    "        opt = Adam(lr=0.01)\n",
    "        model.compile(optimizer=opt, loss='mae',metrics=['accuracy'])\n",
    "        model.fit(X, input_Y, epochs=10, verbose=1, batch_size=b_s[i],validation_split=0.2)\n",
    "        if b_s[i]==32:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for batch size=\",b_s[i],\"is:\",nmaes_t)\n",
    "        if b_s[i]==64:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for batch size=\",b_s[i],\"is:\",nmaes_t)\n",
    "        if b_s[i]==128:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for batch size=\",b_s[i],\"is:\",nmaes_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning epochs l=1\n",
    "epochs = [10, 50, 100, 200, 500]\n",
    "def LSTM_tune_epochs(input_X, input_Y,test_X,test_Y, l, h, n_features):\n",
    "    for i in range(len(epochs)):\n",
    "        X = Rnn_reshape(input_X, 1, n_features)\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(80, activation='relu',dropout=0.3,return_sequences=True, input_shape=(l, n_features)))\n",
    "        model.add(LSTM(80, activation='relu',dropout=0.2))\n",
    "        model.add(Dense(h))\n",
    "        opt = Adam(lr=0.01)\n",
    "        model.compile(optimizer=opt, loss='mae',metrics=['accuracy'])\n",
    "        model.fit(X, input_Y, epochs=epochs[i], verbose=1, batch_size=32,validation_split=0.2)\n",
    "        if epochs[i]==10:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for epochs=\",epochs[i],\"is:\",nmaes_t)\n",
    "        if epochs[i]==50:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for epochs=\",epochs[i],\"is:\",nmaes_t)\n",
    "        if epochs[i]==100:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for epochs=\",epochs[i],\"is:\",nmaes_t)\n",
    "        if epochs[i]==200:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for epochs=\",epochs[i],\"is:\",nmaes_t)\n",
    "        if epochs[i]==500:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for epochs=\",epochs[i],\"is:\",nmaes_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "#tuning nodes l=1\n",
    "units = [10, 50, 80, 128]\n",
    "def LSTM_tune_nodes(input_X, input_Y,test_X,test_Y, l, h, n_features):\n",
    "    for i in range(len(units)):\n",
    "        X = Rnn_reshape(input_X, 1, n_features)\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units[i], activation='relu',dropout=0.3,return_sequences=True, input_shape=(l, n_features)))\n",
    "        model.add(LSTM(units[i], activation='relu',dropout=0.2))\n",
    "        model.add(Dense(h))\n",
    "        opt = Adam(lr=0.01)\n",
    "        model.compile(optimizer=opt, loss='mae',metrics=['accuracy'])\n",
    "        model.fit(X, input_Y, epochs= 50, verbose=1, batch_size=32,validation_split=0.2)\n",
    "        if units[i]==10:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for units=\",units[i],\"is:\",nmaes_t)\n",
    "        if units[i]==50:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for units=\",units[i],\"is:\",nmaes_t)\n",
    "        if units[i]==80:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for units=\",units[i],\"is:\",nmaes_t)\n",
    "        if units[i]==128:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for units=\",units[i],\"is:\",nmaes_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning learningrate l=1\n",
    "l_r = [1e-2, 1e-3, 1e-4]\n",
    "def LSTM_tune_learningrate(input_X, input_Y,test_X,test_Y, l, h, n_features):\n",
    "    for i in range(len(l_r[i])):\n",
    "        X = Rnn_reshape(input_X, 1, n_features)\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu',dropout=0.3,return_sequences=True, input_shape=(l, n_features)))\n",
    "        model.add(LSTM(50, activation='relu',dropout=0.2))\n",
    "        model.add(Dense(h))\n",
    "        opt = Adam(lr=l_r[i])\n",
    "        model.compile(optimizer=opt, loss='mae',metrics=['accuracy'])\n",
    "        model.fit(X, input_Y, epochs=50, verbose=1, batch_size=32,validation_split=0.2)\n",
    "        if l_r[i]==1e-2:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for learning rate=\",l_r[i],\"is:\",nmaes_t)\n",
    "        if l_r[i]==1e-3:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for learning rate=\",l_r[i],\"is:\",nmaes_t)\n",
    "        if l_r[i]==1e-4:\n",
    "            Rnn_test = Rnn_reshape(test_X, 1, 16)\n",
    "            Rnn_pred = model.predict(Rnn_test,verbose=0)\n",
    "            nmaes_t =  np.round(metrics.mean_absolute_error(Rnn_pred,test_Y)/np.mean(test_Y), decimals=6)\n",
    "            print(\"the NMAE for learning rate=\",l_r[i],\"is:\",nmaes_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(data_X,data_Y,h,l):\n",
    "    num_range = len(data_X)-1*l-1*h\n",
    "    X = data_X[0:num_range]\n",
    "    Y = data_Y[l*1:l*1+num_range]['ReadsAvg']\n",
    "    target = ['ReadsAvg']\n",
    "    index = X.index\n",
    "    Y.index = index\n",
    "    feature = [col for col in data_X] \n",
    "    \n",
    "    for i in range(l):\n",
    "        if(i==0):\n",
    "            X = X\n",
    "        if(i>0):\n",
    "            X_add = data_X[(i+1)*1:(i+1)*1+num_range]\n",
    "            X_add.columns = [j+str(i+2) for j in feature] \n",
    "            X_add.index = index\n",
    "            X = pd.concat([X,X_add],axis=1)\n",
    "    \n",
    "    for i in range(h):\n",
    "        if(i==0):\n",
    "            Y = Y\n",
    "        if(i>0):\n",
    "            Y_add = data_Y[(l+i+1)*1:(l+i+1)*1+num_range]['ReadsAvg']\n",
    "            Y_add.columns = [j+str(i+2) for j in target] \n",
    "            Y_add.index = index\n",
    "            Y = pd.concat([Y,Y_add],axis=1)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/10\n",
      "8023/8023 [==============================] - 31s 4ms/step - loss: 11.4896 - accuracy: 0.0877 - val_loss: 2.3635 - val_accuracy: 0.0892\n",
      "Epoch 2/10\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 3.0212 - accuracy: 0.0921 - val_loss: 1.6489 - val_accuracy: 0.0862\n",
      "Epoch 3/10\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.9695 - accuracy: 0.0939 - val_loss: 1.3915 - val_accuracy: 0.0912\n",
      "Epoch 4/10\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.7003 - accuracy: 0.0911 - val_loss: 1.2342 - val_accuracy: 0.0927\n",
      "Epoch 5/10\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.6155 - accuracy: 0.0905 - val_loss: 1.2238 - val_accuracy: 0.0977\n",
      "Epoch 6/10\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.6187 - accuracy: 0.0901 - val_loss: 1.3183 - val_accuracy: 0.0997\n",
      "Epoch 7/10\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.6112 - accuracy: 0.0876 - val_loss: 1.2053 - val_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5844 - accuracy: 0.0950 - val_loss: 1.2618 - val_accuracy: 0.1017\n",
      "Epoch 9/10\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5983 - accuracy: 0.0927 - val_loss: 1.2498 - val_accuracy: 0.1062\n",
      "Epoch 10/10\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5836 - accuracy: 0.0901 - val_loss: 1.1994 - val_accuracy: 0.0857\n",
      "the NMAE for epochs= 10 is: ReadsAvg    0.028751\n",
      "ReadsAvg    0.028753\n",
      "ReadsAvg    0.028753\n",
      "ReadsAvg    0.028753\n",
      "ReadsAvg    0.028754\n",
      "ReadsAvg    0.028754\n",
      "ReadsAvg    0.028755\n",
      "ReadsAvg    0.028756\n",
      "ReadsAvg    0.028756\n",
      "ReadsAvg    0.028757\n",
      "ReadsAvg    0.028758\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/50\n",
      "8023/8023 [==============================] - 31s 4ms/step - loss: 11.4807 - accuracy: 0.0864 - val_loss: 1.2830 - val_accuracy: 0.0927\n",
      "Epoch 2/50\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 3.1824 - accuracy: 0.0930 - val_loss: 2.3777 - val_accuracy: 0.0907\n",
      "Epoch 3/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 2.2410 - accuracy: 0.0921 - val_loss: 1.6250 - val_accuracy: 0.0897\n",
      "Epoch 4/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.7261 - accuracy: 0.0961 - val_loss: 1.2730 - val_accuracy: 0.0867\n",
      "Epoch 5/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.6357 - accuracy: 0.0975 - val_loss: 1.2318 - val_accuracy: 0.0867\n",
      "Epoch 6/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.6165 - accuracy: 0.0947 - val_loss: 1.2831 - val_accuracy: 0.0872\n",
      "Epoch 7/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5987 - accuracy: 0.0988 - val_loss: 1.2034 - val_accuracy: 0.1022\n",
      "Epoch 8/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5784 - accuracy: 0.0985 - val_loss: 1.2049 - val_accuracy: 0.0892\n",
      "Epoch 9/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5760 - accuracy: 0.0947 - val_loss: 1.2031 - val_accuracy: 0.1007\n",
      "Epoch 10/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5649 - accuracy: 0.0980 - val_loss: 1.2120 - val_accuracy: 0.0957\n",
      "Epoch 11/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5624 - accuracy: 0.0931 - val_loss: 1.2253 - val_accuracy: 0.1067\n",
      "Epoch 12/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5731 - accuracy: 0.0982 - val_loss: 1.4032 - val_accuracy: 0.0932\n",
      "Epoch 13/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5613 - accuracy: 0.0935 - val_loss: 1.2166 - val_accuracy: 0.0922\n",
      "Epoch 14/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5653 - accuracy: 0.1007 - val_loss: 1.2362 - val_accuracy: 0.0877\n",
      "Epoch 15/50\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5411 - accuracy: 0.0955 - val_loss: 1.1886 - val_accuracy: 0.0922\n",
      "Epoch 16/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5468 - accuracy: 0.0941 - val_loss: 1.1776 - val_accuracy: 0.0947\n",
      "Epoch 17/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5463 - accuracy: 0.0951 - val_loss: 1.2074 - val_accuracy: 0.0937\n",
      "Epoch 18/50\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5414 - accuracy: 0.0927 - val_loss: 1.2433 - val_accuracy: 0.0997\n",
      "Epoch 19/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5296 - accuracy: 0.0919 - val_loss: 1.1886 - val_accuracy: 0.0877\n",
      "Epoch 20/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5377 - accuracy: 0.0942 - val_loss: 1.2023 - val_accuracy: 0.0882\n",
      "Epoch 21/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5385 - accuracy: 0.0924 - val_loss: 1.2114 - val_accuracy: 0.0877\n",
      "Epoch 22/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5383 - accuracy: 0.0985 - val_loss: 1.2073 - val_accuracy: 0.0887\n",
      "Epoch 23/50\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5258 - accuracy: 0.0957 - val_loss: 1.1776 - val_accuracy: 0.1097\n",
      "Epoch 24/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5290 - accuracy: 0.1006 - val_loss: 1.1966 - val_accuracy: 0.0852\n",
      "Epoch 25/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5331 - accuracy: 0.0940 - val_loss: 1.2427 - val_accuracy: 0.0872\n",
      "Epoch 26/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5356 - accuracy: 0.0909 - val_loss: 1.2421 - val_accuracy: 0.0862\n",
      "Epoch 27/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5304 - accuracy: 0.0946 - val_loss: 1.2301 - val_accuracy: 0.0972\n",
      "Epoch 28/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5273 - accuracy: 0.0920 - val_loss: 1.2003 - val_accuracy: 0.0897\n",
      "Epoch 29/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5282 - accuracy: 0.0977 - val_loss: 1.2231 - val_accuracy: 0.0902\n",
      "Epoch 30/50\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5329 - accuracy: 0.0960 - val_loss: 1.2670 - val_accuracy: 0.0862\n",
      "Epoch 31/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5287 - accuracy: 0.0950 - val_loss: 1.1932 - val_accuracy: 0.0927\n",
      "Epoch 32/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5303 - accuracy: 0.0911 - val_loss: 1.1907 - val_accuracy: 0.1012\n",
      "Epoch 33/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5406 - accuracy: 0.0950 - val_loss: 1.3152 - val_accuracy: 0.0952\n",
      "Epoch 34/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5293 - accuracy: 0.0967 - val_loss: 1.1839 - val_accuracy: 0.0932\n",
      "Epoch 35/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5414 - accuracy: 0.0952 - val_loss: 1.2433 - val_accuracy: 0.0932\n",
      "Epoch 36/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5218 - accuracy: 0.0977 - val_loss: 1.2077 - val_accuracy: 0.1077\n",
      "Epoch 37/50\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.5393 - accuracy: 0.0911 - val_loss: 1.2768 - val_accuracy: 0.1022\n",
      "Epoch 38/50\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5261 - accuracy: 0.0926 - val_loss: 1.1963 - val_accuracy: 0.0997\n",
      "Epoch 39/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5317 - accuracy: 0.0907 - val_loss: 1.2590 - val_accuracy: 0.0902\n",
      "Epoch 40/50\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5272 - accuracy: 0.0890 - val_loss: 1.1776 - val_accuracy: 0.0952\n",
      "Epoch 41/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5290 - accuracy: 0.0995 - val_loss: 1.1994 - val_accuracy: 0.0947\n",
      "Epoch 42/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5324 - accuracy: 0.0932 - val_loss: 1.1911 - val_accuracy: 0.0867\n",
      "Epoch 43/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5339 - accuracy: 0.0901 - val_loss: 1.2729 - val_accuracy: 0.0922\n",
      "Epoch 44/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5295 - accuracy: 0.0967 - val_loss: 1.2335 - val_accuracy: 0.0922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5247 - accuracy: 0.0961 - val_loss: 1.2031 - val_accuracy: 0.1037\n",
      "Epoch 46/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5262 - accuracy: 0.0991 - val_loss: 1.1919 - val_accuracy: 0.1037\n",
      "Epoch 47/50\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5334 - accuracy: 0.0937 - val_loss: 1.1701 - val_accuracy: 0.1052\n",
      "Epoch 48/50\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5326 - accuracy: 0.0861 - val_loss: 1.1819 - val_accuracy: 0.1007\n",
      "Epoch 49/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5243 - accuracy: 0.0899 - val_loss: 1.1976 - val_accuracy: 0.0932\n",
      "Epoch 50/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5328 - accuracy: 0.0894 - val_loss: 1.1932 - val_accuracy: 0.0932\n",
      "the NMAE for epochs= 50 is: ReadsAvg    0.028488\n",
      "ReadsAvg    0.028489\n",
      "ReadsAvg    0.028490\n",
      "ReadsAvg    0.028490\n",
      "ReadsAvg    0.028491\n",
      "ReadsAvg    0.028491\n",
      "ReadsAvg    0.028491\n",
      "ReadsAvg    0.028492\n",
      "ReadsAvg    0.028493\n",
      "ReadsAvg    0.028493\n",
      "ReadsAvg    0.028495\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/100\n",
      "8023/8023 [==============================] - 32s 4ms/step - loss: 11.4530 - accuracy: 0.0976 - val_loss: 2.4202 - val_accuracy: 0.0902\n",
      "Epoch 2/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 3.0205 - accuracy: 0.0925 - val_loss: 1.3815 - val_accuracy: 0.0927\n",
      "Epoch 3/100\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 2.0794 - accuracy: 0.0966 - val_loss: 1.3953 - val_accuracy: 0.0877\n",
      "Epoch 4/100\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.7020 - accuracy: 0.0909 - val_loss: 1.2770 - val_accuracy: 0.0917\n",
      "Epoch 5/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.6227 - accuracy: 0.0935 - val_loss: 1.3174 - val_accuracy: 0.0937\n",
      "Epoch 6/100\n",
      "8023/8023 [==============================] - 13s 2ms/step - loss: 1.6448 - accuracy: 0.0881 - val_loss: 1.2297 - val_accuracy: 0.0937\n",
      "Epoch 7/100\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.6065 - accuracy: 0.0955 - val_loss: 1.2426 - val_accuracy: 0.1002\n",
      "Epoch 8/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5770 - accuracy: 0.0942 - val_loss: 1.1709 - val_accuracy: 0.0927\n",
      "Epoch 9/100\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.6191 - accuracy: 0.0927 - val_loss: 1.2523 - val_accuracy: 0.0907\n",
      "Epoch 10/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5970 - accuracy: 0.0925 - val_loss: 1.2019 - val_accuracy: 0.0967\n",
      "Epoch 11/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5864 - accuracy: 0.0899 - val_loss: 1.3025 - val_accuracy: 0.0922\n",
      "Epoch 12/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5753 - accuracy: 0.1018 - val_loss: 1.2291 - val_accuracy: 0.1132\n",
      "Epoch 13/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5785 - accuracy: 0.0932 - val_loss: 1.2098 - val_accuracy: 0.1002\n",
      "Epoch 14/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5705 - accuracy: 0.0997 - val_loss: 1.2383 - val_accuracy: 0.0887\n",
      "Epoch 15/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5644 - accuracy: 0.0952 - val_loss: 1.2949 - val_accuracy: 0.1032\n",
      "Epoch 16/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5928 - accuracy: 0.0949 - val_loss: 1.2043 - val_accuracy: 0.0927\n",
      "Epoch 17/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5645 - accuracy: 0.0925 - val_loss: 1.2065 - val_accuracy: 0.0867\n",
      "Epoch 18/100\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5509 - accuracy: 0.1011 - val_loss: 1.2443 - val_accuracy: 0.1037\n",
      "Epoch 19/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5499 - accuracy: 0.0874 - val_loss: 1.2292 - val_accuracy: 0.0972\n",
      "Epoch 20/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5433 - accuracy: 0.0936 - val_loss: 1.2062 - val_accuracy: 0.0952\n",
      "Epoch 21/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5444 - accuracy: 0.0936 - val_loss: 1.2197 - val_accuracy: 0.0862\n",
      "Epoch 22/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5393 - accuracy: 0.0850 - val_loss: 1.1859 - val_accuracy: 0.0962\n",
      "Epoch 23/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5426 - accuracy: 0.0891 - val_loss: 1.1896 - val_accuracy: 0.1097\n",
      "Epoch 24/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5297 - accuracy: 0.0971 - val_loss: 1.1832 - val_accuracy: 0.0932\n",
      "Epoch 25/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5456 - accuracy: 0.0939 - val_loss: 1.2180 - val_accuracy: 0.1042\n",
      "Epoch 26/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5281 - accuracy: 0.0987 - val_loss: 1.1822 - val_accuracy: 0.0847\n",
      "Epoch 27/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5480 - accuracy: 0.0902 - val_loss: 1.1958 - val_accuracy: 0.0897\n",
      "Epoch 28/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5287 - accuracy: 0.0951 - val_loss: 1.2267 - val_accuracy: 0.0877\n",
      "Epoch 29/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5235 - accuracy: 0.0892 - val_loss: 1.1841 - val_accuracy: 0.1007\n",
      "Epoch 30/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5354 - accuracy: 0.0900 - val_loss: 1.1838 - val_accuracy: 0.0897\n",
      "Epoch 31/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5339 - accuracy: 0.0945 - val_loss: 1.2078 - val_accuracy: 0.1047\n",
      "Epoch 32/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5248 - accuracy: 0.0944 - val_loss: 1.1873 - val_accuracy: 0.0877\n",
      "Epoch 33/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5340 - accuracy: 0.0957 - val_loss: 1.2391 - val_accuracy: 0.0922\n",
      "Epoch 34/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5377 - accuracy: 0.1003 - val_loss: 1.2196 - val_accuracy: 0.1002\n",
      "Epoch 35/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5333 - accuracy: 0.0986 - val_loss: 1.1913 - val_accuracy: 0.0912\n",
      "Epoch 36/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5348 - accuracy: 0.0890 - val_loss: 1.1828 - val_accuracy: 0.0947\n",
      "Epoch 37/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5321 - accuracy: 0.0939 - val_loss: 1.1933 - val_accuracy: 0.1092\n",
      "Epoch 38/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5276 - accuracy: 0.0940 - val_loss: 1.2679 - val_accuracy: 0.0982\n",
      "Epoch 39/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5280 - accuracy: 0.0915 - val_loss: 1.2088 - val_accuracy: 0.1052\n",
      "Epoch 40/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5285 - accuracy: 0.0982 - val_loss: 1.1930 - val_accuracy: 0.0937\n",
      "Epoch 41/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5319 - accuracy: 0.0950 - val_loss: 1.2183 - val_accuracy: 0.0937\n",
      "Epoch 42/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5317 - accuracy: 0.0912 - val_loss: 1.3049 - val_accuracy: 0.0942\n",
      "Epoch 43/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5265 - accuracy: 0.0935 - val_loss: 1.2074 - val_accuracy: 0.0887\n",
      "Epoch 44/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5242 - accuracy: 0.0947 - val_loss: 1.1949 - val_accuracy: 0.1042\n",
      "Epoch 45/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5176 - accuracy: 0.0992 - val_loss: 1.2143 - val_accuracy: 0.0852\n",
      "Epoch 46/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5339 - accuracy: 0.0921 - val_loss: 1.2374 - val_accuracy: 0.0892\n",
      "Epoch 47/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5332 - accuracy: 0.0919 - val_loss: 1.1987 - val_accuracy: 0.0862\n",
      "Epoch 48/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5218 - accuracy: 0.0985 - val_loss: 1.1871 - val_accuracy: 0.0882\n",
      "Epoch 49/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5209 - accuracy: 0.0970 - val_loss: 1.1874 - val_accuracy: 0.0882\n",
      "Epoch 50/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5234 - accuracy: 0.0944 - val_loss: 1.2059 - val_accuracy: 0.0867\n",
      "Epoch 51/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5256 - accuracy: 0.1052 - val_loss: 1.1753 - val_accuracy: 0.0932\n",
      "Epoch 52/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5267 - accuracy: 0.0875 - val_loss: 1.2158 - val_accuracy: 0.0922\n",
      "Epoch 53/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5327 - accuracy: 0.0927 - val_loss: 1.2536 - val_accuracy: 0.0907\n",
      "Epoch 54/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5271 - accuracy: 0.0941 - val_loss: 1.2956 - val_accuracy: 0.0892\n",
      "Epoch 55/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5229 - accuracy: 0.0914 - val_loss: 1.1894 - val_accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5264 - accuracy: 0.0955 - val_loss: 1.1884 - val_accuracy: 0.0902\n",
      "Epoch 57/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5267 - accuracy: 0.0892 - val_loss: 1.2117 - val_accuracy: 0.0927\n",
      "Epoch 58/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5257 - accuracy: 0.0958 - val_loss: 1.1768 - val_accuracy: 0.0992\n",
      "Epoch 59/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5160 - accuracy: 0.0926 - val_loss: 1.1820 - val_accuracy: 0.0872\n",
      "Epoch 60/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5247 - accuracy: 0.0904 - val_loss: 1.2005 - val_accuracy: 0.0882\n",
      "Epoch 61/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5146 - accuracy: 0.0990 - val_loss: 1.1988 - val_accuracy: 0.0922\n",
      "Epoch 62/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5204 - accuracy: 0.0911 - val_loss: 1.2404 - val_accuracy: 0.0917\n",
      "Epoch 63/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5265 - accuracy: 0.0983 - val_loss: 1.2111 - val_accuracy: 0.0897\n",
      "Epoch 64/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5408 - accuracy: 0.0887 - val_loss: 1.2280 - val_accuracy: 0.0942\n",
      "Epoch 65/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5213 - accuracy: 0.0925 - val_loss: 1.2273 - val_accuracy: 0.0862\n",
      "Epoch 66/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5165 - accuracy: 0.0920 - val_loss: 1.1855 - val_accuracy: 0.0857\n",
      "Epoch 67/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5246 - accuracy: 0.0941 - val_loss: 1.2485 - val_accuracy: 0.0877\n",
      "Epoch 68/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5181 - accuracy: 0.0942 - val_loss: 1.2070 - val_accuracy: 0.0852\n",
      "Epoch 69/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5232 - accuracy: 0.0976 - val_loss: 1.2035 - val_accuracy: 0.0857\n",
      "Epoch 70/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5157 - accuracy: 0.0927 - val_loss: 1.1870 - val_accuracy: 0.0907\n",
      "Epoch 71/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5159 - accuracy: 0.0901 - val_loss: 1.2295 - val_accuracy: 0.0852\n",
      "Epoch 72/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5189 - accuracy: 0.0877 - val_loss: 1.2026 - val_accuracy: 0.1037\n",
      "Epoch 73/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5178 - accuracy: 0.0891 - val_loss: 1.2352 - val_accuracy: 0.0852\n",
      "Epoch 74/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5223 - accuracy: 0.0922 - val_loss: 1.2093 - val_accuracy: 0.0997\n",
      "Epoch 75/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5154 - accuracy: 0.0910 - val_loss: 1.1917 - val_accuracy: 0.0917\n",
      "Epoch 76/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5176 - accuracy: 0.0946 - val_loss: 1.1790 - val_accuracy: 0.0897\n",
      "Epoch 77/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5186 - accuracy: 0.0937 - val_loss: 1.1992 - val_accuracy: 0.0847\n",
      "Epoch 78/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5094 - accuracy: 0.0988 - val_loss: 1.2020 - val_accuracy: 0.0902\n",
      "Epoch 79/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5204 - accuracy: 0.0886 - val_loss: 1.2097 - val_accuracy: 0.0997\n",
      "Epoch 80/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5180 - accuracy: 0.0882 - val_loss: 1.2902 - val_accuracy: 0.0932\n",
      "Epoch 81/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5189 - accuracy: 0.0914 - val_loss: 1.1978 - val_accuracy: 0.0897\n",
      "Epoch 82/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5128 - accuracy: 0.0906 - val_loss: 1.1860 - val_accuracy: 0.0842\n",
      "Epoch 83/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5144 - accuracy: 0.0956 - val_loss: 1.2794 - val_accuracy: 0.0957\n",
      "Epoch 84/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5255 - accuracy: 0.1020 - val_loss: 1.3413 - val_accuracy: 0.0837\n",
      "Epoch 85/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5270 - accuracy: 0.0992 - val_loss: 1.2641 - val_accuracy: 0.1087\n",
      "Epoch 86/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5257 - accuracy: 0.0934 - val_loss: 1.2448 - val_accuracy: 0.0852\n",
      "Epoch 87/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5128 - accuracy: 0.0954 - val_loss: 1.1991 - val_accuracy: 0.0867\n",
      "Epoch 88/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5115 - accuracy: 0.0887 - val_loss: 1.1899 - val_accuracy: 0.0897\n",
      "Epoch 89/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5178 - accuracy: 0.0925 - val_loss: 1.2462 - val_accuracy: 0.0877\n",
      "Epoch 90/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5166 - accuracy: 0.0931 - val_loss: 1.2316 - val_accuracy: 0.1007\n",
      "Epoch 91/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5129 - accuracy: 0.0910 - val_loss: 1.2041 - val_accuracy: 0.0907\n",
      "Epoch 92/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5094 - accuracy: 0.0971 - val_loss: 1.2512 - val_accuracy: 0.0917\n",
      "Epoch 93/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5060 - accuracy: 0.0968 - val_loss: 1.2320 - val_accuracy: 0.0922\n",
      "Epoch 94/100\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5103 - accuracy: 0.0987 - val_loss: 1.1784 - val_accuracy: 0.0902\n",
      "Epoch 95/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5080 - accuracy: 0.0970 - val_loss: 1.1981 - val_accuracy: 0.1062\n",
      "Epoch 96/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5179 - accuracy: 0.0955 - val_loss: 1.2209 - val_accuracy: 0.1057\n",
      "Epoch 97/100\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5214 - accuracy: 0.0976 - val_loss: 1.2157 - val_accuracy: 0.0857\n",
      "Epoch 98/100\n",
      "8023/8023 [==============================] - 8s 992us/step - loss: 1.5049 - accuracy: 0.0971 - val_loss: 1.2539 - val_accuracy: 0.0833\n",
      "Epoch 99/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5040 - accuracy: 0.0899 - val_loss: 1.2899 - val_accuracy: 0.0877\n",
      "Epoch 100/100\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5194 - accuracy: 0.0902 - val_loss: 1.2108 - val_accuracy: 0.0907\n",
      "the NMAE for epochs= 100 is: ReadsAvg    0.028755\n",
      "ReadsAvg    0.028757\n",
      "ReadsAvg    0.028757\n",
      "ReadsAvg    0.028757\n",
      "ReadsAvg    0.028758\n",
      "ReadsAvg    0.028758\n",
      "ReadsAvg    0.028759\n",
      "ReadsAvg    0.028760\n",
      "ReadsAvg    0.028760\n",
      "ReadsAvg    0.028761\n",
      "ReadsAvg    0.028762\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/200\n",
      "8023/8023 [==============================] - 32s 4ms/step - loss: 11.3731 - accuracy: 0.0962 - val_loss: 2.3843 - val_accuracy: 0.0877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 3.0637 - accuracy: 0.0951 - val_loss: 1.5814 - val_accuracy: 0.0927\n",
      "Epoch 3/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 2.0406 - accuracy: 0.0946 - val_loss: 1.3055 - val_accuracy: 0.1052\n",
      "Epoch 4/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.6920 - accuracy: 0.0921 - val_loss: 1.2205 - val_accuracy: 0.0907\n",
      "Epoch 5/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.6138 - accuracy: 0.0936 - val_loss: 1.3283 - val_accuracy: 0.0887\n",
      "Epoch 6/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.6093 - accuracy: 0.0992 - val_loss: 1.2274 - val_accuracy: 0.1052\n",
      "Epoch 7/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5902 - accuracy: 0.0917 - val_loss: 1.3390 - val_accuracy: 0.0902\n",
      "Epoch 8/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.6014 - accuracy: 0.0935 - val_loss: 1.1966 - val_accuracy: 0.0947\n",
      "Epoch 9/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5734 - accuracy: 0.0955 - val_loss: 1.2613 - val_accuracy: 0.0852\n",
      "Epoch 10/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5912 - accuracy: 0.0939 - val_loss: 1.3464 - val_accuracy: 0.0927\n",
      "Epoch 11/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5642 - accuracy: 0.0972 - val_loss: 1.2217 - val_accuracy: 0.0902\n",
      "Epoch 12/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5785 - accuracy: 0.0920 - val_loss: 1.2760 - val_accuracy: 0.0897\n",
      "Epoch 13/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5702 - accuracy: 0.0983 - val_loss: 1.2323 - val_accuracy: 0.1042\n",
      "Epoch 14/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5713 - accuracy: 0.0971 - val_loss: 1.2003 - val_accuracy: 0.0892\n",
      "Epoch 15/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5717 - accuracy: 0.0922 - val_loss: 1.1767 - val_accuracy: 0.1017\n",
      "Epoch 16/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5640 - accuracy: 0.0919 - val_loss: 1.2390 - val_accuracy: 0.0837\n",
      "Epoch 17/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5600 - accuracy: 0.0936 - val_loss: 1.3255 - val_accuracy: 0.0897\n",
      "Epoch 18/200\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5690 - accuracy: 0.0952 - val_loss: 1.2300 - val_accuracy: 0.0987\n",
      "Epoch 19/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5557 - accuracy: 0.0965 - val_loss: 1.2365 - val_accuracy: 0.0937\n",
      "Epoch 20/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5453 - accuracy: 0.0945 - val_loss: 1.1971 - val_accuracy: 0.0872\n",
      "Epoch 21/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5510 - accuracy: 0.0921 - val_loss: 1.2088 - val_accuracy: 0.0997\n",
      "Epoch 22/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5437 - accuracy: 0.0920 - val_loss: 1.2172 - val_accuracy: 0.0997\n",
      "Epoch 23/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5472 - accuracy: 0.0956 - val_loss: 1.2383 - val_accuracy: 0.0912\n",
      "Epoch 24/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5498 - accuracy: 0.0851 - val_loss: 1.1973 - val_accuracy: 0.0982\n",
      "Epoch 25/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5460 - accuracy: 0.0912 - val_loss: 1.2211 - val_accuracy: 0.0852\n",
      "Epoch 26/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5431 - accuracy: 0.0940 - val_loss: 1.2116 - val_accuracy: 0.0937\n",
      "Epoch 27/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5547 - accuracy: 0.0967 - val_loss: 1.2213 - val_accuracy: 0.1007\n",
      "Epoch 28/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5608 - accuracy: 0.0921 - val_loss: 1.1783 - val_accuracy: 0.0877\n",
      "Epoch 29/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5445 - accuracy: 0.0961 - val_loss: 1.2050 - val_accuracy: 0.1077\n",
      "Epoch 30/200\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.5463 - accuracy: 0.0905 - val_loss: 1.2045 - val_accuracy: 0.0857\n",
      "Epoch 31/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5454 - accuracy: 0.0996 - val_loss: 1.2674 - val_accuracy: 0.0932\n",
      "Epoch 32/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5476 - accuracy: 0.0916 - val_loss: 1.1989 - val_accuracy: 0.0842\n",
      "Epoch 33/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5434 - accuracy: 0.0945 - val_loss: 1.2236 - val_accuracy: 0.0872\n",
      "Epoch 34/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5395 - accuracy: 0.0951 - val_loss: 1.2044 - val_accuracy: 0.0857\n",
      "Epoch 35/200\n",
      "8023/8023 [==============================] - 8s 997us/step - loss: 1.5452 - accuracy: 0.0967 - val_loss: 1.1849 - val_accuracy: 0.0972\n",
      "Epoch 36/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5384 - accuracy: 0.0983 - val_loss: 1.2008 - val_accuracy: 0.0892\n",
      "Epoch 37/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5455 - accuracy: 0.0924 - val_loss: 1.2099 - val_accuracy: 0.0927\n",
      "Epoch 38/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5460 - accuracy: 0.0956 - val_loss: 1.1822 - val_accuracy: 0.0852\n",
      "Epoch 39/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5431 - accuracy: 0.0968 - val_loss: 1.2131 - val_accuracy: 0.0897\n",
      "Epoch 40/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5406 - accuracy: 0.0885 - val_loss: 1.1773 - val_accuracy: 0.0997\n",
      "Epoch 41/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5388 - accuracy: 0.0990 - val_loss: 1.1969 - val_accuracy: 0.0997\n",
      "Epoch 42/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5347 - accuracy: 0.0952 - val_loss: 1.2418 - val_accuracy: 0.0892\n",
      "Epoch 43/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5428 - accuracy: 0.0982 - val_loss: 1.1783 - val_accuracy: 0.1007\n",
      "Epoch 44/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5338 - accuracy: 0.0937 - val_loss: 1.2051 - val_accuracy: 0.0907\n",
      "Epoch 45/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5352 - accuracy: 0.0966 - val_loss: 1.2179 - val_accuracy: 0.1037\n",
      "Epoch 46/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5350 - accuracy: 0.0935 - val_loss: 1.1976 - val_accuracy: 0.0887\n",
      "Epoch 47/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5350 - accuracy: 0.0946 - val_loss: 1.1791 - val_accuracy: 0.1052\n",
      "Epoch 48/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5398 - accuracy: 0.0924 - val_loss: 1.1809 - val_accuracy: 0.0932\n",
      "Epoch 49/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5277 - accuracy: 0.0963 - val_loss: 1.1673 - val_accuracy: 0.0977\n",
      "Epoch 50/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5268 - accuracy: 0.0926 - val_loss: 1.1794 - val_accuracy: 0.0992\n",
      "Epoch 51/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5214 - accuracy: 0.0975 - val_loss: 1.2069 - val_accuracy: 0.0902\n",
      "Epoch 52/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5331 - accuracy: 0.0957 - val_loss: 1.2037 - val_accuracy: 0.0837\n",
      "Epoch 53/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5350 - accuracy: 0.0940 - val_loss: 1.1882 - val_accuracy: 0.0897\n",
      "Epoch 54/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5344 - accuracy: 0.0949 - val_loss: 1.2605 - val_accuracy: 0.0922\n",
      "Epoch 55/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5264 - accuracy: 0.0983 - val_loss: 1.1881 - val_accuracy: 0.0962\n",
      "Epoch 56/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5246 - accuracy: 0.0936 - val_loss: 1.1933 - val_accuracy: 0.0872\n",
      "Epoch 57/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5414 - accuracy: 0.0871 - val_loss: 1.1896 - val_accuracy: 0.0972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5386 - accuracy: 0.0992 - val_loss: 1.2023 - val_accuracy: 0.1012\n",
      "Epoch 59/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5298 - accuracy: 0.0949 - val_loss: 1.2445 - val_accuracy: 0.0887\n",
      "Epoch 60/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5311 - accuracy: 0.0945 - val_loss: 1.2360 - val_accuracy: 0.0942\n",
      "Epoch 61/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5282 - accuracy: 0.1018 - val_loss: 1.2365 - val_accuracy: 0.0852\n",
      "Epoch 62/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5313 - accuracy: 0.0958 - val_loss: 1.2015 - val_accuracy: 0.0897\n",
      "Epoch 63/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5347 - accuracy: 0.0925 - val_loss: 1.2182 - val_accuracy: 0.0902\n",
      "Epoch 64/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5317 - accuracy: 0.0929 - val_loss: 1.1834 - val_accuracy: 0.0937\n",
      "Epoch 65/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5285 - accuracy: 0.0972 - val_loss: 1.2112 - val_accuracy: 0.0997\n",
      "Epoch 66/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5299 - accuracy: 0.0924 - val_loss: 1.2157 - val_accuracy: 0.0932\n",
      "Epoch 67/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5182 - accuracy: 0.0973 - val_loss: 1.2183 - val_accuracy: 0.0852\n",
      "Epoch 68/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5289 - accuracy: 0.0992 - val_loss: 1.1684 - val_accuracy: 0.0862\n",
      "Epoch 69/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5222 - accuracy: 0.0958 - val_loss: 1.1808 - val_accuracy: 0.0932\n",
      "Epoch 70/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5238 - accuracy: 0.1005 - val_loss: 1.2287 - val_accuracy: 0.0932\n",
      "Epoch 71/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5289 - accuracy: 0.0956 - val_loss: 1.2236 - val_accuracy: 0.0922\n",
      "Epoch 72/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5228 - accuracy: 0.0906 - val_loss: 1.1804 - val_accuracy: 0.0967\n",
      "Epoch 73/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5220 - accuracy: 0.0957 - val_loss: 1.2522 - val_accuracy: 0.0927\n",
      "Epoch 74/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5333 - accuracy: 0.0921 - val_loss: 1.2141 - val_accuracy: 0.0932\n",
      "Epoch 75/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5234 - accuracy: 0.0957 - val_loss: 1.2025 - val_accuracy: 0.1097\n",
      "Epoch 76/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5326 - accuracy: 0.1010 - val_loss: 1.1991 - val_accuracy: 0.1052\n",
      "Epoch 77/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5193 - accuracy: 0.0947 - val_loss: 1.2400 - val_accuracy: 0.0927\n",
      "Epoch 78/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5274 - accuracy: 0.0975 - val_loss: 1.2019 - val_accuracy: 0.0962\n",
      "Epoch 79/200\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.5148 - accuracy: 0.0955 - val_loss: 1.1781 - val_accuracy: 0.0942\n",
      "Epoch 80/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5140 - accuracy: 0.0998 - val_loss: 1.1784 - val_accuracy: 0.1102\n",
      "Epoch 81/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5191 - accuracy: 0.0982 - val_loss: 1.2005 - val_accuracy: 0.0922\n",
      "Epoch 82/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5234 - accuracy: 0.0915 - val_loss: 1.2057 - val_accuracy: 0.0962\n",
      "Epoch 83/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5256 - accuracy: 0.0982 - val_loss: 1.1780 - val_accuracy: 0.0972\n",
      "Epoch 84/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5255 - accuracy: 0.0975 - val_loss: 1.2331 - val_accuracy: 0.1052\n",
      "Epoch 85/200\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5244 - accuracy: 0.0977 - val_loss: 1.2487 - val_accuracy: 0.0857\n",
      "Epoch 86/200\n",
      "8023/8023 [==============================] - 8s 982us/step - loss: 1.5149 - accuracy: 0.0978 - val_loss: 1.1976 - val_accuracy: 0.0887\n",
      "Epoch 87/200\n",
      "8023/8023 [==============================] - 8s 979us/step - loss: 1.5158 - accuracy: 0.0944 - val_loss: 1.2745 - val_accuracy: 0.0862\n",
      "Epoch 88/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5170 - accuracy: 0.0965 - val_loss: 1.1834 - val_accuracy: 0.0872\n",
      "Epoch 89/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5185 - accuracy: 0.0965 - val_loss: 1.2182 - val_accuracy: 0.1097\n",
      "Epoch 90/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5193 - accuracy: 0.0934 - val_loss: 1.2227 - val_accuracy: 0.0892\n",
      "Epoch 91/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5155 - accuracy: 0.0935 - val_loss: 1.1796 - val_accuracy: 0.0887\n",
      "Epoch 92/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5140 - accuracy: 0.0949 - val_loss: 1.1850 - val_accuracy: 0.1042\n",
      "Epoch 93/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5141 - accuracy: 0.0941 - val_loss: 1.1962 - val_accuracy: 0.0997\n",
      "Epoch 94/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5217 - accuracy: 0.0960 - val_loss: 1.2185 - val_accuracy: 0.0867\n",
      "Epoch 95/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5216 - accuracy: 0.0925 - val_loss: 1.1853 - val_accuracy: 0.0942\n",
      "Epoch 96/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5182 - accuracy: 0.0971 - val_loss: 1.2015 - val_accuracy: 0.0862\n",
      "Epoch 97/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5161 - accuracy: 0.0966 - val_loss: 1.2076 - val_accuracy: 0.0867\n",
      "Epoch 98/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5174 - accuracy: 0.0954 - val_loss: 1.2741 - val_accuracy: 0.0927\n",
      "Epoch 99/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5245 - accuracy: 0.0932 - val_loss: 1.2053 - val_accuracy: 0.0932\n",
      "Epoch 100/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5192 - accuracy: 0.0960 - val_loss: 1.2303 - val_accuracy: 0.1097\n",
      "Epoch 101/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5232 - accuracy: 0.0944 - val_loss: 1.2169 - val_accuracy: 0.0937\n",
      "Epoch 102/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5137 - accuracy: 0.0925 - val_loss: 1.2228 - val_accuracy: 0.0997\n",
      "Epoch 103/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5184 - accuracy: 0.0963 - val_loss: 1.1908 - val_accuracy: 0.1047\n",
      "Epoch 104/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5141 - accuracy: 0.0951 - val_loss: 1.2077 - val_accuracy: 0.0892\n",
      "Epoch 105/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5208 - accuracy: 0.0967 - val_loss: 1.2755 - val_accuracy: 0.0927\n",
      "Epoch 106/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5193 - accuracy: 0.0932 - val_loss: 1.2034 - val_accuracy: 0.0917\n",
      "Epoch 107/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5123 - accuracy: 0.0961 - val_loss: 1.2031 - val_accuracy: 0.0942\n",
      "Epoch 108/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5110 - accuracy: 0.0942 - val_loss: 1.1863 - val_accuracy: 0.0952\n",
      "Epoch 109/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5131 - accuracy: 0.0966 - val_loss: 1.2111 - val_accuracy: 0.0837\n",
      "Epoch 110/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5120 - accuracy: 0.0982 - val_loss: 1.2253 - val_accuracy: 0.0912\n",
      "Epoch 111/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5147 - accuracy: 0.0987 - val_loss: 1.2188 - val_accuracy: 0.0992\n",
      "Epoch 112/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5137 - accuracy: 0.0947 - val_loss: 1.1762 - val_accuracy: 0.0952\n",
      "Epoch 113/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5227 - accuracy: 0.0951 - val_loss: 1.2210 - val_accuracy: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5191 - accuracy: 0.0962 - val_loss: 1.2025 - val_accuracy: 0.0887\n",
      "Epoch 115/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5122 - accuracy: 0.0965 - val_loss: 1.2013 - val_accuracy: 0.0897\n",
      "Epoch 116/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5100 - accuracy: 0.1012 - val_loss: 1.2306 - val_accuracy: 0.1092\n",
      "Epoch 117/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5211 - accuracy: 0.0954 - val_loss: 1.2735 - val_accuracy: 0.0927\n",
      "Epoch 118/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5218 - accuracy: 0.0952 - val_loss: 1.2246 - val_accuracy: 0.1042\n",
      "Epoch 119/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5133 - accuracy: 0.0973 - val_loss: 1.3460 - val_accuracy: 0.0997\n",
      "Epoch 120/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5164 - accuracy: 0.0941 - val_loss: 1.2340 - val_accuracy: 0.0912\n",
      "Epoch 121/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5128 - accuracy: 0.0941 - val_loss: 1.2271 - val_accuracy: 0.0932\n",
      "Epoch 122/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5142 - accuracy: 0.0968 - val_loss: 1.2687 - val_accuracy: 0.0892\n",
      "Epoch 123/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5195 - accuracy: 0.0927 - val_loss: 1.2098 - val_accuracy: 0.0922\n",
      "Epoch 124/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5143 - accuracy: 0.0961 - val_loss: 1.1911 - val_accuracy: 0.0997\n",
      "Epoch 125/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5049 - accuracy: 0.0958 - val_loss: 1.3189 - val_accuracy: 0.0862\n",
      "Epoch 126/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5056 - accuracy: 0.0968 - val_loss: 1.2474 - val_accuracy: 0.1057\n",
      "Epoch 127/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5117 - accuracy: 0.0971 - val_loss: 1.2310 - val_accuracy: 0.1032\n",
      "Epoch 128/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5135 - accuracy: 0.0944 - val_loss: 1.1892 - val_accuracy: 0.0912\n",
      "Epoch 129/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5103 - accuracy: 0.0993 - val_loss: 1.2179 - val_accuracy: 0.0897\n",
      "Epoch 130/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5136 - accuracy: 0.0941 - val_loss: 1.2667 - val_accuracy: 0.1052\n",
      "Epoch 131/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5040 - accuracy: 0.0963 - val_loss: 1.2498 - val_accuracy: 0.1052\n",
      "Epoch 132/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5096 - accuracy: 0.0919 - val_loss: 1.1800 - val_accuracy: 0.0842\n",
      "Epoch 133/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5067 - accuracy: 0.0930 - val_loss: 1.3498 - val_accuracy: 0.0842\n",
      "Epoch 134/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5095 - accuracy: 0.0973 - val_loss: 1.2215 - val_accuracy: 0.0907\n",
      "Epoch 135/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5127 - accuracy: 0.0932 - val_loss: 1.2604 - val_accuracy: 0.0902\n",
      "Epoch 136/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5048 - accuracy: 0.0975 - val_loss: 1.2211 - val_accuracy: 0.0932\n",
      "Epoch 137/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5112 - accuracy: 0.0956 - val_loss: 1.2447 - val_accuracy: 0.0867\n",
      "Epoch 138/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5127 - accuracy: 0.0939 - val_loss: 1.2205 - val_accuracy: 0.0997\n",
      "Epoch 139/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5158 - accuracy: 0.0894 - val_loss: 1.1774 - val_accuracy: 0.0867\n",
      "Epoch 140/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5127 - accuracy: 0.0914 - val_loss: 1.1977 - val_accuracy: 0.1077\n",
      "Epoch 141/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5043 - accuracy: 0.0952 - val_loss: 1.3982 - val_accuracy: 0.0892\n",
      "Epoch 142/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5122 - accuracy: 0.1035 - val_loss: 1.2574 - val_accuracy: 0.0937\n",
      "Epoch 143/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5156 - accuracy: 0.0978 - val_loss: 1.1863 - val_accuracy: 0.0852\n",
      "Epoch 144/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5145 - accuracy: 0.0932 - val_loss: 1.1874 - val_accuracy: 0.0897\n",
      "Epoch 145/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5127 - accuracy: 0.0976 - val_loss: 1.2144 - val_accuracy: 0.0897\n",
      "Epoch 146/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5158 - accuracy: 0.0922 - val_loss: 1.2014 - val_accuracy: 0.0907\n",
      "Epoch 147/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5006 - accuracy: 0.0906 - val_loss: 1.2110 - val_accuracy: 0.0892\n",
      "Epoch 148/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5100 - accuracy: 0.0966 - val_loss: 1.2047 - val_accuracy: 0.0852\n",
      "Epoch 149/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4976 - accuracy: 0.0956 - val_loss: 1.2045 - val_accuracy: 0.0942\n",
      "Epoch 150/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5018 - accuracy: 0.0963 - val_loss: 1.2214 - val_accuracy: 0.0927\n",
      "Epoch 151/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5079 - accuracy: 0.0954 - val_loss: 1.2035 - val_accuracy: 0.0857\n",
      "Epoch 152/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5144 - accuracy: 0.0935 - val_loss: 1.2487 - val_accuracy: 0.0887\n",
      "Epoch 153/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5085 - accuracy: 0.0915 - val_loss: 1.2389 - val_accuracy: 0.0882\n",
      "Epoch 154/200\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.5061 - accuracy: 0.1016 - val_loss: 1.2007 - val_accuracy: 0.0997\n",
      "Epoch 155/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4989 - accuracy: 0.0976 - val_loss: 1.2843 - val_accuracy: 0.0897\n",
      "Epoch 156/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5015 - accuracy: 0.0906 - val_loss: 1.3561 - val_accuracy: 0.0867\n",
      "Epoch 157/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5063 - accuracy: 0.0990 - val_loss: 1.2887 - val_accuracy: 0.0837\n",
      "Epoch 158/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5034 - accuracy: 0.0975 - val_loss: 1.2456 - val_accuracy: 0.1037\n",
      "Epoch 159/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4989 - accuracy: 0.1021 - val_loss: 1.1916 - val_accuracy: 0.0902\n",
      "Epoch 160/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5042 - accuracy: 0.0945 - val_loss: 1.2436 - val_accuracy: 0.0997\n",
      "Epoch 161/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4988 - accuracy: 0.0914 - val_loss: 1.1842 - val_accuracy: 0.0922\n",
      "Epoch 162/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5041 - accuracy: 0.0988 - val_loss: 1.2066 - val_accuracy: 0.0937\n",
      "Epoch 163/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5004 - accuracy: 0.0968 - val_loss: 1.2247 - val_accuracy: 0.0932\n",
      "Epoch 164/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5096 - accuracy: 0.0981 - val_loss: 1.2764 - val_accuracy: 0.0922\n",
      "Epoch 165/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5030 - accuracy: 0.0981 - val_loss: 1.2294 - val_accuracy: 0.1062\n",
      "Epoch 166/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5023 - accuracy: 0.0930 - val_loss: 1.3170 - val_accuracy: 0.0922\n",
      "Epoch 167/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4951 - accuracy: 0.0961 - val_loss: 1.2346 - val_accuracy: 0.0922\n",
      "Epoch 168/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5037 - accuracy: 0.0973 - val_loss: 1.1865 - val_accuracy: 0.0867\n",
      "Epoch 169/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5005 - accuracy: 0.0961 - val_loss: 1.2892 - val_accuracy: 0.0922\n",
      "Epoch 170/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4996 - accuracy: 0.0907 - val_loss: 1.2379 - val_accuracy: 0.0867\n",
      "Epoch 171/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5028 - accuracy: 0.1011 - val_loss: 1.2142 - val_accuracy: 0.0862\n",
      "Epoch 172/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4951 - accuracy: 0.0988 - val_loss: 1.1930 - val_accuracy: 0.0912\n",
      "Epoch 173/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5070 - accuracy: 0.0961 - val_loss: 1.1795 - val_accuracy: 0.1057\n",
      "Epoch 174/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4942 - accuracy: 0.1005 - val_loss: 1.2927 - val_accuracy: 0.0907\n",
      "Epoch 175/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4854 - accuracy: 0.0972 - val_loss: 1.2088 - val_accuracy: 0.1057\n",
      "Epoch 176/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5003 - accuracy: 0.0987 - val_loss: 1.2277 - val_accuracy: 0.1037\n",
      "Epoch 177/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4929 - accuracy: 0.0982 - val_loss: 1.2298 - val_accuracy: 0.1037\n",
      "Epoch 178/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4911 - accuracy: 0.0978 - val_loss: 1.2515 - val_accuracy: 0.0997\n",
      "Epoch 179/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4939 - accuracy: 0.0932 - val_loss: 1.2015 - val_accuracy: 0.0932\n",
      "Epoch 180/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4995 - accuracy: 0.0965 - val_loss: 1.2114 - val_accuracy: 0.0957\n",
      "Epoch 181/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5041 - accuracy: 0.1018 - val_loss: 1.1795 - val_accuracy: 0.1047\n",
      "Epoch 182/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4954 - accuracy: 0.0966 - val_loss: 1.1997 - val_accuracy: 0.0997\n",
      "Epoch 183/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4919 - accuracy: 0.1025 - val_loss: 1.2422 - val_accuracy: 0.0877\n",
      "Epoch 184/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5041 - accuracy: 0.0905 - val_loss: 1.2088 - val_accuracy: 0.1032\n",
      "Epoch 185/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4893 - accuracy: 0.0972 - val_loss: 1.2781 - val_accuracy: 0.0932\n",
      "Epoch 186/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4935 - accuracy: 0.0879 - val_loss: 1.2264 - val_accuracy: 0.1002\n",
      "Epoch 187/200\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4927 - accuracy: 0.0914 - val_loss: 1.2850 - val_accuracy: 0.0872\n",
      "Epoch 188/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5029 - accuracy: 0.0926 - val_loss: 1.2308 - val_accuracy: 0.1057\n",
      "Epoch 189/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4934 - accuracy: 0.1007 - val_loss: 1.2806 - val_accuracy: 0.0912\n",
      "Epoch 190/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4924 - accuracy: 0.0954 - val_loss: 1.2467 - val_accuracy: 0.0922\n",
      "Epoch 191/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4938 - accuracy: 0.0967 - val_loss: 1.2244 - val_accuracy: 0.0932\n",
      "Epoch 192/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4887 - accuracy: 0.0985 - val_loss: 1.2303 - val_accuracy: 0.0897\n",
      "Epoch 193/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4967 - accuracy: 0.0939 - val_loss: 1.1885 - val_accuracy: 0.0892\n",
      "Epoch 194/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5022 - accuracy: 0.0946 - val_loss: 1.1670 - val_accuracy: 0.0962\n",
      "Epoch 195/200\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4979 - accuracy: 0.0981 - val_loss: 1.3019 - val_accuracy: 0.0947\n",
      "Epoch 196/200\n",
      "8023/8023 [==============================] - 8s 967us/step - loss: 1.4890 - accuracy: 0.0956 - val_loss: 1.1755 - val_accuracy: 0.0917\n",
      "Epoch 197/200\n",
      "8023/8023 [==============================] - 8s 975us/step - loss: 1.4992 - accuracy: 0.0939 - val_loss: 1.2288 - val_accuracy: 0.0842\n",
      "Epoch 198/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4872 - accuracy: 0.0936 - val_loss: 1.2812 - val_accuracy: 0.0897\n",
      "Epoch 199/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4974 - accuracy: 0.1003 - val_loss: 1.2286 - val_accuracy: 0.0872\n",
      "Epoch 200/200\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4946 - accuracy: 0.0958 - val_loss: 1.2065 - val_accuracy: 0.0887\n",
      "the NMAE for epochs= 200 is: ReadsAvg    0.028665\n",
      "ReadsAvg    0.028666\n",
      "ReadsAvg    0.028667\n",
      "ReadsAvg    0.028667\n",
      "ReadsAvg    0.028667\n",
      "ReadsAvg    0.028668\n",
      "ReadsAvg    0.028668\n",
      "ReadsAvg    0.028669\n",
      "ReadsAvg    0.028670\n",
      "ReadsAvg    0.028670\n",
      "ReadsAvg    0.028671\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/500\n",
      "8023/8023 [==============================] - 31s 4ms/step - loss: 11.8604 - accuracy: 0.0904 - val_loss: 1.6029 - val_accuracy: 0.0912\n",
      "Epoch 2/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 3.1676 - accuracy: 0.0855 - val_loss: 1.5142 - val_accuracy: 0.0917\n",
      "Epoch 3/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 2.1373 - accuracy: 0.0899 - val_loss: 1.3412 - val_accuracy: 0.1037\n",
      "Epoch 4/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.6436 - accuracy: 0.0921 - val_loss: 1.4484 - val_accuracy: 0.0927\n",
      "Epoch 5/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.6231 - accuracy: 0.0936 - val_loss: 1.2457 - val_accuracy: 0.0917\n",
      "Epoch 6/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5910 - accuracy: 0.1035 - val_loss: 1.1856 - val_accuracy: 0.0927\n",
      "Epoch 7/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5902 - accuracy: 0.0897 - val_loss: 1.2041 - val_accuracy: 0.0897\n",
      "Epoch 8/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.5905 - accuracy: 0.0935 - val_loss: 1.2465 - val_accuracy: 0.0922\n",
      "Epoch 9/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5837 - accuracy: 0.0947 - val_loss: 1.2152 - val_accuracy: 0.0962\n",
      "Epoch 10/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5959 - accuracy: 0.0931 - val_loss: 1.2149 - val_accuracy: 0.1072\n",
      "Epoch 11/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5728 - accuracy: 0.0931 - val_loss: 1.2081 - val_accuracy: 0.0847\n",
      "Epoch 12/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5645 - accuracy: 0.0876 - val_loss: 1.3052 - val_accuracy: 0.1007\n",
      "Epoch 13/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5764 - accuracy: 0.0902 - val_loss: 1.2157 - val_accuracy: 0.0927\n",
      "Epoch 14/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5714 - accuracy: 0.0920 - val_loss: 1.2906 - val_accuracy: 0.0862\n",
      "Epoch 15/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5631 - accuracy: 0.0978 - val_loss: 1.2855 - val_accuracy: 0.0867\n",
      "Epoch 16/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5673 - accuracy: 0.0921 - val_loss: 1.2372 - val_accuracy: 0.1067\n",
      "Epoch 17/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5651 - accuracy: 0.0944 - val_loss: 1.2245 - val_accuracy: 0.0897\n",
      "Epoch 18/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5632 - accuracy: 0.0936 - val_loss: 1.2756 - val_accuracy: 0.0862\n",
      "Epoch 19/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5576 - accuracy: 0.0916 - val_loss: 1.1945 - val_accuracy: 0.0902\n",
      "Epoch 20/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5467 - accuracy: 0.0971 - val_loss: 1.2993 - val_accuracy: 0.0882\n",
      "Epoch 21/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5477 - accuracy: 0.0955 - val_loss: 1.2244 - val_accuracy: 0.1057\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5533 - accuracy: 0.0950 - val_loss: 1.2344 - val_accuracy: 0.0917\n",
      "Epoch 23/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5379 - accuracy: 0.1000 - val_loss: 1.2143 - val_accuracy: 0.0927\n",
      "Epoch 24/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5406 - accuracy: 0.0904 - val_loss: 1.1762 - val_accuracy: 0.0887\n",
      "Epoch 25/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5407 - accuracy: 0.0942 - val_loss: 1.2138 - val_accuracy: 0.0927\n",
      "Epoch 26/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5379 - accuracy: 0.0944 - val_loss: 1.2098 - val_accuracy: 0.0907\n",
      "Epoch 27/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5381 - accuracy: 0.0987 - val_loss: 1.1916 - val_accuracy: 0.0852\n",
      "Epoch 28/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5354 - accuracy: 0.0915 - val_loss: 1.2131 - val_accuracy: 0.0897\n",
      "Epoch 29/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5320 - accuracy: 0.0956 - val_loss: 1.2254 - val_accuracy: 0.1052\n",
      "Epoch 30/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5254 - accuracy: 0.1020 - val_loss: 1.1938 - val_accuracy: 0.0937\n",
      "Epoch 31/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5324 - accuracy: 0.0947 - val_loss: 1.1946 - val_accuracy: 0.0922\n",
      "Epoch 32/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5337 - accuracy: 0.0952 - val_loss: 1.1693 - val_accuracy: 0.0937\n",
      "Epoch 33/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5422 - accuracy: 0.0954 - val_loss: 1.1944 - val_accuracy: 0.0942\n",
      "Epoch 34/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5372 - accuracy: 0.0926 - val_loss: 1.2745 - val_accuracy: 0.0897\n",
      "Epoch 35/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5255 - accuracy: 0.0954 - val_loss: 1.2647 - val_accuracy: 0.0857\n",
      "Epoch 36/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5391 - accuracy: 0.0930 - val_loss: 1.1996 - val_accuracy: 0.0927\n",
      "Epoch 37/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5320 - accuracy: 0.0997 - val_loss: 1.3407 - val_accuracy: 0.0897\n",
      "Epoch 38/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5266 - accuracy: 0.0941 - val_loss: 1.1794 - val_accuracy: 0.0927\n",
      "Epoch 39/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5295 - accuracy: 0.0941 - val_loss: 1.1999 - val_accuracy: 0.0917\n",
      "Epoch 40/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5270 - accuracy: 0.0931 - val_loss: 1.1844 - val_accuracy: 0.0892\n",
      "Epoch 41/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.5244 - accuracy: 0.0978 - val_loss: 1.2098 - val_accuracy: 0.0842\n",
      "Epoch 42/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5262 - accuracy: 0.0939 - val_loss: 1.2128 - val_accuracy: 0.0897\n",
      "Epoch 43/500\n",
      "8023/8023 [==============================] - 13s 2ms/step - loss: 1.5316 - accuracy: 0.0874 - val_loss: 1.1987 - val_accuracy: 0.0947\n",
      "Epoch 44/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5202 - accuracy: 0.0912 - val_loss: 1.1932 - val_accuracy: 0.1052\n",
      "Epoch 45/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5353 - accuracy: 0.0947 - val_loss: 1.1692 - val_accuracy: 0.0852\n",
      "Epoch 46/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5364 - accuracy: 0.0904 - val_loss: 1.1847 - val_accuracy: 0.1032\n",
      "Epoch 47/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5262 - accuracy: 0.1037 - val_loss: 1.1906 - val_accuracy: 0.0877\n",
      "Epoch 48/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5186 - accuracy: 0.0951 - val_loss: 1.1822 - val_accuracy: 0.0997\n",
      "Epoch 49/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5305 - accuracy: 0.0939 - val_loss: 1.2158 - val_accuracy: 0.0852\n",
      "Epoch 50/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5258 - accuracy: 0.0919 - val_loss: 1.2133 - val_accuracy: 0.1082\n",
      "Epoch 51/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5288 - accuracy: 0.0977 - val_loss: 1.2259 - val_accuracy: 0.1007\n",
      "Epoch 52/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5186 - accuracy: 0.0951 - val_loss: 1.1881 - val_accuracy: 0.0997\n",
      "Epoch 53/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5158 - accuracy: 0.0963 - val_loss: 1.1876 - val_accuracy: 0.0872\n",
      "Epoch 54/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5245 - accuracy: 0.0946 - val_loss: 1.1828 - val_accuracy: 0.0947\n",
      "Epoch 55/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5258 - accuracy: 0.0995 - val_loss: 1.2039 - val_accuracy: 0.0852\n",
      "Epoch 56/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5211 - accuracy: 0.1000 - val_loss: 1.1875 - val_accuracy: 0.1017\n",
      "Epoch 57/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5227 - accuracy: 0.0870 - val_loss: 1.1821 - val_accuracy: 0.0867\n",
      "Epoch 58/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5246 - accuracy: 0.0934 - val_loss: 1.1872 - val_accuracy: 0.0902\n",
      "Epoch 59/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5248 - accuracy: 0.0970 - val_loss: 1.1928 - val_accuracy: 0.1062\n",
      "Epoch 60/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5183 - accuracy: 0.0945 - val_loss: 1.2302 - val_accuracy: 0.0927\n",
      "Epoch 61/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5318 - accuracy: 0.0940 - val_loss: 1.1743 - val_accuracy: 0.0942\n",
      "Epoch 62/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5184 - accuracy: 0.0997 - val_loss: 1.1799 - val_accuracy: 0.0967\n",
      "Epoch 63/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5305 - accuracy: 0.0963 - val_loss: 1.1847 - val_accuracy: 0.0932\n",
      "Epoch 64/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5225 - accuracy: 0.0924 - val_loss: 1.1926 - val_accuracy: 0.0877\n",
      "Epoch 65/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5264 - accuracy: 0.0904 - val_loss: 1.2098 - val_accuracy: 0.0877\n",
      "Epoch 66/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5174 - accuracy: 0.0947 - val_loss: 1.1630 - val_accuracy: 0.0917\n",
      "Epoch 67/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5219 - accuracy: 0.0939 - val_loss: 1.1720 - val_accuracy: 0.1082\n",
      "Epoch 68/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5118 - accuracy: 0.0932 - val_loss: 1.2359 - val_accuracy: 0.0997\n",
      "Epoch 69/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.5347 - accuracy: 0.0932 - val_loss: 1.1765 - val_accuracy: 0.0927\n",
      "Epoch 70/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5299 - accuracy: 0.0968 - val_loss: 1.2851 - val_accuracy: 0.0857\n",
      "Epoch 71/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5339 - accuracy: 0.0875 - val_loss: 1.1897 - val_accuracy: 0.1112\n",
      "Epoch 72/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5294 - accuracy: 0.0911 - val_loss: 1.2798 - val_accuracy: 0.0847\n",
      "Epoch 73/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5184 - accuracy: 0.0986 - val_loss: 1.2600 - val_accuracy: 0.0917\n",
      "Epoch 74/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5237 - accuracy: 0.0946 - val_loss: 1.2085 - val_accuracy: 0.0902\n",
      "Epoch 75/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5198 - accuracy: 0.0967 - val_loss: 1.1704 - val_accuracy: 0.0833\n",
      "Epoch 76/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5177 - accuracy: 0.0957 - val_loss: 1.2344 - val_accuracy: 0.0847\n",
      "Epoch 77/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5247 - accuracy: 0.0934 - val_loss: 1.1831 - val_accuracy: 0.0932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5231 - accuracy: 0.0916 - val_loss: 1.2096 - val_accuracy: 0.0852\n",
      "Epoch 79/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5199 - accuracy: 0.0922 - val_loss: 1.1777 - val_accuracy: 0.0947\n",
      "Epoch 80/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5243 - accuracy: 0.0985 - val_loss: 1.1912 - val_accuracy: 0.0917\n",
      "Epoch 81/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5246 - accuracy: 0.0920 - val_loss: 1.1801 - val_accuracy: 0.1022\n",
      "Epoch 82/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5160 - accuracy: 0.0985 - val_loss: 1.1885 - val_accuracy: 0.0987\n",
      "Epoch 83/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5257 - accuracy: 0.0961 - val_loss: 1.2191 - val_accuracy: 0.0867\n",
      "Epoch 84/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5309 - accuracy: 0.0971 - val_loss: 1.1910 - val_accuracy: 0.0897\n",
      "Epoch 85/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5213 - accuracy: 0.0963 - val_loss: 1.2132 - val_accuracy: 0.0987\n",
      "Epoch 86/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5119 - accuracy: 0.0931 - val_loss: 1.3000 - val_accuracy: 0.1052\n",
      "Epoch 87/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5456 - accuracy: 0.0934 - val_loss: 1.2277 - val_accuracy: 0.0897\n",
      "Epoch 88/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5257 - accuracy: 0.0954 - val_loss: 1.2166 - val_accuracy: 0.1077\n",
      "Epoch 89/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5133 - accuracy: 0.0906 - val_loss: 1.2072 - val_accuracy: 0.0922\n",
      "Epoch 90/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5106 - accuracy: 0.0985 - val_loss: 1.1881 - val_accuracy: 0.1027\n",
      "Epoch 91/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5168 - accuracy: 0.0949 - val_loss: 1.2096 - val_accuracy: 0.1057\n",
      "Epoch 92/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5167 - accuracy: 0.0915 - val_loss: 1.2122 - val_accuracy: 0.0907\n",
      "Epoch 93/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5194 - accuracy: 0.1012 - val_loss: 1.2112 - val_accuracy: 0.0828\n",
      "Epoch 94/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5102 - accuracy: 0.0942 - val_loss: 1.1907 - val_accuracy: 0.0852\n",
      "Epoch 95/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5146 - accuracy: 0.0915 - val_loss: 1.2149 - val_accuracy: 0.0987\n",
      "Epoch 96/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5157 - accuracy: 0.0924 - val_loss: 1.2460 - val_accuracy: 0.0912\n",
      "Epoch 97/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5171 - accuracy: 0.0965 - val_loss: 1.2063 - val_accuracy: 0.0917\n",
      "Epoch 98/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5092 - accuracy: 0.0955 - val_loss: 1.2133 - val_accuracy: 0.0912\n",
      "Epoch 99/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5233 - accuracy: 0.0977 - val_loss: 1.2119 - val_accuracy: 0.1047\n",
      "Epoch 100/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.5183 - accuracy: 0.0936 - val_loss: 1.2783 - val_accuracy: 0.0862\n",
      "Epoch 101/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5183 - accuracy: 0.0963 - val_loss: 1.2088 - val_accuracy: 0.0902\n",
      "Epoch 102/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5038 - accuracy: 0.0919 - val_loss: 1.2070 - val_accuracy: 0.0972\n",
      "Epoch 103/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5153 - accuracy: 0.0887 - val_loss: 1.1787 - val_accuracy: 0.0867\n",
      "Epoch 104/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5257 - accuracy: 0.0885 - val_loss: 1.2820 - val_accuracy: 0.1002\n",
      "Epoch 105/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5227 - accuracy: 0.0931 - val_loss: 1.2163 - val_accuracy: 0.0937\n",
      "Epoch 106/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5204 - accuracy: 0.0941 - val_loss: 1.2717 - val_accuracy: 0.0857\n",
      "Epoch 107/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5145 - accuracy: 0.1002 - val_loss: 1.1947 - val_accuracy: 0.0847\n",
      "Epoch 108/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5128 - accuracy: 0.0930 - val_loss: 1.2989 - val_accuracy: 0.0872\n",
      "Epoch 109/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5063 - accuracy: 0.0960 - val_loss: 1.1942 - val_accuracy: 0.0982\n",
      "Epoch 110/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5106 - accuracy: 0.0997 - val_loss: 1.2348 - val_accuracy: 0.0912\n",
      "Epoch 111/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5188 - accuracy: 0.0910 - val_loss: 1.2291 - val_accuracy: 0.0957\n",
      "Epoch 112/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5169 - accuracy: 0.0971 - val_loss: 1.2243 - val_accuracy: 0.0887\n",
      "Epoch 113/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5052 - accuracy: 0.1023 - val_loss: 1.2049 - val_accuracy: 0.0917\n",
      "Epoch 114/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5220 - accuracy: 0.0935 - val_loss: 1.2268 - val_accuracy: 0.0897\n",
      "Epoch 115/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5161 - accuracy: 0.0946 - val_loss: 1.1979 - val_accuracy: 0.0892\n",
      "Epoch 116/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5053 - accuracy: 0.0961 - val_loss: 1.2364 - val_accuracy: 0.0877\n",
      "Epoch 117/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5115 - accuracy: 0.0881 - val_loss: 1.2209 - val_accuracy: 0.0887\n",
      "Epoch 118/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5128 - accuracy: 0.0946 - val_loss: 1.2344 - val_accuracy: 0.0917\n",
      "Epoch 119/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5251 - accuracy: 0.0971 - val_loss: 1.1837 - val_accuracy: 0.0897\n",
      "Epoch 120/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5134 - accuracy: 0.0935 - val_loss: 1.2153 - val_accuracy: 0.0897\n",
      "Epoch 121/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5161 - accuracy: 0.0902 - val_loss: 1.1875 - val_accuracy: 0.0892\n",
      "Epoch 122/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5105 - accuracy: 0.0965 - val_loss: 1.3102 - val_accuracy: 0.0917\n",
      "Epoch 123/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5071 - accuracy: 0.0960 - val_loss: 1.2252 - val_accuracy: 0.0987\n",
      "Epoch 124/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5129 - accuracy: 0.0954 - val_loss: 1.2520 - val_accuracy: 0.0897\n",
      "Epoch 125/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5050 - accuracy: 0.0920 - val_loss: 1.1856 - val_accuracy: 0.0892\n",
      "Epoch 126/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4992 - accuracy: 0.0987 - val_loss: 1.2391 - val_accuracy: 0.0917\n",
      "Epoch 127/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5103 - accuracy: 0.0936 - val_loss: 1.3616 - val_accuracy: 0.0972\n",
      "Epoch 128/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5147 - accuracy: 0.1007 - val_loss: 1.2272 - val_accuracy: 0.0917\n",
      "Epoch 129/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5125 - accuracy: 0.0944 - val_loss: 1.1943 - val_accuracy: 0.0912\n",
      "Epoch 130/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5069 - accuracy: 0.0991 - val_loss: 1.2161 - val_accuracy: 0.0852\n",
      "Epoch 131/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5095 - accuracy: 0.0961 - val_loss: 1.1925 - val_accuracy: 0.0852\n",
      "Epoch 132/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5117 - accuracy: 0.0936 - val_loss: 1.2871 - val_accuracy: 0.0872\n",
      "Epoch 133/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5181 - accuracy: 0.0904 - val_loss: 1.2520 - val_accuracy: 0.0897\n",
      "Epoch 134/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5074 - accuracy: 0.0985 - val_loss: 1.2444 - val_accuracy: 0.0897\n",
      "Epoch 135/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5055 - accuracy: 0.0910 - val_loss: 1.2506 - val_accuracy: 0.0907\n",
      "Epoch 136/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5100 - accuracy: 0.0963 - val_loss: 1.2685 - val_accuracy: 0.0852\n",
      "Epoch 137/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4985 - accuracy: 0.0975 - val_loss: 1.3284 - val_accuracy: 0.0852\n",
      "Epoch 138/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5085 - accuracy: 0.0945 - val_loss: 1.2544 - val_accuracy: 0.1052\n",
      "Epoch 139/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5144 - accuracy: 0.0986 - val_loss: 1.2009 - val_accuracy: 0.0927\n",
      "Epoch 140/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5012 - accuracy: 0.0957 - val_loss: 1.2309 - val_accuracy: 0.1022\n",
      "Epoch 141/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5064 - accuracy: 0.0950 - val_loss: 1.3443 - val_accuracy: 0.1057\n",
      "Epoch 142/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5108 - accuracy: 0.0935 - val_loss: 1.1749 - val_accuracy: 0.0922\n",
      "Epoch 143/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5186 - accuracy: 0.0941 - val_loss: 1.2310 - val_accuracy: 0.1052\n",
      "Epoch 144/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5182 - accuracy: 0.0962 - val_loss: 1.2164 - val_accuracy: 0.0897\n",
      "Epoch 145/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5127 - accuracy: 0.0973 - val_loss: 1.2581 - val_accuracy: 0.0952\n",
      "Epoch 146/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5139 - accuracy: 0.0963 - val_loss: 1.2062 - val_accuracy: 0.1052\n",
      "Epoch 147/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5242 - accuracy: 0.0985 - val_loss: 1.2084 - val_accuracy: 0.0872\n",
      "Epoch 148/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5129 - accuracy: 0.0940 - val_loss: 1.2402 - val_accuracy: 0.0852\n",
      "Epoch 149/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5183 - accuracy: 0.0931 - val_loss: 1.1712 - val_accuracy: 0.0922\n",
      "Epoch 150/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5041 - accuracy: 0.0926 - val_loss: 1.3046 - val_accuracy: 0.0847\n",
      "Epoch 151/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5022 - accuracy: 0.0920 - val_loss: 1.2423 - val_accuracy: 0.0852\n",
      "Epoch 152/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5079 - accuracy: 0.0997 - val_loss: 1.2796 - val_accuracy: 0.0922\n",
      "Epoch 153/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5117 - accuracy: 0.1001 - val_loss: 1.2245 - val_accuracy: 0.0887\n",
      "Epoch 154/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5050 - accuracy: 0.0972 - val_loss: 1.2214 - val_accuracy: 0.0897\n",
      "Epoch 155/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5097 - accuracy: 0.0965 - val_loss: 1.2544 - val_accuracy: 0.0942\n",
      "Epoch 156/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4994 - accuracy: 0.0976 - val_loss: 1.2354 - val_accuracy: 0.1032\n",
      "Epoch 157/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5061 - accuracy: 0.0936 - val_loss: 1.1957 - val_accuracy: 0.0917\n",
      "Epoch 158/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5052 - accuracy: 0.0987 - val_loss: 1.1959 - val_accuracy: 0.0982\n",
      "Epoch 159/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5039 - accuracy: 0.0971 - val_loss: 1.2119 - val_accuracy: 0.0927\n",
      "Epoch 160/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4988 - accuracy: 0.0961 - val_loss: 1.2862 - val_accuracy: 0.1042\n",
      "Epoch 161/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5022 - accuracy: 0.0961 - val_loss: 1.2339 - val_accuracy: 0.0942\n",
      "Epoch 162/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5027 - accuracy: 0.0909 - val_loss: 1.2026 - val_accuracy: 0.0992\n",
      "Epoch 163/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5029 - accuracy: 0.0966 - val_loss: 1.1875 - val_accuracy: 0.1012\n",
      "Epoch 164/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5050 - accuracy: 0.0929 - val_loss: 1.2107 - val_accuracy: 0.0852\n",
      "Epoch 165/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5065 - accuracy: 0.0952 - val_loss: 1.2083 - val_accuracy: 0.0907\n",
      "Epoch 166/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5026 - accuracy: 0.0930 - val_loss: 1.2563 - val_accuracy: 0.0882\n",
      "Epoch 167/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5067 - accuracy: 0.1003 - val_loss: 1.1821 - val_accuracy: 0.0932\n",
      "Epoch 168/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5088 - accuracy: 0.0998 - val_loss: 1.2035 - val_accuracy: 0.1007\n",
      "Epoch 169/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5040 - accuracy: 0.0980 - val_loss: 1.1751 - val_accuracy: 0.0997\n",
      "Epoch 170/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5099 - accuracy: 0.0952 - val_loss: 1.2401 - val_accuracy: 0.0857\n",
      "Epoch 171/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4994 - accuracy: 0.0985 - val_loss: 1.2518 - val_accuracy: 0.0927\n",
      "Epoch 172/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5035 - accuracy: 0.1001 - val_loss: 1.2955 - val_accuracy: 0.0887\n",
      "Epoch 173/500\n",
      "8023/8023 [==============================] - 12s 2ms/step - loss: 1.5078 - accuracy: 0.0949 - val_loss: 1.1998 - val_accuracy: 0.0852\n",
      "Epoch 174/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5024 - accuracy: 0.0960 - val_loss: 1.2909 - val_accuracy: 0.0912\n",
      "Epoch 175/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5026 - accuracy: 0.1044 - val_loss: 1.3406 - val_accuracy: 0.0877\n",
      "Epoch 176/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5080 - accuracy: 0.0997 - val_loss: 1.2441 - val_accuracy: 0.0917\n",
      "Epoch 177/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5035 - accuracy: 0.0925 - val_loss: 1.2164 - val_accuracy: 0.1052\n",
      "Epoch 178/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4967 - accuracy: 0.0952 - val_loss: 1.2238 - val_accuracy: 0.0897\n",
      "Epoch 179/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5124 - accuracy: 0.0957 - val_loss: 1.2482 - val_accuracy: 0.1002\n",
      "Epoch 180/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5037 - accuracy: 0.0996 - val_loss: 1.2375 - val_accuracy: 0.0887\n",
      "Epoch 181/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5203 - accuracy: 0.0904 - val_loss: 1.1934 - val_accuracy: 0.0907\n",
      "Epoch 182/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5182 - accuracy: 0.0963 - val_loss: 1.2006 - val_accuracy: 0.1052\n",
      "Epoch 183/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5046 - accuracy: 0.0931 - val_loss: 1.2052 - val_accuracy: 0.0877\n",
      "Epoch 184/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4969 - accuracy: 0.0957 - val_loss: 1.2844 - val_accuracy: 0.0882\n",
      "Epoch 185/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4970 - accuracy: 0.1000 - val_loss: 1.2253 - val_accuracy: 0.0852\n",
      "Epoch 186/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4976 - accuracy: 0.0906 - val_loss: 1.2064 - val_accuracy: 0.0882\n",
      "Epoch 187/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5056 - accuracy: 0.0955 - val_loss: 1.2137 - val_accuracy: 0.0877\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5039 - accuracy: 0.0972 - val_loss: 1.3245 - val_accuracy: 0.0922\n",
      "Epoch 189/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5042 - accuracy: 0.0986 - val_loss: 1.2553 - val_accuracy: 0.0877\n",
      "Epoch 190/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4994 - accuracy: 0.0980 - val_loss: 1.2042 - val_accuracy: 0.0902\n",
      "Epoch 191/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5018 - accuracy: 0.1007 - val_loss: 1.2015 - val_accuracy: 0.0917\n",
      "Epoch 192/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4975 - accuracy: 0.1013 - val_loss: 1.2001 - val_accuracy: 0.0997\n",
      "Epoch 193/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5016 - accuracy: 0.0905 - val_loss: 1.2518 - val_accuracy: 0.1032\n",
      "Epoch 194/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5036 - accuracy: 0.1012 - val_loss: 1.2569 - val_accuracy: 0.0937\n",
      "Epoch 195/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5045 - accuracy: 0.1003 - val_loss: 1.2164 - val_accuracy: 0.0877\n",
      "Epoch 196/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.4974 - accuracy: 0.0936 - val_loss: 1.2067 - val_accuracy: 0.0852\n",
      "Epoch 197/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4957 - accuracy: 0.1006 - val_loss: 1.1914 - val_accuracy: 0.0862\n",
      "Epoch 198/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5000 - accuracy: 0.1002 - val_loss: 1.2325 - val_accuracy: 0.0897\n",
      "Epoch 199/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4999 - accuracy: 0.0961 - val_loss: 1.2879 - val_accuracy: 0.0932\n",
      "Epoch 200/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5047 - accuracy: 0.0968 - val_loss: 1.2868 - val_accuracy: 0.0902\n",
      "Epoch 201/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4927 - accuracy: 0.0983 - val_loss: 1.2072 - val_accuracy: 0.0932\n",
      "Epoch 202/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4993 - accuracy: 0.0975 - val_loss: 1.1916 - val_accuracy: 0.0932\n",
      "Epoch 203/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4909 - accuracy: 0.1033 - val_loss: 1.2240 - val_accuracy: 0.0877\n",
      "Epoch 204/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4964 - accuracy: 0.0957 - val_loss: 1.2402 - val_accuracy: 0.1052\n",
      "Epoch 205/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4983 - accuracy: 0.0916 - val_loss: 1.2045 - val_accuracy: 0.0932\n",
      "Epoch 206/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4961 - accuracy: 0.1010 - val_loss: 1.2266 - val_accuracy: 0.0852\n",
      "Epoch 207/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5008 - accuracy: 0.0995 - val_loss: 1.2508 - val_accuracy: 0.0847\n",
      "Epoch 208/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4996 - accuracy: 0.0972 - val_loss: 1.2172 - val_accuracy: 0.0937\n",
      "Epoch 209/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4977 - accuracy: 0.0951 - val_loss: 1.2845 - val_accuracy: 0.0892\n",
      "Epoch 210/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5118 - accuracy: 0.0925 - val_loss: 1.2984 - val_accuracy: 0.0897\n",
      "Epoch 211/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5151 - accuracy: 0.0920 - val_loss: 1.2353 - val_accuracy: 0.1002\n",
      "Epoch 212/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4946 - accuracy: 0.0939 - val_loss: 1.1883 - val_accuracy: 0.0897\n",
      "Epoch 213/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5026 - accuracy: 0.0949 - val_loss: 1.2211 - val_accuracy: 0.0912\n",
      "Epoch 214/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5050 - accuracy: 0.0951 - val_loss: 1.1838 - val_accuracy: 0.0897\n",
      "Epoch 215/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4979 - accuracy: 0.0985 - val_loss: 1.2159 - val_accuracy: 0.0902\n",
      "Epoch 216/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4958 - accuracy: 0.0896 - val_loss: 1.2848 - val_accuracy: 0.0917\n",
      "Epoch 217/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4970 - accuracy: 0.0919 - val_loss: 1.2246 - val_accuracy: 0.0957\n",
      "Epoch 218/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4927 - accuracy: 0.0956 - val_loss: 1.2348 - val_accuracy: 0.0837\n",
      "Epoch 219/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4960 - accuracy: 0.1006 - val_loss: 1.3068 - val_accuracy: 0.0952\n",
      "Epoch 220/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.5008 - accuracy: 0.0997 - val_loss: 1.2217 - val_accuracy: 0.0932\n",
      "Epoch 221/500\n",
      "8023/8023 [==============================] - 8s 993us/step - loss: 1.4969 - accuracy: 0.0987 - val_loss: 1.2024 - val_accuracy: 0.0892\n",
      "Epoch 222/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5013 - accuracy: 0.0966 - val_loss: 1.1907 - val_accuracy: 0.0897\n",
      "Epoch 223/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5034 - accuracy: 0.0914 - val_loss: 1.2002 - val_accuracy: 0.0887\n",
      "Epoch 224/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5051 - accuracy: 0.0992 - val_loss: 1.2001 - val_accuracy: 0.0977\n",
      "Epoch 225/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4941 - accuracy: 0.0972 - val_loss: 1.1852 - val_accuracy: 0.0942\n",
      "Epoch 226/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5017 - accuracy: 0.0954 - val_loss: 1.1993 - val_accuracy: 0.1002\n",
      "Epoch 227/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4980 - accuracy: 0.0950 - val_loss: 1.2174 - val_accuracy: 0.0847\n",
      "Epoch 228/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4999 - accuracy: 0.0929 - val_loss: 1.2864 - val_accuracy: 0.0887\n",
      "Epoch 229/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5013 - accuracy: 0.0909 - val_loss: 1.2428 - val_accuracy: 0.0852\n",
      "Epoch 230/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4920 - accuracy: 0.0940 - val_loss: 1.2329 - val_accuracy: 0.0947\n",
      "Epoch 231/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5042 - accuracy: 0.1013 - val_loss: 1.1963 - val_accuracy: 0.1022\n",
      "Epoch 232/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5027 - accuracy: 0.0983 - val_loss: 1.3326 - val_accuracy: 0.0892\n",
      "Epoch 233/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4920 - accuracy: 0.0980 - val_loss: 1.4653 - val_accuracy: 0.0842\n",
      "Epoch 234/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5000 - accuracy: 0.0950 - val_loss: 1.2283 - val_accuracy: 0.0947\n",
      "Epoch 235/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4975 - accuracy: 0.0993 - val_loss: 1.2702 - val_accuracy: 0.0912\n",
      "Epoch 236/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4949 - accuracy: 0.0879 - val_loss: 1.1805 - val_accuracy: 0.1047\n",
      "Epoch 237/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4898 - accuracy: 0.1002 - val_loss: 1.2652 - val_accuracy: 0.0897\n",
      "Epoch 238/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4948 - accuracy: 0.0936 - val_loss: 1.2599 - val_accuracy: 0.0837\n",
      "Epoch 239/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4980 - accuracy: 0.0992 - val_loss: 1.1937 - val_accuracy: 0.1002\n",
      "Epoch 240/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4909 - accuracy: 0.0980 - val_loss: 1.2243 - val_accuracy: 0.0942\n",
      "Epoch 241/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4918 - accuracy: 0.1010 - val_loss: 1.2289 - val_accuracy: 0.1052\n",
      "Epoch 242/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4946 - accuracy: 0.0965 - val_loss: 1.2617 - val_accuracy: 0.0867\n",
      "Epoch 243/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4864 - accuracy: 0.0995 - val_loss: 1.2175 - val_accuracy: 0.0932\n",
      "Epoch 244/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5106 - accuracy: 0.1018 - val_loss: 1.1982 - val_accuracy: 0.0877\n",
      "Epoch 245/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4983 - accuracy: 0.0960 - val_loss: 1.1857 - val_accuracy: 0.0907\n",
      "Epoch 246/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4942 - accuracy: 0.1001 - val_loss: 1.2253 - val_accuracy: 0.0937\n",
      "Epoch 247/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4899 - accuracy: 0.0907 - val_loss: 1.2103 - val_accuracy: 0.0867\n",
      "Epoch 248/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4937 - accuracy: 0.0914 - val_loss: 1.1924 - val_accuracy: 0.1002\n",
      "Epoch 249/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5025 - accuracy: 0.0924 - val_loss: 1.2544 - val_accuracy: 0.1047\n",
      "Epoch 250/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4972 - accuracy: 0.0960 - val_loss: 1.2248 - val_accuracy: 0.0917\n",
      "Epoch 251/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4978 - accuracy: 0.0966 - val_loss: 1.2129 - val_accuracy: 0.0847\n",
      "Epoch 252/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4904 - accuracy: 0.0917 - val_loss: 1.2023 - val_accuracy: 0.0902\n",
      "Epoch 253/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5050 - accuracy: 0.0961 - val_loss: 1.2347 - val_accuracy: 0.0847\n",
      "Epoch 254/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4877 - accuracy: 0.0899 - val_loss: 1.2273 - val_accuracy: 0.1047\n",
      "Epoch 255/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4912 - accuracy: 0.0900 - val_loss: 1.2165 - val_accuracy: 0.0877\n",
      "Epoch 256/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4989 - accuracy: 0.0977 - val_loss: 1.2379 - val_accuracy: 0.0852\n",
      "Epoch 257/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.5035 - accuracy: 0.0967 - val_loss: 1.2721 - val_accuracy: 0.0857\n",
      "Epoch 258/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5033 - accuracy: 0.0971 - val_loss: 1.2064 - val_accuracy: 0.0852\n",
      "Epoch 259/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4957 - accuracy: 0.0951 - val_loss: 1.3289 - val_accuracy: 0.0927\n",
      "Epoch 260/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4929 - accuracy: 0.0970 - val_loss: 1.3056 - val_accuracy: 0.1052\n",
      "Epoch 261/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4874 - accuracy: 0.0946 - val_loss: 1.1795 - val_accuracy: 0.0942\n",
      "Epoch 262/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4908 - accuracy: 0.0947 - val_loss: 1.1967 - val_accuracy: 0.0937\n",
      "Epoch 263/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4902 - accuracy: 0.0976 - val_loss: 1.2158 - val_accuracy: 0.0922\n",
      "Epoch 264/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4908 - accuracy: 0.0976 - val_loss: 1.1904 - val_accuracy: 0.0937\n",
      "Epoch 265/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4894 - accuracy: 0.0997 - val_loss: 1.2789 - val_accuracy: 0.0882\n",
      "Epoch 266/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4922 - accuracy: 0.0977 - val_loss: 1.2163 - val_accuracy: 0.1032\n",
      "Epoch 267/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4939 - accuracy: 0.0934 - val_loss: 1.2103 - val_accuracy: 0.1127\n",
      "Epoch 268/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5005 - accuracy: 0.0932 - val_loss: 1.2101 - val_accuracy: 0.1042\n",
      "Epoch 269/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5036 - accuracy: 0.0966 - val_loss: 1.2443 - val_accuracy: 0.1052\n",
      "Epoch 270/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4918 - accuracy: 0.0960 - val_loss: 1.2461 - val_accuracy: 0.0852\n",
      "Epoch 271/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.5034 - accuracy: 0.0899 - val_loss: 1.2233 - val_accuracy: 0.0902\n",
      "Epoch 272/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4884 - accuracy: 0.0932 - val_loss: 1.1898 - val_accuracy: 0.0912\n",
      "Epoch 273/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4901 - accuracy: 0.0978 - val_loss: 1.2364 - val_accuracy: 0.0867\n",
      "Epoch 274/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4909 - accuracy: 0.0976 - val_loss: 1.2653 - val_accuracy: 0.1052\n",
      "Epoch 275/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4906 - accuracy: 0.0985 - val_loss: 1.2196 - val_accuracy: 0.0852\n",
      "Epoch 276/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4929 - accuracy: 0.0904 - val_loss: 1.1772 - val_accuracy: 0.1002\n",
      "Epoch 277/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4959 - accuracy: 0.0935 - val_loss: 1.2169 - val_accuracy: 0.0897\n",
      "Epoch 278/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4878 - accuracy: 0.0981 - val_loss: 1.2644 - val_accuracy: 0.1002\n",
      "Epoch 279/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4907 - accuracy: 0.0975 - val_loss: 1.2381 - val_accuracy: 0.0912\n",
      "Epoch 280/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4983 - accuracy: 0.0950 - val_loss: 1.1906 - val_accuracy: 0.1052\n",
      "Epoch 281/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.5000 - accuracy: 0.0927 - val_loss: 1.2520 - val_accuracy: 0.0982\n",
      "Epoch 282/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4936 - accuracy: 0.0897 - val_loss: 1.2140 - val_accuracy: 0.0927\n",
      "Epoch 283/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4876 - accuracy: 0.0914 - val_loss: 1.1806 - val_accuracy: 0.0912\n",
      "Epoch 284/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4876 - accuracy: 0.0975 - val_loss: 1.2041 - val_accuracy: 0.0952\n",
      "Epoch 285/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4861 - accuracy: 0.0983 - val_loss: 1.2420 - val_accuracy: 0.0902\n",
      "Epoch 286/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4884 - accuracy: 0.0972 - val_loss: 1.2605 - val_accuracy: 0.1052\n",
      "Epoch 287/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4843 - accuracy: 0.0960 - val_loss: 1.2078 - val_accuracy: 0.1057\n",
      "Epoch 288/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4872 - accuracy: 0.0981 - val_loss: 1.2293 - val_accuracy: 0.1052\n",
      "Epoch 289/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4940 - accuracy: 0.0951 - val_loss: 1.2153 - val_accuracy: 0.0932\n",
      "Epoch 290/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4915 - accuracy: 0.0917 - val_loss: 1.2074 - val_accuracy: 0.0902\n",
      "Epoch 291/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4884 - accuracy: 0.0996 - val_loss: 1.1874 - val_accuracy: 0.0907\n",
      "Epoch 292/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4836 - accuracy: 0.0926 - val_loss: 1.2325 - val_accuracy: 0.0877\n",
      "Epoch 293/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4859 - accuracy: 0.0997 - val_loss: 1.2015 - val_accuracy: 0.0912\n",
      "Epoch 294/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4877 - accuracy: 0.0968 - val_loss: 1.2382 - val_accuracy: 0.0897\n",
      "Epoch 295/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4898 - accuracy: 0.0962 - val_loss: 1.2502 - val_accuracy: 0.0947\n",
      "Epoch 296/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4914 - accuracy: 0.1020 - val_loss: 1.2191 - val_accuracy: 0.0882\n",
      "Epoch 297/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4845 - accuracy: 0.0982 - val_loss: 1.2262 - val_accuracy: 0.1002\n",
      "Epoch 298/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4815 - accuracy: 0.0990 - val_loss: 1.2384 - val_accuracy: 0.0912\n",
      "Epoch 299/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4920 - accuracy: 0.0987 - val_loss: 1.2397 - val_accuracy: 0.1012\n",
      "Epoch 300/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4863 - accuracy: 0.0973 - val_loss: 1.2239 - val_accuracy: 0.0877\n",
      "Epoch 301/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4868 - accuracy: 0.0972 - val_loss: 1.1759 - val_accuracy: 0.0932\n",
      "Epoch 302/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4854 - accuracy: 0.0880 - val_loss: 1.2158 - val_accuracy: 0.0867\n",
      "Epoch 303/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4823 - accuracy: 0.0936 - val_loss: 1.2282 - val_accuracy: 0.0917\n",
      "Epoch 304/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4867 - accuracy: 0.0945 - val_loss: 1.2082 - val_accuracy: 0.1057\n",
      "Epoch 305/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4824 - accuracy: 0.0971 - val_loss: 1.1877 - val_accuracy: 0.0947\n",
      "Epoch 306/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4878 - accuracy: 0.0956 - val_loss: 1.2637 - val_accuracy: 0.0877\n",
      "Epoch 307/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4897 - accuracy: 0.1018 - val_loss: 1.2486 - val_accuracy: 0.0862\n",
      "Epoch 308/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4952 - accuracy: 0.0916 - val_loss: 1.1904 - val_accuracy: 0.0877\n",
      "Epoch 309/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4855 - accuracy: 0.0926 - val_loss: 1.2109 - val_accuracy: 0.0907\n",
      "Epoch 310/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4950 - accuracy: 0.0986 - val_loss: 1.2108 - val_accuracy: 0.0902\n",
      "Epoch 311/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4873 - accuracy: 0.0985 - val_loss: 1.1867 - val_accuracy: 0.0922\n",
      "Epoch 312/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4814 - accuracy: 0.0905 - val_loss: 1.2043 - val_accuracy: 0.0922\n",
      "Epoch 313/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4915 - accuracy: 0.0995 - val_loss: 1.2016 - val_accuracy: 0.0962\n",
      "Epoch 314/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4889 - accuracy: 0.0985 - val_loss: 1.1779 - val_accuracy: 0.1012\n",
      "Epoch 315/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4821 - accuracy: 0.1037 - val_loss: 1.1919 - val_accuracy: 0.0857\n",
      "Epoch 316/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4748 - accuracy: 0.0971 - val_loss: 1.1822 - val_accuracy: 0.0897\n",
      "Epoch 317/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4888 - accuracy: 0.1017 - val_loss: 1.2263 - val_accuracy: 0.1057\n",
      "Epoch 318/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4889 - accuracy: 0.0977 - val_loss: 1.2879 - val_accuracy: 0.0917\n",
      "Epoch 319/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4788 - accuracy: 0.0966 - val_loss: 1.1829 - val_accuracy: 0.0912\n",
      "Epoch 320/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4818 - accuracy: 0.1007 - val_loss: 1.2187 - val_accuracy: 0.0892\n",
      "Epoch 321/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4927 - accuracy: 0.0917 - val_loss: 1.1986 - val_accuracy: 0.1022\n",
      "Epoch 322/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4834 - accuracy: 0.0954 - val_loss: 1.2645 - val_accuracy: 0.0942\n",
      "Epoch 323/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4856 - accuracy: 0.0939 - val_loss: 1.2036 - val_accuracy: 0.0852\n",
      "Epoch 324/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4868 - accuracy: 0.1005 - val_loss: 1.2149 - val_accuracy: 0.0907\n",
      "Epoch 325/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4832 - accuracy: 0.1011 - val_loss: 1.2060 - val_accuracy: 0.1052\n",
      "Epoch 326/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4828 - accuracy: 0.1011 - val_loss: 1.2213 - val_accuracy: 0.0932\n",
      "Epoch 327/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4797 - accuracy: 0.0958 - val_loss: 1.2470 - val_accuracy: 0.0872\n",
      "Epoch 328/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4784 - accuracy: 0.1025 - val_loss: 1.2251 - val_accuracy: 0.0997\n",
      "Epoch 329/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4829 - accuracy: 0.0977 - val_loss: 1.1992 - val_accuracy: 0.0907\n",
      "Epoch 330/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4927 - accuracy: 0.0932 - val_loss: 1.2283 - val_accuracy: 0.0862\n",
      "Epoch 331/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4846 - accuracy: 0.0937 - val_loss: 1.2551 - val_accuracy: 0.0892\n",
      "Epoch 332/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4846 - accuracy: 0.0950 - val_loss: 1.2170 - val_accuracy: 0.0907\n",
      "Epoch 333/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4901 - accuracy: 0.0944 - val_loss: 1.2312 - val_accuracy: 0.0937\n",
      "Epoch 334/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4890 - accuracy: 0.0967 - val_loss: 1.2113 - val_accuracy: 0.0917\n",
      "Epoch 335/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4835 - accuracy: 0.1023 - val_loss: 1.1913 - val_accuracy: 0.0882\n",
      "Epoch 336/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4820 - accuracy: 0.1027 - val_loss: 1.2058 - val_accuracy: 0.0997\n",
      "Epoch 337/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4784 - accuracy: 0.0980 - val_loss: 1.2054 - val_accuracy: 0.0887\n",
      "Epoch 338/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4794 - accuracy: 0.0966 - val_loss: 1.1973 - val_accuracy: 0.1052\n",
      "Epoch 339/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4771 - accuracy: 0.1006 - val_loss: 1.1915 - val_accuracy: 0.1052\n",
      "Epoch 340/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4768 - accuracy: 0.0957 - val_loss: 1.2239 - val_accuracy: 0.0862\n",
      "Epoch 341/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4786 - accuracy: 0.1005 - val_loss: 1.2482 - val_accuracy: 0.0882\n",
      "Epoch 342/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4836 - accuracy: 0.0962 - val_loss: 1.1997 - val_accuracy: 0.0912\n",
      "Epoch 343/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4825 - accuracy: 0.1017 - val_loss: 1.2328 - val_accuracy: 0.0892\n",
      "Epoch 344/500\n",
      "8023/8023 [==============================] - 12s 2ms/step - loss: 1.4805 - accuracy: 0.1002 - val_loss: 1.2416 - val_accuracy: 0.0872\n",
      "Epoch 345/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4848 - accuracy: 0.1032 - val_loss: 1.1808 - val_accuracy: 0.1002\n",
      "Epoch 346/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4816 - accuracy: 0.0993 - val_loss: 1.2667 - val_accuracy: 0.1057\n",
      "Epoch 347/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.4779 - accuracy: 0.1008 - val_loss: 1.2258 - val_accuracy: 0.0862\n",
      "Epoch 348/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4802 - accuracy: 0.0954 - val_loss: 1.2222 - val_accuracy: 0.0902\n",
      "Epoch 349/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4740 - accuracy: 0.1062 - val_loss: 1.1836 - val_accuracy: 0.0862\n",
      "Epoch 350/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4822 - accuracy: 0.0971 - val_loss: 1.2421 - val_accuracy: 0.0877\n",
      "Epoch 351/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4808 - accuracy: 0.0958 - val_loss: 1.2241 - val_accuracy: 0.0932\n",
      "Epoch 352/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4753 - accuracy: 0.1012 - val_loss: 1.2189 - val_accuracy: 0.0922\n",
      "Epoch 353/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4724 - accuracy: 0.0957 - val_loss: 1.2144 - val_accuracy: 0.0912\n",
      "Epoch 354/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4758 - accuracy: 0.1016 - val_loss: 1.1986 - val_accuracy: 0.0922\n",
      "Epoch 355/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4710 - accuracy: 0.1002 - val_loss: 1.1909 - val_accuracy: 0.0907\n",
      "Epoch 356/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4736 - accuracy: 0.0932 - val_loss: 1.2207 - val_accuracy: 0.0862\n",
      "Epoch 357/500\n",
      "8023/8023 [==============================] - 12s 2ms/step - loss: 1.4768 - accuracy: 0.1018 - val_loss: 1.2584 - val_accuracy: 0.0917\n",
      "Epoch 358/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4789 - accuracy: 0.0957 - val_loss: 1.2097 - val_accuracy: 0.0867\n",
      "Epoch 359/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4827 - accuracy: 0.0997 - val_loss: 1.2842 - val_accuracy: 0.0852\n",
      "Epoch 360/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4847 - accuracy: 0.0941 - val_loss: 1.2066 - val_accuracy: 0.0897\n",
      "Epoch 361/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4709 - accuracy: 0.1036 - val_loss: 1.2619 - val_accuracy: 0.0897\n",
      "Epoch 362/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4791 - accuracy: 0.1008 - val_loss: 1.2130 - val_accuracy: 0.0887\n",
      "Epoch 363/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4723 - accuracy: 0.0980 - val_loss: 1.2092 - val_accuracy: 0.0902\n",
      "Epoch 364/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.4718 - accuracy: 0.0946 - val_loss: 1.2594 - val_accuracy: 0.0932\n",
      "Epoch 365/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.4705 - accuracy: 0.0949 - val_loss: 1.2197 - val_accuracy: 0.0952\n",
      "Epoch 366/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4731 - accuracy: 0.1040 - val_loss: 1.1743 - val_accuracy: 0.0972\n",
      "Epoch 367/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4754 - accuracy: 0.1068 - val_loss: 1.2042 - val_accuracy: 0.0952\n",
      "Epoch 368/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4739 - accuracy: 0.0960 - val_loss: 1.1894 - val_accuracy: 0.1007\n",
      "Epoch 369/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4742 - accuracy: 0.1000 - val_loss: 1.2777 - val_accuracy: 0.1052\n",
      "Epoch 370/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4802 - accuracy: 0.1005 - val_loss: 1.2267 - val_accuracy: 0.0852\n",
      "Epoch 371/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4740 - accuracy: 0.1036 - val_loss: 1.2335 - val_accuracy: 0.0927\n",
      "Epoch 372/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4710 - accuracy: 0.1018 - val_loss: 1.1974 - val_accuracy: 0.0907\n",
      "Epoch 373/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4737 - accuracy: 0.1013 - val_loss: 1.2601 - val_accuracy: 0.0862\n",
      "Epoch 374/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4663 - accuracy: 0.0996 - val_loss: 1.2087 - val_accuracy: 0.0947\n",
      "Epoch 375/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4698 - accuracy: 0.0956 - val_loss: 1.2130 - val_accuracy: 0.1052\n",
      "Epoch 376/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4743 - accuracy: 0.0992 - val_loss: 1.1978 - val_accuracy: 0.0957\n",
      "Epoch 377/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4756 - accuracy: 0.0963 - val_loss: 1.1738 - val_accuracy: 0.0862\n",
      "Epoch 378/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4781 - accuracy: 0.0957 - val_loss: 1.1912 - val_accuracy: 0.0877\n",
      "Epoch 379/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4765 - accuracy: 0.0997 - val_loss: 1.1827 - val_accuracy: 0.0912\n",
      "Epoch 380/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.4760 - accuracy: 0.1016 - val_loss: 1.2324 - val_accuracy: 0.0867\n",
      "Epoch 381/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4759 - accuracy: 0.1001 - val_loss: 1.2714 - val_accuracy: 0.0982\n",
      "Epoch 382/500\n",
      "8023/8023 [==============================] - 12s 1ms/step - loss: 1.4861 - accuracy: 0.1073 - val_loss: 1.2547 - val_accuracy: 0.0892\n",
      "Epoch 383/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4743 - accuracy: 0.0946 - val_loss: 1.1837 - val_accuracy: 0.0932\n",
      "Epoch 384/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4739 - accuracy: 0.0990 - val_loss: 1.1816 - val_accuracy: 0.0867\n",
      "Epoch 385/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4701 - accuracy: 0.0967 - val_loss: 1.2232 - val_accuracy: 0.0882\n",
      "Epoch 386/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4685 - accuracy: 0.0982 - val_loss: 1.2144 - val_accuracy: 0.0937\n",
      "Epoch 387/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4731 - accuracy: 0.0976 - val_loss: 1.2672 - val_accuracy: 0.0907\n",
      "Epoch 388/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4735 - accuracy: 0.0954 - val_loss: 1.2404 - val_accuracy: 0.0902\n",
      "Epoch 389/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4742 - accuracy: 0.0965 - val_loss: 1.2110 - val_accuracy: 0.0897\n",
      "Epoch 390/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4754 - accuracy: 0.1022 - val_loss: 1.2223 - val_accuracy: 0.0892\n",
      "Epoch 391/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4777 - accuracy: 0.1026 - val_loss: 1.1873 - val_accuracy: 0.0937\n",
      "Epoch 392/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4702 - accuracy: 0.0965 - val_loss: 1.3172 - val_accuracy: 0.1007\n",
      "Epoch 393/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4700 - accuracy: 0.0937 - val_loss: 1.2020 - val_accuracy: 0.0927\n",
      "Epoch 394/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4694 - accuracy: 0.1037 - val_loss: 1.2346 - val_accuracy: 0.1042\n",
      "Epoch 395/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4768 - accuracy: 0.1000 - val_loss: 1.2238 - val_accuracy: 0.0932\n",
      "Epoch 396/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4718 - accuracy: 0.1015 - val_loss: 1.1994 - val_accuracy: 0.1012\n",
      "Epoch 397/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4759 - accuracy: 0.0975 - val_loss: 1.2177 - val_accuracy: 0.0927\n",
      "Epoch 398/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4712 - accuracy: 0.0963 - val_loss: 1.1952 - val_accuracy: 0.0917\n",
      "Epoch 399/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4793 - accuracy: 0.0945 - val_loss: 1.2308 - val_accuracy: 0.0942\n",
      "Epoch 400/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4764 - accuracy: 0.1011 - val_loss: 1.1936 - val_accuracy: 0.0837\n",
      "Epoch 401/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4698 - accuracy: 0.0990 - val_loss: 1.2188 - val_accuracy: 0.0872\n",
      "Epoch 402/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4735 - accuracy: 0.0990 - val_loss: 1.2235 - val_accuracy: 0.0942\n",
      "Epoch 403/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4779 - accuracy: 0.1042 - val_loss: 1.2037 - val_accuracy: 0.0952\n",
      "Epoch 404/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4704 - accuracy: 0.0986 - val_loss: 1.2100 - val_accuracy: 0.0917\n",
      "Epoch 405/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4667 - accuracy: 0.1020 - val_loss: 1.2364 - val_accuracy: 0.0927\n",
      "Epoch 406/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4797 - accuracy: 0.0960 - val_loss: 1.2023 - val_accuracy: 0.0922\n",
      "Epoch 407/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4620 - accuracy: 0.0930 - val_loss: 1.1847 - val_accuracy: 0.1052\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4777 - accuracy: 0.0996 - val_loss: 1.2161 - val_accuracy: 0.0887\n",
      "Epoch 409/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4780 - accuracy: 0.1010 - val_loss: 1.2005 - val_accuracy: 0.0932\n",
      "Epoch 410/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4715 - accuracy: 0.0931 - val_loss: 1.2032 - val_accuracy: 0.1022\n",
      "Epoch 411/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4682 - accuracy: 0.1041 - val_loss: 1.2805 - val_accuracy: 0.0872\n",
      "Epoch 412/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4719 - accuracy: 0.0990 - val_loss: 1.2910 - val_accuracy: 0.0852\n",
      "Epoch 413/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4701 - accuracy: 0.1025 - val_loss: 1.2299 - val_accuracy: 0.0902\n",
      "Epoch 414/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4704 - accuracy: 0.1027 - val_loss: 1.2696 - val_accuracy: 0.1052\n",
      "Epoch 415/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4786 - accuracy: 0.0949 - val_loss: 1.2599 - val_accuracy: 0.0912\n",
      "Epoch 416/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4720 - accuracy: 0.1018 - val_loss: 1.2670 - val_accuracy: 0.1037\n",
      "Epoch 417/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4637 - accuracy: 0.0968 - val_loss: 1.2187 - val_accuracy: 0.0992\n",
      "Epoch 418/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4802 - accuracy: 0.0972 - val_loss: 1.2273 - val_accuracy: 0.0877\n",
      "Epoch 419/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4725 - accuracy: 0.0956 - val_loss: 1.2097 - val_accuracy: 0.0912\n",
      "Epoch 420/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4797 - accuracy: 0.0952 - val_loss: 1.2002 - val_accuracy: 0.0902\n",
      "Epoch 421/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4721 - accuracy: 0.1030 - val_loss: 1.2267 - val_accuracy: 0.0907\n",
      "Epoch 422/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4653 - accuracy: 0.1008 - val_loss: 1.1887 - val_accuracy: 0.0927\n",
      "Epoch 423/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4713 - accuracy: 0.1003 - val_loss: 1.2368 - val_accuracy: 0.0852\n",
      "Epoch 424/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4730 - accuracy: 0.0992 - val_loss: 1.2314 - val_accuracy: 0.0997\n",
      "Epoch 425/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4718 - accuracy: 0.0985 - val_loss: 1.2169 - val_accuracy: 0.0847\n",
      "Epoch 426/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4719 - accuracy: 0.0967 - val_loss: 1.2058 - val_accuracy: 0.1052\n",
      "Epoch 427/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4761 - accuracy: 0.1054 - val_loss: 1.2271 - val_accuracy: 0.0862\n",
      "Epoch 428/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4662 - accuracy: 0.0986 - val_loss: 1.2329 - val_accuracy: 0.0942\n",
      "Epoch 429/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4720 - accuracy: 0.0961 - val_loss: 1.2075 - val_accuracy: 0.0982\n",
      "Epoch 430/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4729 - accuracy: 0.0975 - val_loss: 1.2153 - val_accuracy: 0.1007\n",
      "Epoch 431/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4686 - accuracy: 0.1022 - val_loss: 1.1924 - val_accuracy: 0.0912\n",
      "Epoch 432/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4701 - accuracy: 0.1005 - val_loss: 1.1746 - val_accuracy: 0.0852\n",
      "Epoch 433/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4796 - accuracy: 0.0985 - val_loss: 1.2554 - val_accuracy: 0.0877\n",
      "Epoch 434/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4737 - accuracy: 0.1076 - val_loss: 1.2232 - val_accuracy: 0.0917\n",
      "Epoch 435/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4694 - accuracy: 0.0995 - val_loss: 1.2009 - val_accuracy: 0.0887\n",
      "Epoch 436/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4659 - accuracy: 0.1003 - val_loss: 1.2778 - val_accuracy: 0.0877\n",
      "Epoch 437/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4740 - accuracy: 0.1015 - val_loss: 1.2067 - val_accuracy: 0.0977\n",
      "Epoch 438/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4720 - accuracy: 0.1042 - val_loss: 1.1909 - val_accuracy: 0.0892\n",
      "Epoch 439/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4689 - accuracy: 0.0958 - val_loss: 1.1728 - val_accuracy: 0.0917\n",
      "Epoch 440/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4669 - accuracy: 0.0968 - val_loss: 1.2354 - val_accuracy: 0.0902\n",
      "Epoch 441/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4678 - accuracy: 0.0935 - val_loss: 1.1723 - val_accuracy: 0.0877\n",
      "Epoch 442/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4692 - accuracy: 0.1021 - val_loss: 1.2006 - val_accuracy: 0.0847\n",
      "Epoch 443/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4675 - accuracy: 0.1016 - val_loss: 1.2091 - val_accuracy: 0.0892\n",
      "Epoch 444/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4770 - accuracy: 0.0973 - val_loss: 1.2355 - val_accuracy: 0.0867\n",
      "Epoch 445/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4675 - accuracy: 0.0992 - val_loss: 1.2045 - val_accuracy: 0.0937\n",
      "Epoch 446/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4656 - accuracy: 0.0988 - val_loss: 1.2817 - val_accuracy: 0.1067\n",
      "Epoch 447/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4761 - accuracy: 0.1007 - val_loss: 1.2868 - val_accuracy: 0.0992\n",
      "Epoch 448/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4774 - accuracy: 0.0945 - val_loss: 1.2009 - val_accuracy: 0.0882\n",
      "Epoch 449/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4719 - accuracy: 0.0946 - val_loss: 1.2130 - val_accuracy: 0.0867\n",
      "Epoch 450/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4639 - accuracy: 0.0975 - val_loss: 1.2369 - val_accuracy: 0.0847\n",
      "Epoch 451/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4707 - accuracy: 0.1051 - val_loss: 1.1959 - val_accuracy: 0.0882\n",
      "Epoch 452/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4809 - accuracy: 0.0936 - val_loss: 1.2364 - val_accuracy: 0.0977\n",
      "Epoch 453/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4704 - accuracy: 0.1027 - val_loss: 1.2426 - val_accuracy: 0.0992\n",
      "Epoch 454/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4701 - accuracy: 0.0965 - val_loss: 1.2454 - val_accuracy: 0.0997\n",
      "Epoch 455/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4643 - accuracy: 0.0991 - val_loss: 1.2426 - val_accuracy: 0.0917\n",
      "Epoch 456/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4751 - accuracy: 0.0946 - val_loss: 1.2311 - val_accuracy: 0.0932\n",
      "Epoch 457/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4668 - accuracy: 0.1026 - val_loss: 1.2222 - val_accuracy: 0.0892\n",
      "Epoch 458/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4677 - accuracy: 0.0988 - val_loss: 1.2162 - val_accuracy: 0.0912\n",
      "Epoch 459/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4644 - accuracy: 0.1067 - val_loss: 1.2252 - val_accuracy: 0.0907\n",
      "Epoch 460/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4705 - accuracy: 0.1011 - val_loss: 1.2003 - val_accuracy: 0.0957\n",
      "Epoch 461/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4650 - accuracy: 0.1031 - val_loss: 1.1786 - val_accuracy: 0.0912\n",
      "Epoch 462/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4690 - accuracy: 0.0966 - val_loss: 1.1884 - val_accuracy: 0.0847\n",
      "Epoch 463/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4613 - accuracy: 0.0992 - val_loss: 1.1953 - val_accuracy: 0.0887\n",
      "Epoch 464/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4641 - accuracy: 0.0966 - val_loss: 1.1978 - val_accuracy: 0.0872\n",
      "Epoch 465/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4626 - accuracy: 0.1022 - val_loss: 1.1945 - val_accuracy: 0.0842\n",
      "Epoch 466/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4642 - accuracy: 0.1054 - val_loss: 1.2245 - val_accuracy: 0.0937\n",
      "Epoch 467/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4681 - accuracy: 0.1068 - val_loss: 1.2094 - val_accuracy: 0.0932\n",
      "Epoch 468/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4702 - accuracy: 0.1047 - val_loss: 1.2017 - val_accuracy: 0.1052\n",
      "Epoch 469/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4653 - accuracy: 0.0998 - val_loss: 1.2243 - val_accuracy: 0.0922\n",
      "Epoch 470/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4722 - accuracy: 0.1073 - val_loss: 1.2149 - val_accuracy: 0.0942\n",
      "Epoch 471/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4885 - accuracy: 0.0975 - val_loss: 1.2257 - val_accuracy: 0.0907\n",
      "Epoch 472/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4748 - accuracy: 0.1005 - val_loss: 1.3452 - val_accuracy: 0.0907\n",
      "Epoch 473/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4644 - accuracy: 0.0917 - val_loss: 1.1745 - val_accuracy: 0.0892\n",
      "Epoch 474/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4643 - accuracy: 0.1033 - val_loss: 1.2330 - val_accuracy: 0.0922\n",
      "Epoch 475/500\n",
      "8023/8023 [==============================] - 8s 998us/step - loss: 1.4665 - accuracy: 0.0981 - val_loss: 1.2368 - val_accuracy: 0.1052\n",
      "Epoch 476/500\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 1.4679 - accuracy: 0.0961 - val_loss: 1.2321 - val_accuracy: 0.0897\n",
      "Epoch 477/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4794 - accuracy: 0.1023 - val_loss: 1.2199 - val_accuracy: 0.0892\n",
      "Epoch 478/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4677 - accuracy: 0.1012 - val_loss: 1.1849 - val_accuracy: 0.0962\n",
      "Epoch 479/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4705 - accuracy: 0.0980 - val_loss: 1.1965 - val_accuracy: 0.0887\n",
      "Epoch 480/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4775 - accuracy: 0.1006 - val_loss: 1.2559 - val_accuracy: 0.0872\n",
      "Epoch 481/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4625 - accuracy: 0.0927 - val_loss: 1.2161 - val_accuracy: 0.1022\n",
      "Epoch 482/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4707 - accuracy: 0.1017 - val_loss: 1.2252 - val_accuracy: 0.0927\n",
      "Epoch 483/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4709 - accuracy: 0.0981 - val_loss: 1.2727 - val_accuracy: 0.0947\n",
      "Epoch 484/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4680 - accuracy: 0.1028 - val_loss: 1.1845 - val_accuracy: 0.0902\n",
      "Epoch 485/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4694 - accuracy: 0.1002 - val_loss: 1.2375 - val_accuracy: 0.0917\n",
      "Epoch 486/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4696 - accuracy: 0.1028 - val_loss: 1.1907 - val_accuracy: 0.1057\n",
      "Epoch 487/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4649 - accuracy: 0.1001 - val_loss: 1.2081 - val_accuracy: 0.0862\n",
      "Epoch 488/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4620 - accuracy: 0.1015 - val_loss: 1.2187 - val_accuracy: 0.0877\n",
      "Epoch 489/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4646 - accuracy: 0.0965 - val_loss: 1.1954 - val_accuracy: 0.1052\n",
      "Epoch 490/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4670 - accuracy: 0.0988 - val_loss: 1.1911 - val_accuracy: 0.0912\n",
      "Epoch 491/500\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 1.4759 - accuracy: 0.0965 - val_loss: 1.1892 - val_accuracy: 0.0892\n",
      "Epoch 492/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4636 - accuracy: 0.1021 - val_loss: 1.1839 - val_accuracy: 0.1052\n",
      "Epoch 493/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4670 - accuracy: 0.1054 - val_loss: 1.1894 - val_accuracy: 0.0867\n",
      "Epoch 494/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4639 - accuracy: 0.0961 - val_loss: 1.2053 - val_accuracy: 0.1052\n",
      "Epoch 495/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4646 - accuracy: 0.1022 - val_loss: 1.1695 - val_accuracy: 0.1012\n",
      "Epoch 496/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4661 - accuracy: 0.0961 - val_loss: 1.2365 - val_accuracy: 0.0912\n",
      "Epoch 497/500\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 1.4616 - accuracy: 0.0965 - val_loss: 1.1910 - val_accuracy: 0.0892\n",
      "Epoch 498/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4674 - accuracy: 0.0985 - val_loss: 1.2302 - val_accuracy: 0.0907\n",
      "Epoch 499/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4625 - accuracy: 0.0966 - val_loss: 1.2109 - val_accuracy: 0.0957\n",
      "Epoch 500/500\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 1.4621 - accuracy: 0.1017 - val_loss: 1.1959 - val_accuracy: 0.0907\n",
      "the NMAE for epochs= 500 is: ReadsAvg    0.028811\n",
      "ReadsAvg    0.028813\n",
      "ReadsAvg    0.028813\n",
      "ReadsAvg    0.028813\n",
      "ReadsAvg    0.028814\n",
      "ReadsAvg    0.028814\n",
      "ReadsAvg    0.028815\n",
      "ReadsAvg    0.028815\n",
      "ReadsAvg    0.028816\n",
      "ReadsAvg    0.028817\n",
      "ReadsAvg    0.028818\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#commenting everything since tuning is done\n",
    "# tuning batch size\n",
    "#Rnn_xtrain, Rnn_ytrain = fetch_data(X_train, Y_train, 11, 1)\n",
    "#Rnn_xtest, Rnn_ytest = fetch_data(X_test, Y_test, 11, 1)\n",
    "#Rnn_model = LSTM_tune_bs(Rnn_xtrain, Rnn_ytrain,Rnn_xtest, Rnn_ytest, 1, 11, 16)\n",
    "#tuning epochs\n",
    "#Rnn_xtrain, Rnn_ytrain = fetch_data(X_train, Y_train, 11, 1)\n",
    "#Rnn_xtest, Rnn_ytest = fetch_data(X_test, Y_test, 11, 1)\n",
    "#Rnn_model = LSTM_tune_epochs(Rnn_xtrain, Rnn_ytrain,Rnn_xtest, Rnn_ytest, 1, 11, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/50\n",
      "8023/8023 [==============================] - 8s 1ms/step - loss: 17.6802 - accuracy: 0.0889 - val_loss: 1.8815 - val_accuracy: 0.0982\n",
      "Epoch 2/50\n",
      "8023/8023 [==============================] - 4s 499us/step - loss: 2.1614 - accuracy: 0.0869 - val_loss: 1.2673 - val_accuracy: 0.0857\n",
      "Epoch 3/50\n",
      "8023/8023 [==============================] - 4s 507us/step - loss: 1.7635 - accuracy: 0.0906 - val_loss: 1.2762 - val_accuracy: 0.0837\n",
      "Epoch 4/50\n",
      "8023/8023 [==============================] - 4s 484us/step - loss: 1.7234 - accuracy: 0.0949 - val_loss: 1.1912 - val_accuracy: 0.0887\n",
      "Epoch 5/50\n",
      "8023/8023 [==============================] - 4s 481us/step - loss: 1.7174 - accuracy: 0.0934 - val_loss: 1.2055 - val_accuracy: 0.0872\n",
      "Epoch 6/50\n",
      "8023/8023 [==============================] - 4s 438us/step - loss: 1.7059 - accuracy: 0.0905 - val_loss: 1.2115 - val_accuracy: 0.0922\n",
      "Epoch 7/50\n",
      "8023/8023 [==============================] - 3s 428us/step - loss: 1.6720 - accuracy: 0.0841 - val_loss: 1.1966 - val_accuracy: 0.0872\n",
      "Epoch 8/50\n",
      "8023/8023 [==============================] - 4s 461us/step - loss: 1.6530 - accuracy: 0.0949 - val_loss: 1.2074 - val_accuracy: 0.0877\n",
      "Epoch 9/50\n",
      "8023/8023 [==============================] - 4s 454us/step - loss: 1.6588 - accuracy: 0.0865 - val_loss: 1.3137 - val_accuracy: 0.0862\n",
      "Epoch 10/50\n",
      "8023/8023 [==============================] - 4s 449us/step - loss: 1.6581 - accuracy: 0.0922 - val_loss: 1.2452 - val_accuracy: 0.0922\n",
      "Epoch 11/50\n",
      "8023/8023 [==============================] - 4s 442us/step - loss: 1.6581 - accuracy: 0.0940 - val_loss: 1.3220 - val_accuracy: 0.0917\n",
      "Epoch 12/50\n",
      "8023/8023 [==============================] - 3s 421us/step - loss: 1.6349 - accuracy: 0.0993 - val_loss: 1.1730 - val_accuracy: 0.0897\n",
      "Epoch 13/50\n",
      "8023/8023 [==============================] - 3s 402us/step - loss: 1.6109 - accuracy: 0.0922 - val_loss: 1.2772 - val_accuracy: 0.0932\n",
      "Epoch 14/50\n",
      "8023/8023 [==============================] - 3s 431us/step - loss: 1.6274 - accuracy: 0.0909 - val_loss: 1.2070 - val_accuracy: 0.0897\n",
      "Epoch 15/50\n",
      "8023/8023 [==============================] - 3s 418us/step - loss: 1.6040 - accuracy: 0.0957 - val_loss: 1.2059 - val_accuracy: 0.0902\n",
      "Epoch 16/50\n",
      "8023/8023 [==============================] - 3s 427us/step - loss: 1.5913 - accuracy: 0.0939 - val_loss: 1.2233 - val_accuracy: 0.0857\n",
      "Epoch 17/50\n",
      "8023/8023 [==============================] - 3s 406us/step - loss: 1.6052 - accuracy: 0.0929 - val_loss: 1.2713 - val_accuracy: 0.0927\n",
      "Epoch 18/50\n",
      "8023/8023 [==============================] - 3s 392us/step - loss: 1.5871 - accuracy: 0.0896 - val_loss: 1.1892 - val_accuracy: 0.0967\n",
      "Epoch 19/50\n",
      "8023/8023 [==============================] - 3s 411us/step - loss: 1.5883 - accuracy: 0.0930 - val_loss: 1.1953 - val_accuracy: 0.0912\n",
      "Epoch 20/50\n",
      "8023/8023 [==============================] - 3s 405us/step - loss: 1.5667 - accuracy: 0.0976 - val_loss: 1.1683 - val_accuracy: 0.0872\n",
      "Epoch 21/50\n",
      "8023/8023 [==============================] - 3s 407us/step - loss: 1.5711 - accuracy: 0.0961 - val_loss: 1.1821 - val_accuracy: 0.0852\n",
      "Epoch 22/50\n",
      "8023/8023 [==============================] - 3s 406us/step - loss: 1.5562 - accuracy: 0.0985 - val_loss: 1.2054 - val_accuracy: 0.0852\n",
      "Epoch 23/50\n",
      "8023/8023 [==============================] - 3s 419us/step - loss: 1.5559 - accuracy: 0.0962 - val_loss: 1.2074 - val_accuracy: 0.0942\n",
      "Epoch 24/50\n",
      "8023/8023 [==============================] - 3s 404us/step - loss: 1.5485 - accuracy: 0.0990 - val_loss: 1.1966 - val_accuracy: 0.0857\n",
      "Epoch 25/50\n",
      "8023/8023 [==============================] - 3s 393us/step - loss: 1.5582 - accuracy: 0.0967 - val_loss: 1.2018 - val_accuracy: 0.0912\n",
      "Epoch 26/50\n",
      "8023/8023 [==============================] - 4s 499us/step - loss: 1.5605 - accuracy: 0.0946 - val_loss: 1.1773 - val_accuracy: 0.1052\n",
      "Epoch 27/50\n",
      "8023/8023 [==============================] - 3s 409us/step - loss: 1.5504 - accuracy: 0.0960 - val_loss: 1.1777 - val_accuracy: 0.0887\n",
      "Epoch 28/50\n",
      "8023/8023 [==============================] - 3s 403us/step - loss: 1.5437 - accuracy: 0.0947 - val_loss: 1.2031 - val_accuracy: 0.0892\n",
      "Epoch 29/50\n",
      "8023/8023 [==============================] - 4s 444us/step - loss: 1.5303 - accuracy: 0.0922 - val_loss: 1.1779 - val_accuracy: 0.0917\n",
      "Epoch 30/50\n",
      "8023/8023 [==============================] - 4s 446us/step - loss: 1.5300 - accuracy: 0.0905 - val_loss: 1.1792 - val_accuracy: 0.0897\n",
      "Epoch 31/50\n",
      "8023/8023 [==============================] - 4s 438us/step - loss: 1.5281 - accuracy: 0.0915 - val_loss: 1.1745 - val_accuracy: 0.0877\n",
      "Epoch 32/50\n",
      "8023/8023 [==============================] - 4s 437us/step - loss: 1.5398 - accuracy: 0.0936 - val_loss: 1.1688 - val_accuracy: 0.0997\n",
      "Epoch 33/50\n",
      "8023/8023 [==============================] - 3s 425us/step - loss: 1.5311 - accuracy: 0.0987 - val_loss: 1.1889 - val_accuracy: 0.0892\n",
      "Epoch 34/50\n",
      "8023/8023 [==============================] - 3s 404us/step - loss: 1.5298 - accuracy: 0.0952 - val_loss: 1.2210 - val_accuracy: 0.0997\n",
      "Epoch 35/50\n",
      "8023/8023 [==============================] - 3s 420us/step - loss: 1.5294 - accuracy: 0.0991 - val_loss: 1.1880 - val_accuracy: 0.0907\n",
      "Epoch 36/50\n",
      "8023/8023 [==============================] - 4s 457us/step - loss: 1.5330 - accuracy: 0.0978 - val_loss: 1.1854 - val_accuracy: 0.0867\n",
      "Epoch 37/50\n",
      "8023/8023 [==============================] - 3s 422us/step - loss: 1.5280 - accuracy: 0.0958 - val_loss: 1.2087 - val_accuracy: 0.0882\n",
      "Epoch 38/50\n",
      "8023/8023 [==============================] - 3s 431us/step - loss: 1.5412 - accuracy: 0.0925 - val_loss: 1.2418 - val_accuracy: 0.0967\n",
      "Epoch 39/50\n",
      "8023/8023 [==============================] - 3s 408us/step - loss: 1.5300 - accuracy: 0.0983 - val_loss: 1.1623 - val_accuracy: 0.0882\n",
      "Epoch 40/50\n",
      "8023/8023 [==============================] - 3s 429us/step - loss: 1.5279 - accuracy: 0.0973 - val_loss: 1.1734 - val_accuracy: 0.0952\n",
      "Epoch 41/50\n",
      "8023/8023 [==============================] - 4s 437us/step - loss: 1.5378 - accuracy: 0.0968 - val_loss: 1.1848 - val_accuracy: 0.0997\n",
      "Epoch 42/50\n",
      "8023/8023 [==============================] - 3s 421us/step - loss: 1.5213 - accuracy: 0.0947 - val_loss: 1.1715 - val_accuracy: 0.0947\n",
      "Epoch 43/50\n",
      "8023/8023 [==============================] - 3s 399us/step - loss: 1.5237 - accuracy: 0.0968 - val_loss: 1.2062 - val_accuracy: 0.0897\n",
      "Epoch 44/50\n",
      "8023/8023 [==============================] - 3s 406us/step - loss: 1.5255 - accuracy: 0.0966 - val_loss: 1.2131 - val_accuracy: 0.0882\n",
      "Epoch 45/50\n",
      "8023/8023 [==============================] - 3s 397us/step - loss: 1.5313 - accuracy: 0.0932 - val_loss: 1.1890 - val_accuracy: 0.0992\n",
      "Epoch 46/50\n",
      "8023/8023 [==============================] - 3s 404us/step - loss: 1.5226 - accuracy: 0.0952 - val_loss: 1.1823 - val_accuracy: 0.1037\n",
      "Epoch 47/50\n",
      "8023/8023 [==============================] - 3s 417us/step - loss: 1.5280 - accuracy: 0.0972 - val_loss: 1.1738 - val_accuracy: 0.0932\n",
      "Epoch 48/50\n",
      "8023/8023 [==============================] - 3s 393us/step - loss: 1.5261 - accuracy: 0.0911 - val_loss: 1.1751 - val_accuracy: 0.0997\n",
      "Epoch 49/50\n",
      "8023/8023 [==============================] - 3s 412us/step - loss: 1.5286 - accuracy: 0.0961 - val_loss: 1.1757 - val_accuracy: 0.0862\n",
      "Epoch 50/50\n",
      "8023/8023 [==============================] - 3s 404us/step - loss: 1.5260 - accuracy: 0.0934 - val_loss: 1.1769 - val_accuracy: 0.0937\n",
      "the NMAE for units= 10 is: ReadsAvg    0.028919\n",
      "ReadsAvg    0.028921\n",
      "ReadsAvg    0.028921\n",
      "ReadsAvg    0.028921\n",
      "ReadsAvg    0.028922\n",
      "ReadsAvg    0.028922\n",
      "ReadsAvg    0.028923\n",
      "ReadsAvg    0.028923\n",
      "ReadsAvg    0.028924\n",
      "ReadsAvg    0.028925\n",
      "ReadsAvg    0.028926\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 13.1032 - accuracy: 0.0971 - val_loss: 1.7548 - val_accuracy: 0.0837\n",
      "Epoch 2/50\n",
      "8023/8023 [==============================] - 5s 608us/step - loss: 3.4098 - accuracy: 0.0924 - val_loss: 1.2362 - val_accuracy: 0.0927\n",
      "Epoch 3/50\n",
      "8023/8023 [==============================] - 4s 543us/step - loss: 2.0674 - accuracy: 0.0924 - val_loss: 1.2466 - val_accuracy: 0.0833\n",
      "Epoch 4/50\n",
      "8023/8023 [==============================] - 4s 497us/step - loss: 1.6317 - accuracy: 0.0960 - val_loss: 1.2058 - val_accuracy: 0.0942\n",
      "Epoch 5/50\n",
      "8023/8023 [==============================] - 4s 491us/step - loss: 1.6140 - accuracy: 0.0950 - val_loss: 1.2136 - val_accuracy: 0.0922\n",
      "Epoch 6/50\n",
      "8023/8023 [==============================] - 4s 513us/step - loss: 1.6065 - accuracy: 0.0962 - val_loss: 1.1855 - val_accuracy: 0.1052\n",
      "Epoch 7/50\n",
      "8023/8023 [==============================] - 4s 512us/step - loss: 1.5949 - accuracy: 0.1022 - val_loss: 1.2077 - val_accuracy: 0.0907\n",
      "Epoch 8/50\n",
      "8023/8023 [==============================] - 4s 534us/step - loss: 1.5627 - accuracy: 0.0956 - val_loss: 1.3293 - val_accuracy: 0.0897\n",
      "Epoch 9/50\n",
      "8023/8023 [==============================] - 4s 482us/step - loss: 1.5581 - accuracy: 0.0879 - val_loss: 1.2006 - val_accuracy: 0.0917\n",
      "Epoch 10/50\n",
      "8023/8023 [==============================] - 4s 498us/step - loss: 1.5567 - accuracy: 0.1010 - val_loss: 1.2079 - val_accuracy: 0.0927\n",
      "Epoch 11/50\n",
      "8023/8023 [==============================] - 4s 506us/step - loss: 1.5411 - accuracy: 0.0930 - val_loss: 1.3310 - val_accuracy: 0.0882\n",
      "Epoch 12/50\n",
      "8023/8023 [==============================] - 4s 528us/step - loss: 1.5429 - accuracy: 0.0963 - val_loss: 1.1883 - val_accuracy: 0.0992\n",
      "Epoch 13/50\n",
      "8023/8023 [==============================] - 4s 508us/step - loss: 1.5439 - accuracy: 0.0929 - val_loss: 1.2452 - val_accuracy: 0.0857\n",
      "Epoch 14/50\n",
      "8023/8023 [==============================] - 4s 528us/step - loss: 1.5523 - accuracy: 0.0971 - val_loss: 1.2202 - val_accuracy: 0.0922\n",
      "Epoch 15/50\n",
      "8023/8023 [==============================] - 4s 510us/step - loss: 1.5511 - accuracy: 0.0966 - val_loss: 1.2305 - val_accuracy: 0.0892\n",
      "Epoch 16/50\n",
      "8023/8023 [==============================] - 4s 542us/step - loss: 1.5430 - accuracy: 0.0950 - val_loss: 1.1887 - val_accuracy: 0.1052\n",
      "Epoch 17/50\n",
      "8023/8023 [==============================] - 4s 532us/step - loss: 1.5388 - accuracy: 0.0972 - val_loss: 1.2482 - val_accuracy: 0.0922\n",
      "Epoch 18/50\n",
      "8023/8023 [==============================] - 4s 533us/step - loss: 1.5375 - accuracy: 0.0960 - val_loss: 1.1966 - val_accuracy: 0.0902\n",
      "Epoch 19/50\n",
      "8023/8023 [==============================] - 4s 499us/step - loss: 1.5343 - accuracy: 0.0958 - val_loss: 1.1849 - val_accuracy: 0.0917\n",
      "Epoch 20/50\n",
      "8023/8023 [==============================] - 4s 516us/step - loss: 1.5541 - accuracy: 0.0906 - val_loss: 1.2244 - val_accuracy: 0.0887\n",
      "Epoch 21/50\n",
      "8023/8023 [==============================] - 4s 509us/step - loss: 1.5495 - accuracy: 0.0916 - val_loss: 1.2297 - val_accuracy: 0.0952\n",
      "Epoch 22/50\n",
      "8023/8023 [==============================] - 4s 496us/step - loss: 1.5356 - accuracy: 0.0962 - val_loss: 1.1806 - val_accuracy: 0.0997\n",
      "Epoch 23/50\n",
      "8023/8023 [==============================] - 5s 624us/step - loss: 1.5408 - accuracy: 0.0919 - val_loss: 1.1919 - val_accuracy: 0.0897\n",
      "Epoch 24/50\n",
      "8023/8023 [==============================] - 4s 539us/step - loss: 1.5407 - accuracy: 0.0931 - val_loss: 1.1879 - val_accuracy: 0.0877\n",
      "Epoch 25/50\n",
      "8023/8023 [==============================] - 4s 514us/step - loss: 1.5306 - accuracy: 0.0934 - val_loss: 1.1951 - val_accuracy: 0.0897\n",
      "Epoch 26/50\n",
      "8023/8023 [==============================] - 4s 508us/step - loss: 1.5259 - accuracy: 0.0968 - val_loss: 1.1875 - val_accuracy: 0.1117\n",
      "Epoch 27/50\n",
      "8023/8023 [==============================] - 5s 611us/step - loss: 1.5276 - accuracy: 0.0995 - val_loss: 1.1768 - val_accuracy: 0.0947\n",
      "Epoch 28/50\n",
      "8023/8023 [==============================] - 4s 524us/step - loss: 1.5256 - accuracy: 0.0921 - val_loss: 1.1723 - val_accuracy: 0.0882\n",
      "Epoch 29/50\n",
      "8023/8023 [==============================] - 4s 520us/step - loss: 1.5329 - accuracy: 0.0950 - val_loss: 1.2526 - val_accuracy: 0.0867\n",
      "Epoch 30/50\n",
      "8023/8023 [==============================] - 5s 611us/step - loss: 1.5275 - accuracy: 0.0930 - val_loss: 1.1905 - val_accuracy: 0.0902\n",
      "Epoch 31/50\n",
      "8023/8023 [==============================] - 4s 505us/step - loss: 1.5369 - accuracy: 0.0947 - val_loss: 1.1970 - val_accuracy: 0.0907\n",
      "Epoch 32/50\n",
      "8023/8023 [==============================] - 4s 512us/step - loss: 1.5454 - accuracy: 0.0968 - val_loss: 1.2381 - val_accuracy: 0.0907\n",
      "Epoch 33/50\n",
      "8023/8023 [==============================] - 5s 565us/step - loss: 1.5392 - accuracy: 0.0978 - val_loss: 1.2060 - val_accuracy: 0.0803\n",
      "Epoch 34/50\n",
      "8023/8023 [==============================] - 5s 573us/step - loss: 1.5571 - accuracy: 0.0942 - val_loss: 1.2252 - val_accuracy: 0.0957\n",
      "Epoch 35/50\n",
      "8023/8023 [==============================] - 4s 503us/step - loss: 1.5351 - accuracy: 0.0899 - val_loss: 1.1808 - val_accuracy: 0.0847\n",
      "Epoch 36/50\n",
      "8023/8023 [==============================] - 4s 523us/step - loss: 1.5341 - accuracy: 0.0949 - val_loss: 1.2090 - val_accuracy: 0.1002\n",
      "Epoch 37/50\n",
      "8023/8023 [==============================] - 5s 573us/step - loss: 1.5402 - accuracy: 0.0956 - val_loss: 1.2066 - val_accuracy: 0.1022\n",
      "Epoch 38/50\n",
      "8023/8023 [==============================] - 4s 490us/step - loss: 1.5237 - accuracy: 0.0853 - val_loss: 1.1851 - val_accuracy: 0.0922\n",
      "Epoch 39/50\n",
      "8023/8023 [==============================] - 4s 554us/step - loss: 1.5271 - accuracy: 0.0993 - val_loss: 1.2075 - val_accuracy: 0.0987\n",
      "Epoch 40/50\n",
      "8023/8023 [==============================] - 5s 615us/step - loss: 1.5355 - accuracy: 0.0946 - val_loss: 1.1868 - val_accuracy: 0.0902\n",
      "Epoch 41/50\n",
      "8023/8023 [==============================] - 5s 563us/step - loss: 1.5281 - accuracy: 0.0940 - val_loss: 1.2176 - val_accuracy: 0.0922\n",
      "Epoch 42/50\n",
      "8023/8023 [==============================] - 4s 524us/step - loss: 1.5243 - accuracy: 0.0905 - val_loss: 1.1896 - val_accuracy: 0.0887\n",
      "Epoch 43/50\n",
      "8023/8023 [==============================] - 4s 501us/step - loss: 1.5295 - accuracy: 0.0937 - val_loss: 1.2012 - val_accuracy: 0.1047\n",
      "Epoch 44/50\n",
      "8023/8023 [==============================] - 4s 490us/step - loss: 1.5314 - accuracy: 0.0947 - val_loss: 1.1828 - val_accuracy: 0.1102\n",
      "Epoch 45/50\n",
      "8023/8023 [==============================] - 4s 495us/step - loss: 1.5312 - accuracy: 0.0952 - val_loss: 1.1865 - val_accuracy: 0.0897\n",
      "Epoch 46/50\n",
      "8023/8023 [==============================] - 4s 478us/step - loss: 1.5207 - accuracy: 0.0963 - val_loss: 1.2025 - val_accuracy: 0.0892\n",
      "Epoch 47/50\n",
      "8023/8023 [==============================] - 4s 505us/step - loss: 1.5181 - accuracy: 0.0947 - val_loss: 1.2324 - val_accuracy: 0.1097\n",
      "Epoch 48/50\n",
      "8023/8023 [==============================] - 4s 488us/step - loss: 1.5225 - accuracy: 0.0927 - val_loss: 1.2533 - val_accuracy: 0.0922\n",
      "Epoch 49/50\n",
      "8023/8023 [==============================] - 4s 499us/step - loss: 1.5176 - accuracy: 0.0952 - val_loss: 1.1715 - val_accuracy: 0.0917\n",
      "Epoch 50/50\n",
      "8023/8023 [==============================] - 4s 482us/step - loss: 1.5192 - accuracy: 0.0907 - val_loss: 1.1956 - val_accuracy: 0.0902\n",
      "the NMAE for units= 50 is: ReadsAvg    0.028585\n",
      "ReadsAvg    0.028587\n",
      "ReadsAvg    0.028587\n",
      "ReadsAvg    0.028587\n",
      "ReadsAvg    0.028588\n",
      "ReadsAvg    0.028588\n",
      "ReadsAvg    0.028589\n",
      "ReadsAvg    0.028590\n",
      "ReadsAvg    0.028590\n",
      "ReadsAvg    0.028591\n",
      "ReadsAvg    0.028592\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/50\n",
      "8023/8023 [==============================] - 11s 1ms/step - loss: 11.4648 - accuracy: 0.0915 - val_loss: 1.3867 - val_accuracy: 0.0897\n",
      "Epoch 2/50\n",
      "8023/8023 [==============================] - 5s 639us/step - loss: 3.2017 - accuracy: 0.0851 - val_loss: 1.3107 - val_accuracy: 0.0962\n",
      "Epoch 3/50\n",
      "8023/8023 [==============================] - 5s 610us/step - loss: 2.2468 - accuracy: 0.0926 - val_loss: 1.2518 - val_accuracy: 0.0882\n",
      "Epoch 4/50\n",
      "8023/8023 [==============================] - 5s 599us/step - loss: 1.7383 - accuracy: 0.0950 - val_loss: 1.4469 - val_accuracy: 0.0897\n",
      "Epoch 5/50\n",
      "8023/8023 [==============================] - 5s 599us/step - loss: 1.6450 - accuracy: 0.0952 - val_loss: 1.3871 - val_accuracy: 0.0987\n",
      "Epoch 6/50\n",
      "8023/8023 [==============================] - 5s 600us/step - loss: 1.5962 - accuracy: 0.0921 - val_loss: 1.3530 - val_accuracy: 0.0882\n",
      "Epoch 7/50\n",
      "8023/8023 [==============================] - 5s 624us/step - loss: 1.6118 - accuracy: 0.0921 - val_loss: 1.3344 - val_accuracy: 0.0887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "8023/8023 [==============================] - 5s 635us/step - loss: 1.5744 - accuracy: 0.0861 - val_loss: 1.2141 - val_accuracy: 0.0912\n",
      "Epoch 9/50\n",
      "8023/8023 [==============================] - 5s 588us/step - loss: 1.5769 - accuracy: 0.0939 - val_loss: 1.2151 - val_accuracy: 0.0872\n",
      "Epoch 10/50\n",
      "8023/8023 [==============================] - 5s 639us/step - loss: 1.5705 - accuracy: 0.0920 - val_loss: 1.2153 - val_accuracy: 0.0907\n",
      "Epoch 11/50\n",
      "8023/8023 [==============================] - 5s 641us/step - loss: 1.5790 - accuracy: 0.0939 - val_loss: 1.2691 - val_accuracy: 0.1077\n",
      "Epoch 12/50\n",
      "8023/8023 [==============================] - 5s 611us/step - loss: 1.5787 - accuracy: 0.0939 - val_loss: 1.1857 - val_accuracy: 0.0897\n",
      "Epoch 13/50\n",
      "8023/8023 [==============================] - 5s 610us/step - loss: 1.5623 - accuracy: 0.0935 - val_loss: 1.2020 - val_accuracy: 0.0897\n",
      "Epoch 14/50\n",
      "8023/8023 [==============================] - 5s 600us/step - loss: 1.5526 - accuracy: 0.0912 - val_loss: 1.2222 - val_accuracy: 0.0857\n",
      "Epoch 15/50\n",
      "8023/8023 [==============================] - 5s 599us/step - loss: 1.5883 - accuracy: 0.0914 - val_loss: 1.1959 - val_accuracy: 0.0907\n",
      "Epoch 16/50\n",
      "8023/8023 [==============================] - 5s 596us/step - loss: 1.5550 - accuracy: 0.0882 - val_loss: 1.1944 - val_accuracy: 0.1052\n",
      "Epoch 17/50\n",
      "8023/8023 [==============================] - 5s 601us/step - loss: 1.5689 - accuracy: 0.0902 - val_loss: 1.2349 - val_accuracy: 0.0907\n",
      "Epoch 18/50\n",
      "8023/8023 [==============================] - 5s 581us/step - loss: 1.5599 - accuracy: 0.0892 - val_loss: 1.2657 - val_accuracy: 0.1007\n",
      "Epoch 19/50\n",
      "8023/8023 [==============================] - 5s 610us/step - loss: 1.5697 - accuracy: 0.0887 - val_loss: 1.2336 - val_accuracy: 0.0897\n",
      "Epoch 20/50\n",
      "8023/8023 [==============================] - 5s 590us/step - loss: 1.5444 - accuracy: 0.0922 - val_loss: 1.1986 - val_accuracy: 0.0922\n",
      "Epoch 21/50\n",
      "8023/8023 [==============================] - 5s 594us/step - loss: 1.5411 - accuracy: 0.0968 - val_loss: 1.2321 - val_accuracy: 0.0912\n",
      "Epoch 22/50\n",
      "8023/8023 [==============================] - 5s 602us/step - loss: 1.5408 - accuracy: 0.0940 - val_loss: 1.2198 - val_accuracy: 0.0912\n",
      "Epoch 23/50\n",
      "8023/8023 [==============================] - 5s 597us/step - loss: 1.5345 - accuracy: 0.0976 - val_loss: 1.1986 - val_accuracy: 0.0892\n",
      "Epoch 24/50\n",
      "8023/8023 [==============================] - 5s 658us/step - loss: 1.5394 - accuracy: 0.0952 - val_loss: 1.1816 - val_accuracy: 0.0937\n",
      "Epoch 25/50\n",
      "8023/8023 [==============================] - 5s 592us/step - loss: 1.5366 - accuracy: 0.0956 - val_loss: 1.2104 - val_accuracy: 0.0847\n",
      "Epoch 26/50\n",
      "8023/8023 [==============================] - 5s 593us/step - loss: 1.5314 - accuracy: 0.0917 - val_loss: 1.2483 - val_accuracy: 0.0852\n",
      "Epoch 27/50\n",
      "8023/8023 [==============================] - 5s 602us/step - loss: 1.5324 - accuracy: 0.0941 - val_loss: 1.1942 - val_accuracy: 0.0907\n",
      "Epoch 28/50\n",
      "8023/8023 [==============================] - 5s 575us/step - loss: 1.5394 - accuracy: 0.0929 - val_loss: 1.2051 - val_accuracy: 0.0877\n",
      "Epoch 29/50\n",
      "8023/8023 [==============================] - 5s 650us/step - loss: 1.5274 - accuracy: 0.1011 - val_loss: 1.2839 - val_accuracy: 0.0857\n",
      "Epoch 30/50\n",
      "8023/8023 [==============================] - 5s 645us/step - loss: 1.5366 - accuracy: 0.0921 - val_loss: 1.2814 - val_accuracy: 0.1097\n",
      "Epoch 31/50\n",
      "8023/8023 [==============================] - 5s 629us/step - loss: 1.5245 - accuracy: 0.0976 - val_loss: 1.2742 - val_accuracy: 0.0942\n",
      "Epoch 32/50\n",
      "8023/8023 [==============================] - 5s 644us/step - loss: 1.5433 - accuracy: 0.0962 - val_loss: 1.2508 - val_accuracy: 0.0942\n",
      "Epoch 33/50\n",
      "8023/8023 [==============================] - 5s 613us/step - loss: 1.5454 - accuracy: 0.0849 - val_loss: 1.2400 - val_accuracy: 0.1002\n",
      "Epoch 34/50\n",
      "8023/8023 [==============================] - 6s 705us/step - loss: 1.5381 - accuracy: 0.0917 - val_loss: 1.2065 - val_accuracy: 0.0977\n",
      "Epoch 35/50\n",
      "8023/8023 [==============================] - 5s 648us/step - loss: 1.5307 - accuracy: 0.0921 - val_loss: 1.1777 - val_accuracy: 0.0882\n",
      "Epoch 36/50\n",
      "8023/8023 [==============================] - 5s 614us/step - loss: 1.5343 - accuracy: 0.0957 - val_loss: 1.1980 - val_accuracy: 0.0837\n",
      "Epoch 37/50\n",
      "8023/8023 [==============================] - 5s 650us/step - loss: 1.5308 - accuracy: 0.0937 - val_loss: 1.2543 - val_accuracy: 0.0852\n",
      "Epoch 38/50\n",
      "8023/8023 [==============================] - 5s 678us/step - loss: 1.5453 - accuracy: 0.0924 - val_loss: 1.1899 - val_accuracy: 0.0847\n",
      "Epoch 39/50\n",
      "8023/8023 [==============================] - 5s 604us/step - loss: 1.5336 - accuracy: 0.0833 - val_loss: 1.2745 - val_accuracy: 0.0872\n",
      "Epoch 40/50\n",
      "8023/8023 [==============================] - 5s 683us/step - loss: 1.5470 - accuracy: 0.0972 - val_loss: 1.1996 - val_accuracy: 0.0917\n",
      "Epoch 41/50\n",
      "8023/8023 [==============================] - 6s 728us/step - loss: 1.5344 - accuracy: 0.0921 - val_loss: 1.1985 - val_accuracy: 0.0912\n",
      "Epoch 42/50\n",
      "8023/8023 [==============================] - 5s 634us/step - loss: 1.5374 - accuracy: 0.0982 - val_loss: 1.2176 - val_accuracy: 0.0862\n",
      "Epoch 43/50\n",
      "8023/8023 [==============================] - 5s 662us/step - loss: 1.5468 - accuracy: 0.0982 - val_loss: 1.2240 - val_accuracy: 0.0852\n",
      "Epoch 44/50\n",
      "8023/8023 [==============================] - 5s 606us/step - loss: 1.5365 - accuracy: 0.0934 - val_loss: 1.1931 - val_accuracy: 0.0897\n",
      "Epoch 45/50\n",
      "8023/8023 [==============================] - 5s 615us/step - loss: 1.5371 - accuracy: 0.0952 - val_loss: 1.2069 - val_accuracy: 0.0857\n",
      "Epoch 46/50\n",
      "8023/8023 [==============================] - 5s 647us/step - loss: 1.5607 - accuracy: 0.0965 - val_loss: 1.2431 - val_accuracy: 0.0907\n",
      "Epoch 47/50\n",
      "8023/8023 [==============================] - 5s 565us/step - loss: 1.5314 - accuracy: 0.0952 - val_loss: 1.2672 - val_accuracy: 0.1092\n",
      "Epoch 48/50\n",
      "8023/8023 [==============================] - 6s 694us/step - loss: 1.5309 - accuracy: 0.0935 - val_loss: 1.1857 - val_accuracy: 0.0982\n",
      "Epoch 49/50\n",
      "8023/8023 [==============================] - 5s 625us/step - loss: 1.5230 - accuracy: 0.0945 - val_loss: 1.2032 - val_accuracy: 0.0877\n",
      "Epoch 50/50\n",
      "8023/8023 [==============================] - 5s 617us/step - loss: 1.5298 - accuracy: 0.0926 - val_loss: 1.2935 - val_accuracy: 0.0922\n",
      "the NMAE for units= 80 is: ReadsAvg    0.029880\n",
      "ReadsAvg    0.029881\n",
      "ReadsAvg    0.029882\n",
      "ReadsAvg    0.029882\n",
      "ReadsAvg    0.029883\n",
      "ReadsAvg    0.029883\n",
      "ReadsAvg    0.029883\n",
      "ReadsAvg    0.029884\n",
      "ReadsAvg    0.029885\n",
      "ReadsAvg    0.029886\n",
      "ReadsAvg    0.029887\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/50\n",
      "8023/8023 [==============================] - 13s 2ms/step - loss: 10.2356 - accuracy: 0.0863 - val_loss: 2.0076 - val_accuracy: 0.0877\n",
      "Epoch 2/50\n",
      "8023/8023 [==============================] - 7s 864us/step - loss: 3.3625 - accuracy: 0.0954 - val_loss: 3.3042 - val_accuracy: 0.0897\n",
      "Epoch 3/50\n",
      "8023/8023 [==============================] - 7s 879us/step - loss: 2.7276 - accuracy: 0.0954 - val_loss: 1.2502 - val_accuracy: 0.1097\n",
      "Epoch 4/50\n",
      "8023/8023 [==============================] - 7s 869us/step - loss: 2.2595 - accuracy: 0.0990 - val_loss: 1.2151 - val_accuracy: 0.0877\n",
      "Epoch 5/50\n",
      "8023/8023 [==============================] - 7s 910us/step - loss: 1.7804 - accuracy: 0.0966 - val_loss: 1.6049 - val_accuracy: 0.0897\n",
      "Epoch 6/50\n",
      "8023/8023 [==============================] - 7s 843us/step - loss: 1.6470 - accuracy: 0.0950 - val_loss: 1.2072 - val_accuracy: 0.0977\n",
      "Epoch 7/50\n",
      "8023/8023 [==============================] - 7s 829us/step - loss: 1.6085 - accuracy: 0.0957 - val_loss: 1.3308 - val_accuracy: 0.0902\n",
      "Epoch 8/50\n",
      "8023/8023 [==============================] - 7s 888us/step - loss: 1.5853 - accuracy: 0.0941 - val_loss: 1.2768 - val_accuracy: 0.0912\n",
      "Epoch 9/50\n",
      "8023/8023 [==============================] - 7s 851us/step - loss: 1.5788 - accuracy: 0.0955 - val_loss: 1.2447 - val_accuracy: 0.0837\n",
      "Epoch 10/50\n",
      "8023/8023 [==============================] - 7s 858us/step - loss: 1.6282 - accuracy: 0.0991 - val_loss: 1.2166 - val_accuracy: 0.0902\n",
      "Epoch 11/50\n",
      "8023/8023 [==============================] - 7s 812us/step - loss: 1.5704 - accuracy: 0.0940 - val_loss: 1.2740 - val_accuracy: 0.0977\n",
      "Epoch 12/50\n",
      "8023/8023 [==============================] - 7s 828us/step - loss: 1.5903 - accuracy: 0.1023 - val_loss: 1.1925 - val_accuracy: 0.0962\n",
      "Epoch 13/50\n",
      "8023/8023 [==============================] - 7s 844us/step - loss: 1.5833 - accuracy: 0.0950 - val_loss: 1.2169 - val_accuracy: 0.1097\n",
      "Epoch 14/50\n",
      "8023/8023 [==============================] - 7s 890us/step - loss: 1.5777 - accuracy: 0.1017 - val_loss: 1.2106 - val_accuracy: 0.0947\n",
      "Epoch 15/50\n",
      "8023/8023 [==============================] - 7s 844us/step - loss: 1.5622 - accuracy: 0.0955 - val_loss: 1.2178 - val_accuracy: 0.0902\n",
      "Epoch 16/50\n",
      "8023/8023 [==============================] - 7s 891us/step - loss: 1.5485 - accuracy: 0.0965 - val_loss: 1.1891 - val_accuracy: 0.0882\n",
      "Epoch 17/50\n",
      "8023/8023 [==============================] - 7s 887us/step - loss: 1.5598 - accuracy: 0.0981 - val_loss: 1.2506 - val_accuracy: 0.0982\n",
      "Epoch 18/50\n",
      "8023/8023 [==============================] - 7s 870us/step - loss: 1.5494 - accuracy: 0.0977 - val_loss: 1.1897 - val_accuracy: 0.0967\n",
      "Epoch 19/50\n",
      "8023/8023 [==============================] - 7s 893us/step - loss: 1.5495 - accuracy: 0.0915 - val_loss: 1.2132 - val_accuracy: 0.0887\n",
      "Epoch 20/50\n",
      "8023/8023 [==============================] - 6s 803us/step - loss: 1.5478 - accuracy: 0.0951 - val_loss: 1.2400 - val_accuracy: 0.0917\n",
      "Epoch 21/50\n",
      "8023/8023 [==============================] - 7s 904us/step - loss: 1.5599 - accuracy: 0.0995 - val_loss: 1.1934 - val_accuracy: 0.0997\n",
      "Epoch 22/50\n",
      "8023/8023 [==============================] - 7s 893us/step - loss: 1.5517 - accuracy: 0.0876 - val_loss: 1.1879 - val_accuracy: 0.0897\n",
      "Epoch 23/50\n",
      "8023/8023 [==============================] - 7s 873us/step - loss: 1.5451 - accuracy: 0.1011 - val_loss: 1.2066 - val_accuracy: 0.1047\n",
      "Epoch 24/50\n",
      "8023/8023 [==============================] - 7s 919us/step - loss: 1.5445 - accuracy: 0.0965 - val_loss: 1.2027 - val_accuracy: 0.0867\n",
      "Epoch 25/50\n",
      "8023/8023 [==============================] - 7s 910us/step - loss: 1.5547 - accuracy: 0.0963 - val_loss: 1.2590 - val_accuracy: 0.0852\n",
      "Epoch 26/50\n",
      "8023/8023 [==============================] - 7s 815us/step - loss: 1.5441 - accuracy: 0.0992 - val_loss: 1.2512 - val_accuracy: 0.0907\n",
      "Epoch 27/50\n",
      "8023/8023 [==============================] - 8s 966us/step - loss: 1.5392 - accuracy: 0.0962 - val_loss: 1.2163 - val_accuracy: 0.0857\n",
      "Epoch 28/50\n",
      "8023/8023 [==============================] - 8s 944us/step - loss: 1.5443 - accuracy: 0.0965 - val_loss: 1.2515 - val_accuracy: 0.1052\n",
      "Epoch 29/50\n",
      "8023/8023 [==============================] - 7s 904us/step - loss: 1.5429 - accuracy: 0.0962 - val_loss: 1.2189 - val_accuracy: 0.0922\n",
      "Epoch 30/50\n",
      "8023/8023 [==============================] - 7s 850us/step - loss: 1.5519 - accuracy: 0.0917 - val_loss: 1.2058 - val_accuracy: 0.0972\n",
      "Epoch 31/50\n",
      "8023/8023 [==============================] - 7s 893us/step - loss: 1.5710 - accuracy: 0.0960 - val_loss: 1.2503 - val_accuracy: 0.1077\n",
      "Epoch 32/50\n",
      "8023/8023 [==============================] - 7s 922us/step - loss: 1.5396 - accuracy: 0.0982 - val_loss: 1.1936 - val_accuracy: 0.0892\n",
      "Epoch 33/50\n",
      "8023/8023 [==============================] - 7s 913us/step - loss: 1.5474 - accuracy: 0.0915 - val_loss: 1.1744 - val_accuracy: 0.0877\n",
      "Epoch 34/50\n",
      "8023/8023 [==============================] - 7s 902us/step - loss: 1.5487 - accuracy: 0.0941 - val_loss: 1.2018 - val_accuracy: 0.0927\n",
      "Epoch 35/50\n",
      "8023/8023 [==============================] - 7s 934us/step - loss: 1.5384 - accuracy: 0.0946 - val_loss: 1.1975 - val_accuracy: 0.0902\n",
      "Epoch 36/50\n",
      "8023/8023 [==============================] - 7s 890us/step - loss: 1.5332 - accuracy: 0.0895 - val_loss: 1.2154 - val_accuracy: 0.0852\n",
      "Epoch 37/50\n",
      "8023/8023 [==============================] - 7s 869us/step - loss: 1.5493 - accuracy: 0.0886 - val_loss: 1.3112 - val_accuracy: 0.0852\n",
      "Epoch 38/50\n",
      "8023/8023 [==============================] - 7s 924us/step - loss: 1.5569 - accuracy: 0.0957 - val_loss: 1.3355 - val_accuracy: 0.0852\n",
      "Epoch 39/50\n",
      "8023/8023 [==============================] - 7s 837us/step - loss: 1.5556 - accuracy: 0.0925 - val_loss: 1.2319 - val_accuracy: 0.0932\n",
      "Epoch 40/50\n",
      "8023/8023 [==============================] - 7s 866us/step - loss: 1.5392 - accuracy: 0.0904 - val_loss: 1.1962 - val_accuracy: 0.0937\n",
      "Epoch 41/50\n",
      "8023/8023 [==============================] - 7s 879us/step - loss: 1.5920 - accuracy: 0.0946 - val_loss: 1.1833 - val_accuracy: 0.0987\n",
      "Epoch 42/50\n",
      "8023/8023 [==============================] - 7s 878us/step - loss: 1.5639 - accuracy: 0.0925 - val_loss: 1.2106 - val_accuracy: 0.0887\n",
      "Epoch 43/50\n",
      "8023/8023 [==============================] - 7s 883us/step - loss: 1.5550 - accuracy: 0.0886 - val_loss: 1.2164 - val_accuracy: 0.0977\n",
      "Epoch 44/50\n",
      "8023/8023 [==============================] - 7s 902us/step - loss: 1.5362 - accuracy: 0.0951 - val_loss: 1.2298 - val_accuracy: 0.1062\n",
      "Epoch 45/50\n",
      "8023/8023 [==============================] - 7s 899us/step - loss: 1.5507 - accuracy: 0.0931 - val_loss: 1.1908 - val_accuracy: 0.0987\n",
      "Epoch 46/50\n",
      "8023/8023 [==============================] - 7s 859us/step - loss: 1.5954 - accuracy: 0.0941 - val_loss: 1.2397 - val_accuracy: 0.0997\n",
      "Epoch 47/50\n",
      "8023/8023 [==============================] - 7s 845us/step - loss: 1.5391 - accuracy: 0.0951 - val_loss: 1.2115 - val_accuracy: 0.0877\n",
      "Epoch 48/50\n",
      "8023/8023 [==============================] - 6s 762us/step - loss: 1.5846 - accuracy: 0.0946 - val_loss: 1.2166 - val_accuracy: 0.0927\n",
      "Epoch 49/50\n",
      "8023/8023 [==============================] - 6s 776us/step - loss: 1.5454 - accuracy: 0.0952 - val_loss: 1.2346 - val_accuracy: 0.0897\n",
      "Epoch 50/50\n",
      "8023/8023 [==============================] - 7s 873us/step - loss: 1.5431 - accuracy: 0.0970 - val_loss: 1.2102 - val_accuracy: 0.0877\n",
      "the NMAE for units= 128 is: ReadsAvg    0.029581\n",
      "ReadsAvg    0.029582\n",
      "ReadsAvg    0.029583\n",
      "ReadsAvg    0.029583\n",
      "ReadsAvg    0.029584\n",
      "ReadsAvg    0.029584\n",
      "ReadsAvg    0.029584\n",
      "ReadsAvg    0.029585\n",
      "ReadsAvg    0.029586\n",
      "ReadsAvg    0.029587\n",
      "ReadsAvg    0.029588\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#tuning the no. of nodes/units\n",
    "#Rnn_xtrain, Rnn_ytrain = fetch_data(X_train, Y_train, 11, 1)\n",
    "#Rnn_xtest, Rnn_ytest = fetch_data(X_test, Y_test, 11, 1)\n",
    "#Rnn_model = LSTM_tune_nodes(Rnn_xtrain, Rnn_ytrain,Rnn_xtest, Rnn_ytest, 1, 11, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 13.2054 - accuracy: 0.0896 - val_loss: 2.1368 - val_accuracy: 0.0892\n",
      "Epoch 2/50\n",
      "8023/8023 [==============================] - 4s 518us/step - loss: 3.4839 - accuracy: 0.0849 - val_loss: 1.6236 - val_accuracy: 0.0947\n",
      "Epoch 3/50\n",
      "8023/8023 [==============================] - 4s 465us/step - loss: 2.0445 - accuracy: 0.0952 - val_loss: 1.3228 - val_accuracy: 0.0887\n",
      "Epoch 4/50\n",
      "8023/8023 [==============================] - 4s 540us/step - loss: 1.6413 - accuracy: 0.0945 - val_loss: 1.2211 - val_accuracy: 0.1012\n",
      "Epoch 5/50\n",
      "8023/8023 [==============================] - 4s 524us/step - loss: 1.5948 - accuracy: 0.0961 - val_loss: 1.2007 - val_accuracy: 0.0892\n",
      "Epoch 6/50\n",
      "8023/8023 [==============================] - 4s 475us/step - loss: 1.5837 - accuracy: 0.0947 - val_loss: 1.2307 - val_accuracy: 0.0922\n",
      "Epoch 7/50\n",
      "8023/8023 [==============================] - 4s 503us/step - loss: 1.5688 - accuracy: 0.0925 - val_loss: 1.1907 - val_accuracy: 0.0872\n",
      "Epoch 8/50\n",
      "8023/8023 [==============================] - 4s 524us/step - loss: 1.5703 - accuracy: 0.0950 - val_loss: 1.2680 - val_accuracy: 0.0897\n",
      "Epoch 9/50\n",
      "8023/8023 [==============================] - 4s 513us/step - loss: 1.5674 - accuracy: 0.0970 - val_loss: 1.2253 - val_accuracy: 0.1027\n",
      "Epoch 10/50\n",
      "8023/8023 [==============================] - 5s 567us/step - loss: 1.5803 - accuracy: 0.0970 - val_loss: 1.1920 - val_accuracy: 0.0987\n",
      "Epoch 11/50\n",
      "8023/8023 [==============================] - 5s 571us/step - loss: 1.5620 - accuracy: 0.0946 - val_loss: 1.2471 - val_accuracy: 0.0957\n",
      "Epoch 12/50\n",
      "8023/8023 [==============================] - 4s 538us/step - loss: 1.5506 - accuracy: 0.0909 - val_loss: 1.2030 - val_accuracy: 0.0992\n",
      "Epoch 13/50\n",
      "8023/8023 [==============================] - 4s 540us/step - loss: 1.5468 - accuracy: 0.0983 - val_loss: 1.2000 - val_accuracy: 0.0927\n",
      "Epoch 14/50\n",
      "8023/8023 [==============================] - 4s 542us/step - loss: 1.5471 - accuracy: 0.0968 - val_loss: 1.1914 - val_accuracy: 0.1017\n",
      "Epoch 15/50\n",
      "8023/8023 [==============================] - 4s 535us/step - loss: 1.5498 - accuracy: 0.0884 - val_loss: 1.2618 - val_accuracy: 0.0852\n",
      "Epoch 16/50\n",
      "8023/8023 [==============================] - 4s 538us/step - loss: 1.5436 - accuracy: 0.0981 - val_loss: 1.2151 - val_accuracy: 0.0917\n",
      "Epoch 17/50\n",
      "8023/8023 [==============================] - 4s 544us/step - loss: 1.5428 - accuracy: 0.0906 - val_loss: 1.2397 - val_accuracy: 0.0902\n",
      "Epoch 18/50\n",
      "8023/8023 [==============================] - 4s 539us/step - loss: 1.5423 - accuracy: 0.0919 - val_loss: 1.2512 - val_accuracy: 0.0902\n",
      "Epoch 19/50\n",
      "8023/8023 [==============================] - 4s 537us/step - loss: 1.5403 - accuracy: 0.0921 - val_loss: 1.2073 - val_accuracy: 0.0892\n",
      "Epoch 20/50\n",
      "8023/8023 [==============================] - 4s 538us/step - loss: 1.5305 - accuracy: 0.0972 - val_loss: 1.2253 - val_accuracy: 0.0877\n",
      "Epoch 21/50\n",
      "8023/8023 [==============================] - 4s 517us/step - loss: 1.5465 - accuracy: 0.0921 - val_loss: 1.1795 - val_accuracy: 0.0927\n",
      "Epoch 22/50\n",
      "8023/8023 [==============================] - 4s 551us/step - loss: 1.5311 - accuracy: 0.0988 - val_loss: 1.2168 - val_accuracy: 0.1042\n",
      "Epoch 23/50\n",
      "8023/8023 [==============================] - 4s 538us/step - loss: 1.5382 - accuracy: 0.0962 - val_loss: 1.1821 - val_accuracy: 0.0842\n",
      "Epoch 24/50\n",
      "8023/8023 [==============================] - 4s 536us/step - loss: 1.5343 - accuracy: 0.0904 - val_loss: 1.1862 - val_accuracy: 0.0922\n",
      "Epoch 25/50\n",
      "8023/8023 [==============================] - 4s 515us/step - loss: 1.5211 - accuracy: 0.0986 - val_loss: 1.1867 - val_accuracy: 0.0842\n",
      "Epoch 26/50\n",
      "8023/8023 [==============================] - 4s 543us/step - loss: 1.5230 - accuracy: 0.0886 - val_loss: 1.1846 - val_accuracy: 0.0912\n",
      "Epoch 27/50\n",
      "8023/8023 [==============================] - 4s 540us/step - loss: 1.5287 - accuracy: 0.0955 - val_loss: 1.1865 - val_accuracy: 0.0982\n",
      "Epoch 28/50\n",
      "8023/8023 [==============================] - 4s 534us/step - loss: 1.5229 - accuracy: 0.0941 - val_loss: 1.1941 - val_accuracy: 0.0857\n",
      "Epoch 29/50\n",
      "8023/8023 [==============================] - 4s 535us/step - loss: 1.5198 - accuracy: 0.0997 - val_loss: 1.2394 - val_accuracy: 0.0867\n",
      "Epoch 30/50\n",
      "8023/8023 [==============================] - 4s 534us/step - loss: 1.5168 - accuracy: 0.0946 - val_loss: 1.2946 - val_accuracy: 0.0962\n",
      "Epoch 31/50\n",
      "8023/8023 [==============================] - 5s 563us/step - loss: 1.5278 - accuracy: 0.1012 - val_loss: 1.2460 - val_accuracy: 0.0897\n",
      "Epoch 32/50\n",
      "8023/8023 [==============================] - 4s 537us/step - loss: 1.5381 - accuracy: 0.0976 - val_loss: 1.1956 - val_accuracy: 0.0907\n",
      "Epoch 33/50\n",
      "8023/8023 [==============================] - 5s 581us/step - loss: 1.5345 - accuracy: 0.0966 - val_loss: 1.2019 - val_accuracy: 0.0932\n",
      "Epoch 34/50\n",
      "8023/8023 [==============================] - 5s 591us/step - loss: 1.5273 - accuracy: 0.0978 - val_loss: 1.1880 - val_accuracy: 0.0902\n",
      "Epoch 35/50\n",
      "8023/8023 [==============================] - 4s 529us/step - loss: 1.5260 - accuracy: 0.0954 - val_loss: 1.1968 - val_accuracy: 0.0917\n",
      "Epoch 36/50\n",
      "8023/8023 [==============================] - 4s 501us/step - loss: 1.5146 - accuracy: 0.0968 - val_loss: 1.2233 - val_accuracy: 0.0877\n",
      "Epoch 37/50\n",
      "8023/8023 [==============================] - 4s 496us/step - loss: 1.5187 - accuracy: 0.0905 - val_loss: 1.2404 - val_accuracy: 0.0897\n",
      "Epoch 38/50\n",
      "8023/8023 [==============================] - 4s 527us/step - loss: 1.5359 - accuracy: 0.0924 - val_loss: 1.1873 - val_accuracy: 0.0852\n",
      "Epoch 39/50\n",
      "8023/8023 [==============================] - 4s 495us/step - loss: 1.5248 - accuracy: 0.0951 - val_loss: 1.1796 - val_accuracy: 0.0887\n",
      "Epoch 40/50\n",
      "8023/8023 [==============================] - 4s 506us/step - loss: 1.5220 - accuracy: 0.0993 - val_loss: 1.2127 - val_accuracy: 0.1082\n",
      "Epoch 41/50\n",
      "8023/8023 [==============================] - 4s 490us/step - loss: 1.5162 - accuracy: 0.1025 - val_loss: 1.2178 - val_accuracy: 0.0837\n",
      "Epoch 42/50\n",
      "8023/8023 [==============================] - 4s 508us/step - loss: 1.5753 - accuracy: 0.0935 - val_loss: 1.2507 - val_accuracy: 0.1022\n",
      "Epoch 43/50\n",
      "8023/8023 [==============================] - 5s 580us/step - loss: 1.5214 - accuracy: 0.0973 - val_loss: 1.1813 - val_accuracy: 0.1002\n",
      "Epoch 44/50\n",
      "8023/8023 [==============================] - 4s 480us/step - loss: 1.5284 - accuracy: 0.1023 - val_loss: 1.1913 - val_accuracy: 0.0842\n",
      "Epoch 45/50\n",
      "8023/8023 [==============================] - 4s 498us/step - loss: 1.5258 - accuracy: 0.0980 - val_loss: 1.1814 - val_accuracy: 0.0852\n",
      "Epoch 46/50\n",
      "8023/8023 [==============================] - 4s 536us/step - loss: 1.5212 - accuracy: 0.1000 - val_loss: 1.2150 - val_accuracy: 0.0922\n",
      "Epoch 47/50\n",
      "8023/8023 [==============================] - 3s 433us/step - loss: 1.5234 - accuracy: 0.0954 - val_loss: 1.2224 - val_accuracy: 0.0912\n",
      "Epoch 48/50\n",
      "8023/8023 [==============================] - 4s 459us/step - loss: 1.5192 - accuracy: 0.1017 - val_loss: 1.1833 - val_accuracy: 0.0917\n",
      "Epoch 49/50\n",
      "8023/8023 [==============================] - 4s 515us/step - loss: 1.5055 - accuracy: 0.0963 - val_loss: 1.2358 - val_accuracy: 0.0877\n",
      "Epoch 50/50\n",
      "8023/8023 [==============================] - 4s 503us/step - loss: 1.5178 - accuracy: 0.0870 - val_loss: 1.1987 - val_accuracy: 0.0867\n",
      "the NMAE for learning rate= 0.01 is: ReadsAvg    0.028785\n",
      "ReadsAvg    0.028786\n",
      "ReadsAvg    0.028787\n",
      "ReadsAvg    0.028787\n",
      "ReadsAvg    0.028788\n",
      "ReadsAvg    0.028788\n",
      "ReadsAvg    0.028788\n",
      "ReadsAvg    0.028789\n",
      "ReadsAvg    0.028790\n",
      "ReadsAvg    0.028791\n",
      "ReadsAvg    0.028792\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/50\n",
      "8023/8023 [==============================] - 10s 1ms/step - loss: 35.0322 - accuracy: 0.0856 - val_loss: 22.8242 - val_accuracy: 0.0927\n",
      "Epoch 2/50\n",
      "8023/8023 [==============================] - 5s 605us/step - loss: 19.0029 - accuracy: 0.0900 - val_loss: 14.3970 - val_accuracy: 0.0857\n",
      "Epoch 3/50\n",
      "8023/8023 [==============================] - 4s 549us/step - loss: 8.2577 - accuracy: 0.0945 - val_loss: 2.2600 - val_accuracy: 0.0872\n",
      "Epoch 4/50\n",
      "8023/8023 [==============================] - 4s 561us/step - loss: 3.4195 - accuracy: 0.0906 - val_loss: 1.4648 - val_accuracy: 0.0882\n",
      "Epoch 5/50\n",
      "8023/8023 [==============================] - 4s 491us/step - loss: 2.8679 - accuracy: 0.0945 - val_loss: 1.3093 - val_accuracy: 0.0942\n",
      "Epoch 6/50\n",
      "8023/8023 [==============================] - 4s 540us/step - loss: 2.5291 - accuracy: 0.0944 - val_loss: 1.3382 - val_accuracy: 0.0932\n",
      "Epoch 7/50\n",
      "8023/8023 [==============================] - 4s 516us/step - loss: 2.2394 - accuracy: 0.0954 - val_loss: 1.2684 - val_accuracy: 0.0917\n",
      "Epoch 8/50\n",
      "8023/8023 [==============================] - 4s 498us/step - loss: 2.1268 - accuracy: 0.0957 - val_loss: 1.2155 - val_accuracy: 0.0967\n",
      "Epoch 9/50\n",
      "8023/8023 [==============================] - 4s 502us/step - loss: 2.0243 - accuracy: 0.0997 - val_loss: 1.2178 - val_accuracy: 0.0937\n",
      "Epoch 10/50\n",
      "8023/8023 [==============================] - 4s 500us/step - loss: 1.9978 - accuracy: 0.0956 - val_loss: 1.2392 - val_accuracy: 0.0917\n",
      "Epoch 11/50\n",
      "8023/8023 [==============================] - 4s 543us/step - loss: 1.9448 - accuracy: 0.0957 - val_loss: 1.2309 - val_accuracy: 0.0977\n",
      "Epoch 12/50\n",
      "8023/8023 [==============================] - 4s 525us/step - loss: 1.9214 - accuracy: 0.0992 - val_loss: 1.1992 - val_accuracy: 0.1037\n",
      "Epoch 13/50\n",
      "8023/8023 [==============================] - 4s 462us/step - loss: 1.8651 - accuracy: 0.0957 - val_loss: 1.2167 - val_accuracy: 0.0942\n",
      "Epoch 14/50\n",
      "8023/8023 [==============================] - 4s 558us/step - loss: 1.8594 - accuracy: 0.0973 - val_loss: 1.2112 - val_accuracy: 0.0947\n",
      "Epoch 15/50\n",
      "8023/8023 [==============================] - 4s 516us/step - loss: 1.8398 - accuracy: 0.0973 - val_loss: 1.2007 - val_accuracy: 0.0977\n",
      "Epoch 16/50\n",
      "8023/8023 [==============================] - 4s 505us/step - loss: 1.7965 - accuracy: 0.0892 - val_loss: 1.2084 - val_accuracy: 0.0987\n",
      "Epoch 17/50\n",
      "8023/8023 [==============================] - 4s 543us/step - loss: 1.7722 - accuracy: 0.0971 - val_loss: 1.1954 - val_accuracy: 0.0932\n",
      "Epoch 18/50\n",
      "8023/8023 [==============================] - 5s 633us/step - loss: 1.7602 - accuracy: 0.0963 - val_loss: 1.1804 - val_accuracy: 0.0947\n",
      "Epoch 19/50\n",
      "8023/8023 [==============================] - 4s 531us/step - loss: 1.7352 - accuracy: 0.0915 - val_loss: 1.2134 - val_accuracy: 0.0922\n",
      "Epoch 20/50\n",
      "8023/8023 [==============================] - 4s 508us/step - loss: 1.7222 - accuracy: 0.0931 - val_loss: 1.2024 - val_accuracy: 0.0907\n",
      "Epoch 21/50\n",
      "8023/8023 [==============================] - 4s 531us/step - loss: 1.7148 - accuracy: 0.0980 - val_loss: 1.2208 - val_accuracy: 0.0972\n",
      "Epoch 22/50\n",
      "8023/8023 [==============================] - 4s 535us/step - loss: 1.6946 - accuracy: 0.0963 - val_loss: 1.1876 - val_accuracy: 0.0932\n",
      "Epoch 23/50\n",
      "8023/8023 [==============================] - 4s 510us/step - loss: 1.6825 - accuracy: 0.0950 - val_loss: 1.1736 - val_accuracy: 0.0952\n",
      "Epoch 24/50\n",
      "8023/8023 [==============================] - 4s 495us/step - loss: 1.6840 - accuracy: 0.0978 - val_loss: 1.1781 - val_accuracy: 0.0967\n",
      "Epoch 25/50\n",
      "8023/8023 [==============================] - 4s 542us/step - loss: 1.6781 - accuracy: 0.0916 - val_loss: 1.2853 - val_accuracy: 0.0977\n",
      "Epoch 26/50\n",
      "8023/8023 [==============================] - 5s 605us/step - loss: 1.6691 - accuracy: 0.0983 - val_loss: 1.1789 - val_accuracy: 0.0997\n",
      "Epoch 27/50\n",
      "8023/8023 [==============================] - 4s 560us/step - loss: 1.6447 - accuracy: 0.0934 - val_loss: 1.2182 - val_accuracy: 0.1037\n",
      "Epoch 28/50\n",
      "8023/8023 [==============================] - 5s 566us/step - loss: 1.6377 - accuracy: 0.0996 - val_loss: 1.1779 - val_accuracy: 0.1052\n",
      "Epoch 29/50\n",
      "8023/8023 [==============================] - 4s 535us/step - loss: 1.6310 - accuracy: 0.0985 - val_loss: 1.1815 - val_accuracy: 0.0922\n",
      "Epoch 30/50\n",
      "8023/8023 [==============================] - 4s 551us/step - loss: 1.6288 - accuracy: 0.0889 - val_loss: 1.1896 - val_accuracy: 0.0967\n",
      "Epoch 31/50\n",
      "8023/8023 [==============================] - 4s 553us/step - loss: 1.6177 - accuracy: 0.0977 - val_loss: 1.1822 - val_accuracy: 0.0982\n",
      "Epoch 32/50\n",
      "8023/8023 [==============================] - 4s 555us/step - loss: 1.6122 - accuracy: 0.0996 - val_loss: 1.2312 - val_accuracy: 0.0927\n",
      "Epoch 33/50\n",
      "8023/8023 [==============================] - 4s 547us/step - loss: 1.6151 - accuracy: 0.0986 - val_loss: 1.1888 - val_accuracy: 0.0927\n",
      "Epoch 34/50\n",
      "8023/8023 [==============================] - 4s 544us/step - loss: 1.6085 - accuracy: 0.0935 - val_loss: 1.2227 - val_accuracy: 0.0957\n",
      "Epoch 35/50\n",
      "8023/8023 [==============================] - 4s 532us/step - loss: 1.5905 - accuracy: 0.1010 - val_loss: 1.2321 - val_accuracy: 0.0872\n",
      "Epoch 36/50\n",
      "8023/8023 [==============================] - 5s 576us/step - loss: 1.5853 - accuracy: 0.0895 - val_loss: 1.2164 - val_accuracy: 0.0957\n",
      "Epoch 37/50\n",
      "8023/8023 [==============================] - 5s 587us/step - loss: 1.5884 - accuracy: 0.0946 - val_loss: 1.2236 - val_accuracy: 0.1017\n",
      "Epoch 38/50\n",
      "8023/8023 [==============================] - 4s 484us/step - loss: 1.5791 - accuracy: 0.0971 - val_loss: 1.1993 - val_accuracy: 0.0932\n",
      "Epoch 39/50\n",
      "8023/8023 [==============================] - 5s 580us/step - loss: 1.5703 - accuracy: 0.0955 - val_loss: 1.2105 - val_accuracy: 0.0892\n",
      "Epoch 40/50\n",
      "8023/8023 [==============================] - 5s 575us/step - loss: 1.5753 - accuracy: 0.0987 - val_loss: 1.2473 - val_accuracy: 0.0927\n",
      "Epoch 41/50\n",
      "8023/8023 [==============================] - 5s 580us/step - loss: 1.5549 - accuracy: 0.0915 - val_loss: 1.1730 - val_accuracy: 0.0927\n",
      "Epoch 42/50\n",
      "8023/8023 [==============================] - 4s 509us/step - loss: 1.5655 - accuracy: 0.0932 - val_loss: 1.2163 - val_accuracy: 0.0982\n",
      "Epoch 43/50\n",
      "8023/8023 [==============================] - 5s 570us/step - loss: 1.5526 - accuracy: 0.1054 - val_loss: 1.2104 - val_accuracy: 0.0902\n",
      "Epoch 44/50\n",
      "8023/8023 [==============================] - 4s 503us/step - loss: 1.5582 - accuracy: 0.0995 - val_loss: 1.1990 - val_accuracy: 0.0952\n",
      "Epoch 45/50\n",
      "8023/8023 [==============================] - 4s 535us/step - loss: 1.5401 - accuracy: 0.0996 - val_loss: 1.1911 - val_accuracy: 0.0977\n",
      "Epoch 46/50\n",
      "8023/8023 [==============================] - 5s 599us/step - loss: 1.5374 - accuracy: 0.0934 - val_loss: 1.1589 - val_accuracy: 0.0952\n",
      "Epoch 47/50\n",
      "8023/8023 [==============================] - 5s 587us/step - loss: 1.5426 - accuracy: 0.0982 - val_loss: 1.1908 - val_accuracy: 0.0992\n",
      "Epoch 48/50\n",
      "8023/8023 [==============================] - 4s 525us/step - loss: 1.5353 - accuracy: 0.0962 - val_loss: 1.1597 - val_accuracy: 0.0952\n",
      "Epoch 49/50\n",
      "8023/8023 [==============================] - 4s 511us/step - loss: 1.5369 - accuracy: 0.0998 - val_loss: 1.2986 - val_accuracy: 0.0947\n",
      "Epoch 50/50\n",
      "8023/8023 [==============================] - 4s 501us/step - loss: 1.5261 - accuracy: 0.0962 - val_loss: 1.1882 - val_accuracy: 0.0927\n",
      "the NMAE for learning rate= 0.001 is: ReadsAvg    0.028833\n",
      "ReadsAvg    0.028834\n",
      "ReadsAvg    0.028835\n",
      "ReadsAvg    0.028835\n",
      "ReadsAvg    0.028835\n",
      "ReadsAvg    0.028836\n",
      "ReadsAvg    0.028836\n",
      "ReadsAvg    0.028837\n",
      "ReadsAvg    0.028838\n",
      "ReadsAvg    0.028838\n",
      "ReadsAvg    0.028839\n",
      "dtype: float64\n",
      "Train on 8023 samples, validate on 2006 samples\n",
      "Epoch 1/50\n",
      "8023/8023 [==============================] - 9s 1ms/step - loss: 55.9777 - accuracy: 0.0881 - val_loss: 54.8106 - val_accuracy: 0.0887\n",
      "Epoch 2/50\n",
      "8023/8023 [==============================] - 5s 601us/step - loss: 53.1932 - accuracy: 0.0877 - val_loss: 47.9532 - val_accuracy: 0.0907\n",
      "Epoch 3/50\n",
      "8023/8023 [==============================] - 5s 572us/step - loss: 35.8172 - accuracy: 0.0854 - val_loss: 29.9669 - val_accuracy: 0.0902\n",
      "Epoch 4/50\n",
      "8023/8023 [==============================] - 4s 534us/step - loss: 26.1615 - accuracy: 0.0870 - val_loss: 26.9881 - val_accuracy: 0.0892\n",
      "Epoch 5/50\n",
      "8023/8023 [==============================] - 4s 518us/step - loss: 25.1219 - accuracy: 0.0896 - val_loss: 26.1323 - val_accuracy: 0.0892\n",
      "Epoch 6/50\n",
      "8023/8023 [==============================] - 4s 503us/step - loss: 24.4154 - accuracy: 0.0895 - val_loss: 25.5135 - val_accuracy: 0.0917\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8023/8023 [==============================] - 4s 521us/step - loss: 23.8722 - accuracy: 0.0936 - val_loss: 24.8611 - val_accuracy: 0.0867\n",
      "Epoch 8/50\n",
      "8023/8023 [==============================] - 4s 515us/step - loss: 23.1571 - accuracy: 0.0919 - val_loss: 24.2300 - val_accuracy: 0.0877\n",
      "Epoch 9/50\n",
      "8023/8023 [==============================] - 4s 519us/step - loss: 22.7896 - accuracy: 0.0885 - val_loss: 23.8058 - val_accuracy: 0.0932\n",
      "Epoch 10/50\n",
      "8023/8023 [==============================] - 4s 535us/step - loss: 22.1401 - accuracy: 0.0871 - val_loss: 23.0521 - val_accuracy: 0.0882\n",
      "Epoch 11/50\n",
      "8023/8023 [==============================] - 4s 525us/step - loss: 21.3528 - accuracy: 0.0912 - val_loss: 22.5400 - val_accuracy: 0.0897\n",
      "Epoch 12/50\n",
      "8023/8023 [==============================] - 4s 466us/step - loss: 21.0375 - accuracy: 0.0869 - val_loss: 21.9877 - val_accuracy: 0.0937\n",
      "Epoch 13/50\n",
      "8023/8023 [==============================] - 4s 536us/step - loss: 20.6506 - accuracy: 0.0843 - val_loss: 21.3039 - val_accuracy: 0.0917\n",
      "Epoch 14/50\n",
      "8023/8023 [==============================] - 5s 627us/step - loss: 20.0339 - accuracy: 0.0907 - val_loss: 20.7184 - val_accuracy: 0.0892\n",
      "Epoch 15/50\n",
      "8023/8023 [==============================] - 5s 578us/step - loss: 19.5148 - accuracy: 0.0945 - val_loss: 20.1050 - val_accuracy: 0.0897\n",
      "Epoch 16/50\n",
      "8023/8023 [==============================] - 4s 559us/step - loss: 18.9161 - accuracy: 0.0925 - val_loss: 19.3105 - val_accuracy: 0.0907\n",
      "Epoch 17/50\n",
      "8023/8023 [==============================] - 5s 638us/step - loss: 18.0075 - accuracy: 0.0879 - val_loss: 18.5979 - val_accuracy: 0.0847\n",
      "Epoch 18/50\n",
      "8023/8023 [==============================] - 5s 593us/step - loss: 17.4011 - accuracy: 0.0906 - val_loss: 17.8117 - val_accuracy: 0.0867\n",
      "Epoch 19/50\n",
      "8023/8023 [==============================] - 5s 607us/step - loss: 16.7820 - accuracy: 0.0860 - val_loss: 17.0863 - val_accuracy: 0.0847\n",
      "Epoch 20/50\n",
      "8023/8023 [==============================] - 5s 599us/step - loss: 16.0251 - accuracy: 0.0881 - val_loss: 16.3437 - val_accuracy: 0.0842\n",
      "Epoch 21/50\n",
      "8023/8023 [==============================] - 5s 583us/step - loss: 15.3128 - accuracy: 0.0863 - val_loss: 15.4204 - val_accuracy: 0.0833\n",
      "Epoch 22/50\n",
      "8023/8023 [==============================] - 5s 572us/step - loss: 14.5938 - accuracy: 0.0906 - val_loss: 14.6071 - val_accuracy: 0.0818\n",
      "Epoch 23/50\n",
      "8023/8023 [==============================] - 4s 554us/step - loss: 13.7206 - accuracy: 0.0886 - val_loss: 13.5596 - val_accuracy: 0.0808\n",
      "Epoch 24/50\n",
      "8023/8023 [==============================] - 4s 548us/step - loss: 12.9476 - accuracy: 0.0886 - val_loss: 12.5031 - val_accuracy: 0.0833\n",
      "Epoch 25/50\n",
      "8023/8023 [==============================] - 4s 558us/step - loss: 11.9689 - accuracy: 0.0881 - val_loss: 11.5366 - val_accuracy: 0.0833\n",
      "Epoch 26/50\n",
      "8023/8023 [==============================] - 5s 593us/step - loss: 11.0210 - accuracy: 0.0906 - val_loss: 10.4057 - val_accuracy: 0.0837\n",
      "Epoch 27/50\n",
      "8023/8023 [==============================] - 4s 525us/step - loss: 10.0560 - accuracy: 0.0935 - val_loss: 9.2675 - val_accuracy: 0.0862\n",
      "Epoch 28/50\n",
      "8023/8023 [==============================] - 4s 505us/step - loss: 8.8819 - accuracy: 0.0889 - val_loss: 7.9687 - val_accuracy: 0.0842\n",
      "Epoch 29/50\n",
      "8023/8023 [==============================] - 4s 505us/step - loss: 7.6956 - accuracy: 0.0914 - val_loss: 6.4794 - val_accuracy: 0.0857\n",
      "Epoch 30/50\n",
      "8023/8023 [==============================] - 4s 508us/step - loss: 6.5695 - accuracy: 0.0907 - val_loss: 5.1406 - val_accuracy: 0.0887\n",
      "Epoch 31/50\n",
      "8023/8023 [==============================] - 4s 514us/step - loss: 5.4099 - accuracy: 0.0921 - val_loss: 3.6771 - val_accuracy: 0.0892\n",
      "Epoch 32/50\n",
      "8023/8023 [==============================] - 4s 512us/step - loss: 4.4328 - accuracy: 0.0947 - val_loss: 2.6495 - val_accuracy: 0.0837\n",
      "Epoch 33/50\n",
      "8023/8023 [==============================] - 5s 562us/step - loss: 3.7675 - accuracy: 0.0889 - val_loss: 2.1268 - val_accuracy: 0.0897\n",
      "Epoch 34/50\n",
      "8023/8023 [==============================] - 4s 509us/step - loss: 3.3732 - accuracy: 0.0920 - val_loss: 1.7821 - val_accuracy: 0.0852\n",
      "Epoch 35/50\n",
      "8023/8023 [==============================] - 4s 516us/step - loss: 3.1391 - accuracy: 0.0939 - val_loss: 1.6694 - val_accuracy: 0.0877\n",
      "Epoch 36/50\n",
      "8023/8023 [==============================] - 4s 518us/step - loss: 3.0138 - accuracy: 0.0907 - val_loss: 1.6094 - val_accuracy: 0.0862\n",
      "Epoch 37/50\n",
      "8023/8023 [==============================] - 4s 509us/step - loss: 2.9137 - accuracy: 0.0896 - val_loss: 1.5541 - val_accuracy: 0.0852\n",
      "Epoch 38/50\n",
      "8023/8023 [==============================] - 4s 498us/step - loss: 2.8651 - accuracy: 0.0881 - val_loss: 1.4123 - val_accuracy: 0.0872\n",
      "Epoch 39/50\n",
      "8023/8023 [==============================] - 4s 500us/step - loss: 2.7786 - accuracy: 0.0880 - val_loss: 1.3777 - val_accuracy: 0.0877\n",
      "Epoch 40/50\n",
      "8023/8023 [==============================] - 4s 506us/step - loss: 2.7253 - accuracy: 0.0907 - val_loss: 1.3537 - val_accuracy: 0.0927\n",
      "Epoch 41/50\n",
      "8023/8023 [==============================] - 4s 507us/step - loss: 2.6826 - accuracy: 0.0869 - val_loss: 1.3286 - val_accuracy: 0.0952\n",
      "Epoch 42/50\n",
      "8023/8023 [==============================] - 4s 518us/step - loss: 2.6017 - accuracy: 0.0931 - val_loss: 1.3226 - val_accuracy: 0.0917\n",
      "Epoch 43/50\n",
      "8023/8023 [==============================] - 4s 506us/step - loss: 2.5867 - accuracy: 0.0900 - val_loss: 1.2779 - val_accuracy: 0.0987\n",
      "Epoch 44/50\n",
      "8023/8023 [==============================] - 4s 509us/step - loss: 2.5338 - accuracy: 0.0916 - val_loss: 1.2734 - val_accuracy: 0.0937\n",
      "Epoch 45/50\n",
      "8023/8023 [==============================] - 5s 566us/step - loss: 2.4668 - accuracy: 0.0950 - val_loss: 1.2534 - val_accuracy: 0.0972\n",
      "Epoch 46/50\n",
      "8023/8023 [==============================] - 4s 506us/step - loss: 2.4609 - accuracy: 0.0921 - val_loss: 1.2496 - val_accuracy: 0.0907\n",
      "Epoch 47/50\n",
      "8023/8023 [==============================] - 4s 497us/step - loss: 2.4183 - accuracy: 0.0971 - val_loss: 1.2342 - val_accuracy: 0.0937\n",
      "Epoch 48/50\n",
      "8023/8023 [==============================] - 4s 548us/step - loss: 2.3829 - accuracy: 0.0902 - val_loss: 1.2303 - val_accuracy: 0.0922\n",
      "Epoch 49/50\n",
      "8023/8023 [==============================] - 5s 567us/step - loss: 2.3293 - accuracy: 0.0920 - val_loss: 1.2305 - val_accuracy: 0.0972\n",
      "Epoch 50/50\n",
      "8023/8023 [==============================] - 5s 567us/step - loss: 2.3393 - accuracy: 0.0931 - val_loss: 1.2364 - val_accuracy: 0.0927\n",
      "the NMAE for learning rate= 0.0001 is: ReadsAvg    0.029736\n",
      "ReadsAvg    0.029738\n",
      "ReadsAvg    0.029738\n",
      "ReadsAvg    0.029738\n",
      "ReadsAvg    0.029739\n",
      "ReadsAvg    0.029739\n",
      "ReadsAvg    0.029740\n",
      "ReadsAvg    0.029741\n",
      "ReadsAvg    0.029741\n",
      "ReadsAvg    0.029742\n",
      "ReadsAvg    0.029743\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#tuning learning parameters\n",
    "Rnn_xtrain, Rnn_ytrain = fetch_data(X_train, Y_train, 11, 1)\n",
    "Rnn_xtest, Rnn_ytest = fetch_data(X_test, Y_test, 11, 1)\n",
    "Rnn_model = LSTM_tune_learningrate(Rnn_xtrain, Rnn_ytrain,Rnn_xtest, Rnn_ytest, 1, 11, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ca1d3dd118f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# unable to fetch input to model data for l=0 -Reshape error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRnn_xtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRnn_ytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mRnn_xtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRnn_ytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mRnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_tune_learningrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRnn_xtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRnn_ytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mRnn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRnn_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRnn_xtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# unable to fetch input to model data for l=0 -Reshape error\n",
    "Rnn_xtrain, Rnn_ytrain = fetch_data(X_train, Y_train, 11, 0)\n",
    "Rnn_xtest, Rnn_ytest = fetch_data(X_test, Y_test, 11, 0)\n",
    "Rnn_model = LSTM_tune_learningrate(Rnn_xtrain, Rnn_ytrain, 0, 11, 16)\n",
    "Rnn_test = Rnn_reshape(Rnn_xtest, 0, 16)\n",
    "Rnn_pred = Rnn_model.predict(Rnn_test,verbose=0)\n",
    "nmaes_l = nmaes_array(Rnn_ytest, Rnn_pred, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best hyper parameters are : learning rate: 0.01; epochs: 50; batch_size: 32; nodes: 50;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to step 7 of Task I, for values of l = 0,...,10 and h = 0,...,10 train LSTM models. Evaluate\n",
    "the models by computing the error (NMAE) on the test set. Display the results in a table with rows\n",
    "representing the time horizon h = 0,...,10 and columns representing the lag l = 0,...,10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 4s 8ms/step - loss: 13.1934 - accuracy: 0.0940 - val_loss: 2.9848 - val_accuracy: 0.0922\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 3.3384 - accuracy: 0.0951 - val_loss: 1.6815 - val_accuracy: 0.0967\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 2.2604 - accuracy: 0.0996 - val_loss: 1.2519 - val_accuracy: 0.0962\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.7592 - accuracy: 0.0963 - val_loss: 1.2017 - val_accuracy: 0.0867\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.6039 - accuracy: 0.0960 - val_loss: 1.1953 - val_accuracy: 0.0997\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5820 - accuracy: 0.0981 - val_loss: 1.1999 - val_accuracy: 0.0992\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5927 - accuracy: 0.0941 - val_loss: 1.2923 - val_accuracy: 0.0922\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5778 - accuracy: 0.0936 - val_loss: 1.2045 - val_accuracy: 0.0842\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5781 - accuracy: 0.0926 - val_loss: 1.2461 - val_accuracy: 0.1007\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5739 - accuracy: 0.0896 - val_loss: 1.1914 - val_accuracy: 0.0877\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5581 - accuracy: 0.0983 - val_loss: 1.2232 - val_accuracy: 0.0992\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5706 - accuracy: 0.0961 - val_loss: 1.1950 - val_accuracy: 0.0967\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5544 - accuracy: 0.0990 - val_loss: 1.1938 - val_accuracy: 0.0942\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5564 - accuracy: 0.0991 - val_loss: 1.1679 - val_accuracy: 0.0912\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5565 - accuracy: 0.0958 - val_loss: 1.2158 - val_accuracy: 0.0837\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5468 - accuracy: 0.0966 - val_loss: 1.2605 - val_accuracy: 0.1032\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5412 - accuracy: 0.0981 - val_loss: 1.2078 - val_accuracy: 0.0932\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5709 - accuracy: 0.0869 - val_loss: 1.1974 - val_accuracy: 0.0947\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5387 - accuracy: 0.0914 - val_loss: 1.2265 - val_accuracy: 0.0887\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5481 - accuracy: 0.0971 - val_loss: 1.1824 - val_accuracy: 0.1032\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5479 - accuracy: 0.0924 - val_loss: 1.2125 - val_accuracy: 0.0932\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5399 - accuracy: 0.0954 - val_loss: 1.2570 - val_accuracy: 0.0902\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5307 - accuracy: 0.0936 - val_loss: 1.2223 - val_accuracy: 0.0892\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5400 - accuracy: 0.0977 - val_loss: 1.2477 - val_accuracy: 0.0872\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5489 - accuracy: 0.0947 - val_loss: 1.1696 - val_accuracy: 0.1012\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5500 - accuracy: 0.0977 - val_loss: 1.1864 - val_accuracy: 0.0987\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5371 - accuracy: 0.0955 - val_loss: 1.2068 - val_accuracy: 0.0882\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5396 - accuracy: 0.0966 - val_loss: 1.1793 - val_accuracy: 0.0887\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5301 - accuracy: 0.0937 - val_loss: 1.1880 - val_accuracy: 0.0932\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5336 - accuracy: 0.0926 - val_loss: 1.2039 - val_accuracy: 0.1052\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5293 - accuracy: 0.0961 - val_loss: 1.2209 - val_accuracy: 0.0912\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5276 - accuracy: 0.0968 - val_loss: 1.1832 - val_accuracy: 0.0927\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5245 - accuracy: 0.0962 - val_loss: 1.1826 - val_accuracy: 0.1052\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5280 - accuracy: 0.1000 - val_loss: 1.2039 - val_accuracy: 0.0877\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5207 - accuracy: 0.1027 - val_loss: 1.2047 - val_accuracy: 0.0947\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5249 - accuracy: 0.0937 - val_loss: 1.1790 - val_accuracy: 0.0987\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5339 - accuracy: 0.0967 - val_loss: 1.1818 - val_accuracy: 0.0852\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5185 - accuracy: 0.0995 - val_loss: 1.2127 - val_accuracy: 0.0897\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5319 - accuracy: 0.0931 - val_loss: 1.1900 - val_accuracy: 0.0927\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5342 - accuracy: 0.0954 - val_loss: 1.1752 - val_accuracy: 0.0852\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5272 - accuracy: 0.0983 - val_loss: 1.2435 - val_accuracy: 0.0837\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5214 - accuracy: 0.0911 - val_loss: 1.1989 - val_accuracy: 0.0852\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5525 - accuracy: 0.0981 - val_loss: 1.2752 - val_accuracy: 0.0857\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5140 - accuracy: 0.0940 - val_loss: 1.2026 - val_accuracy: 0.0897\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5180 - accuracy: 0.0976 - val_loss: 1.1925 - val_accuracy: 0.0872\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5212 - accuracy: 0.0945 - val_loss: 1.2111 - val_accuracy: 0.0867\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5148 - accuracy: 0.0954 - val_loss: 1.2170 - val_accuracy: 0.0957\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 1.5187 - accuracy: 0.0931 - val_loss: 1.2314 - val_accuracy: 0.0857\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5185 - accuracy: 0.0992 - val_loss: 1.1877 - val_accuracy: 0.0852\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 1s 5ms/step - loss: 1.5051 - accuracy: 0.1032 - val_loss: 1.2537 - val_accuracy: 0.0987\n",
      "    nmaes_l0\n",
      "0   0.026367\n",
      "1   0.028450\n",
      "2   0.028953\n",
      "3   0.029804\n",
      "4   0.029093\n",
      "5   0.030503\n",
      "6   0.029115\n",
      "7   0.028812\n",
      "8   0.029688\n",
      "9   0.029247\n",
      "10  0.029210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 5s 9ms/step - loss: 9.7274 - accuracy: 0.0893 - val_loss: 1.7467 - val_accuracy: 0.0847\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 2.0399 - accuracy: 0.0914 - val_loss: 1.2723 - val_accuracy: 0.0937\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.7843 - accuracy: 0.0922 - val_loss: 1.2326 - val_accuracy: 0.0942\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.6626 - accuracy: 0.0960 - val_loss: 1.2901 - val_accuracy: 0.0967\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.6547 - accuracy: 0.0992 - val_loss: 1.2788 - val_accuracy: 0.0967\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.6048 - accuracy: 0.0922 - val_loss: 1.2149 - val_accuracy: 0.1092\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5696 - accuracy: 0.0997 - val_loss: 1.2148 - val_accuracy: 0.0942\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5939 - accuracy: 0.0969 - val_loss: 1.2075 - val_accuracy: 0.0937\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.6010 - accuracy: 0.0976 - val_loss: 1.2825 - val_accuracy: 0.0967\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.6064 - accuracy: 0.0954 - val_loss: 1.2134 - val_accuracy: 0.0992\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5972 - accuracy: 0.1003 - val_loss: 1.2057 - val_accuracy: 0.0982\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5597 - accuracy: 0.1003 - val_loss: 1.3152 - val_accuracy: 0.0957\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5715 - accuracy: 0.0926 - val_loss: 1.4052 - val_accuracy: 0.1007\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5617 - accuracy: 0.0955 - val_loss: 1.2880 - val_accuracy: 0.0912\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5494 - accuracy: 0.1006 - val_loss: 1.1847 - val_accuracy: 0.0967\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5531 - accuracy: 0.1051 - val_loss: 1.1703 - val_accuracy: 0.0952\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5381 - accuracy: 0.0995 - val_loss: 1.2433 - val_accuracy: 0.0917\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5654 - accuracy: 0.0976 - val_loss: 1.2403 - val_accuracy: 0.1007\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5544 - accuracy: 0.1038 - val_loss: 1.2535 - val_accuracy: 0.0992\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5846 - accuracy: 0.0940 - val_loss: 1.3641 - val_accuracy: 0.1052\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5484 - accuracy: 0.0970 - val_loss: 1.2990 - val_accuracy: 0.1087\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5366 - accuracy: 0.0924 - val_loss: 1.1966 - val_accuracy: 0.0972\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5486 - accuracy: 0.0975 - val_loss: 1.4071 - val_accuracy: 0.0912\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5424 - accuracy: 0.0972 - val_loss: 1.2138 - val_accuracy: 0.1022\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5577 - accuracy: 0.0899 - val_loss: 1.2363 - val_accuracy: 0.0907\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5426 - accuracy: 0.1012 - val_loss: 1.2361 - val_accuracy: 0.0897\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5299 - accuracy: 0.1027 - val_loss: 1.2393 - val_accuracy: 0.0977\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5387 - accuracy: 0.0951 - val_loss: 1.2063 - val_accuracy: 0.0927\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5263 - accuracy: 0.0992 - val_loss: 1.1854 - val_accuracy: 0.0982\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5347 - accuracy: 0.0989 - val_loss: 1.2609 - val_accuracy: 0.0922\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5411 - accuracy: 0.0976 - val_loss: 1.5994 - val_accuracy: 0.0922\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5525 - accuracy: 0.0979 - val_loss: 1.2450 - val_accuracy: 0.0937\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5307 - accuracy: 0.1005 - val_loss: 1.2002 - val_accuracy: 0.0927\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5256 - accuracy: 0.0981 - val_loss: 1.2340 - val_accuracy: 0.0907\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5301 - accuracy: 0.0972 - val_loss: 1.2558 - val_accuracy: 0.0927\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5254 - accuracy: 0.0975 - val_loss: 1.3114 - val_accuracy: 0.0932\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5210 - accuracy: 0.0992 - val_loss: 1.1985 - val_accuracy: 0.1062\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5347 - accuracy: 0.0990 - val_loss: 1.2448 - val_accuracy: 0.1047\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5403 - accuracy: 0.0984 - val_loss: 1.1877 - val_accuracy: 0.0912\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 1.5870 - accuracy: 0.1038 - val_loss: 1.5505 - val_accuracy: 0.0962\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 1.5395 - accuracy: 0.0990 - val_loss: 1.1744 - val_accuracy: 0.0917\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5578 - accuracy: 0.1001 - val_loss: 1.2792 - val_accuracy: 0.0912\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5341 - accuracy: 0.0994 - val_loss: 1.1906 - val_accuracy: 0.0902\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5322 - accuracy: 0.0937 - val_loss: 1.1793 - val_accuracy: 0.0897\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5221 - accuracy: 0.1022 - val_loss: 1.2356 - val_accuracy: 0.1022\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 1.5330 - accuracy: 0.0972 - val_loss: 1.1685 - val_accuracy: 0.0997\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5392 - accuracy: 0.0987 - val_loss: 1.2220 - val_accuracy: 0.0977\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5173 - accuracy: 0.1003 - val_loss: 1.3864 - val_accuracy: 0.1017\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 1.5186 - accuracy: 0.0957 - val_loss: 1.3333 - val_accuracy: 0.1102\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5097 - accuracy: 0.1005 - val_loss: 1.2044 - val_accuracy: 0.0927\n",
      "    nmaes_l0  nmaes_l1\n",
      "0   0.026367  0.026595\n",
      "1   0.028450  0.028987\n",
      "2   0.028953  0.026854\n",
      "3   0.029804  0.030055\n",
      "4   0.029093  0.028284\n",
      "5   0.030503  0.028401\n",
      "6   0.029115  0.028414\n",
      "7   0.028812  0.029579\n",
      "8   0.029688  0.028476\n",
      "9   0.029247  0.029237\n",
      "10  0.029210  0.028866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 5s 9ms/step - loss: 6.5952 - accuracy: 0.0865 - val_loss: 1.6149 - val_accuracy: 0.0892\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.7993 - accuracy: 0.0931 - val_loss: 1.2780 - val_accuracy: 0.0967\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.7126 - accuracy: 0.0916 - val_loss: 1.2218 - val_accuracy: 0.1097\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.7205 - accuracy: 0.0950 - val_loss: 1.4960 - val_accuracy: 0.0932\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.6085 - accuracy: 0.0984 - val_loss: 1.5126 - val_accuracy: 0.0887\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.6434 - accuracy: 0.0934 - val_loss: 1.2721 - val_accuracy: 0.0942\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5839 - accuracy: 0.0961 - val_loss: 1.2286 - val_accuracy: 0.0902\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.6083 - accuracy: 0.0925 - val_loss: 1.1996 - val_accuracy: 0.0912\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.6084 - accuracy: 0.0965 - val_loss: 1.2807 - val_accuracy: 0.0937\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5886 - accuracy: 0.0986 - val_loss: 1.3161 - val_accuracy: 0.0982\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5770 - accuracy: 0.1009 - val_loss: 1.4436 - val_accuracy: 0.0972\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5758 - accuracy: 0.0943 - val_loss: 1.2337 - val_accuracy: 0.0962\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5713 - accuracy: 0.0972 - val_loss: 1.2483 - val_accuracy: 0.0922\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5706 - accuracy: 0.1020 - val_loss: 1.2270 - val_accuracy: 0.0977\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5742 - accuracy: 0.0918 - val_loss: 1.1924 - val_accuracy: 0.0947\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5338 - accuracy: 0.0960 - val_loss: 1.1788 - val_accuracy: 0.0987\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5765 - accuracy: 0.0962 - val_loss: 1.2095 - val_accuracy: 0.0887\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5450 - accuracy: 0.0949 - val_loss: 1.4844 - val_accuracy: 0.0972\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5274 - accuracy: 0.0936 - val_loss: 1.3017 - val_accuracy: 0.0932\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5455 - accuracy: 0.1020 - val_loss: 1.2595 - val_accuracy: 0.1077\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5571 - accuracy: 0.0974 - val_loss: 1.4755 - val_accuracy: 0.0957\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5511 - accuracy: 0.0924 - val_loss: 1.1760 - val_accuracy: 0.0947\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5335 - accuracy: 0.0924 - val_loss: 1.3593 - val_accuracy: 0.0887\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5845 - accuracy: 0.0966 - val_loss: 1.1774 - val_accuracy: 0.0957\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5857 - accuracy: 0.0955 - val_loss: 1.2446 - val_accuracy: 0.0867\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5310 - accuracy: 0.0954 - val_loss: 1.1833 - val_accuracy: 0.0967\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5575 - accuracy: 0.0980 - val_loss: 1.2741 - val_accuracy: 0.0937\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5495 - accuracy: 0.0936 - val_loss: 1.2003 - val_accuracy: 0.0897\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5478 - accuracy: 0.0975 - val_loss: 1.1683 - val_accuracy: 0.0997\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5652 - accuracy: 0.0936 - val_loss: 1.1743 - val_accuracy: 0.1047\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5153 - accuracy: 0.0960 - val_loss: 1.3193 - val_accuracy: 0.1057\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5384 - accuracy: 0.0944 - val_loss: 1.2099 - val_accuracy: 0.0932\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 1.5223 - accuracy: 0.0994 - val_loss: 1.1973 - val_accuracy: 0.1002\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5269 - accuracy: 0.0934 - val_loss: 1.2093 - val_accuracy: 0.0897\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5541 - accuracy: 0.0994 - val_loss: 1.2604 - val_accuracy: 0.0892\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5249 - accuracy: 0.1066 - val_loss: 1.2274 - val_accuracy: 0.0917\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5316 - accuracy: 0.0949 - val_loss: 1.2025 - val_accuracy: 0.0942\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5439 - accuracy: 0.0951 - val_loss: 1.1722 - val_accuracy: 0.0867\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5557 - accuracy: 0.0944 - val_loss: 1.1655 - val_accuracy: 0.0942\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5202 - accuracy: 0.0967 - val_loss: 1.2135 - val_accuracy: 0.0987\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5374 - accuracy: 0.0985 - val_loss: 1.2623 - val_accuracy: 0.0912\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5453 - accuracy: 0.0971 - val_loss: 1.2054 - val_accuracy: 0.0917\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5428 - accuracy: 0.0960 - val_loss: 1.1944 - val_accuracy: 0.0942\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5075 - accuracy: 0.0965 - val_loss: 1.2933 - val_accuracy: 0.0992\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5147 - accuracy: 0.1027 - val_loss: 1.2210 - val_accuracy: 0.0962\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5122 - accuracy: 0.0992 - val_loss: 1.2487 - val_accuracy: 0.0937\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5103 - accuracy: 0.0995 - val_loss: 1.2367 - val_accuracy: 0.0987\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5094 - accuracy: 0.1001 - val_loss: 1.1931 - val_accuracy: 0.0992\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5101 - accuracy: 0.0977 - val_loss: 1.1804 - val_accuracy: 0.1002\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 1.5322 - accuracy: 0.0921 - val_loss: 1.3015 - val_accuracy: 0.0937\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2\n",
      "0   0.026367  0.026595  0.028552\n",
      "1   0.028450  0.028987  0.026366\n",
      "2   0.028953  0.026854  0.027764\n",
      "3   0.029804  0.030055  0.027852\n",
      "4   0.029093  0.028284  0.028251\n",
      "5   0.030503  0.028401  0.028396\n",
      "6   0.029115  0.028414  0.028836\n",
      "7   0.028812  0.029579  0.028265\n",
      "8   0.029688  0.028476  0.028658\n",
      "9   0.029247  0.029237  0.031558\n",
      "10  0.029210  0.028866  0.030199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 5s 11ms/step - loss: 6.9749 - accuracy: 0.0929 - val_loss: 1.2898 - val_accuracy: 0.0922\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.8912 - accuracy: 0.0963 - val_loss: 1.2273 - val_accuracy: 0.0947\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.6860 - accuracy: 0.0915 - val_loss: 1.2708 - val_accuracy: 0.0882\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.6303 - accuracy: 0.1005 - val_loss: 1.2587 - val_accuracy: 0.0987\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.6513 - accuracy: 0.1030 - val_loss: 1.2413 - val_accuracy: 0.0897\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.6349 - accuracy: 0.1009 - val_loss: 1.3071 - val_accuracy: 0.0937\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5779 - accuracy: 0.0954 - val_loss: 1.2423 - val_accuracy: 0.1017\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5909 - accuracy: 0.0986 - val_loss: 1.5797 - val_accuracy: 0.0982\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5828 - accuracy: 0.0956 - val_loss: 1.3020 - val_accuracy: 0.1052\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5677 - accuracy: 0.1009 - val_loss: 1.2362 - val_accuracy: 0.1007\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5624 - accuracy: 0.0971 - val_loss: 1.1645 - val_accuracy: 0.1007\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5752 - accuracy: 0.0945 - val_loss: 1.8512 - val_accuracy: 0.0972\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5868 - accuracy: 0.1011 - val_loss: 1.2013 - val_accuracy: 0.1117\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5918 - accuracy: 0.0976 - val_loss: 1.6169 - val_accuracy: 0.0952\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5846 - accuracy: 0.0988 - val_loss: 1.2010 - val_accuracy: 0.1047\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5879 - accuracy: 0.1016 - val_loss: 1.3115 - val_accuracy: 0.0947\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5954 - accuracy: 0.1047 - val_loss: 1.6545 - val_accuracy: 0.0937\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5827 - accuracy: 0.0963 - val_loss: 1.2223 - val_accuracy: 0.1007\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5140 - accuracy: 0.0963 - val_loss: 1.2448 - val_accuracy: 0.0987\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5264 - accuracy: 0.1047 - val_loss: 1.3454 - val_accuracy: 0.0952\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5313 - accuracy: 0.1035 - val_loss: 1.3272 - val_accuracy: 0.1012\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5273 - accuracy: 0.0985 - val_loss: 1.5178 - val_accuracy: 0.1042\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5514 - accuracy: 0.0984 - val_loss: 1.1867 - val_accuracy: 0.1042\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5230 - accuracy: 0.0935 - val_loss: 1.4863 - val_accuracy: 0.0917\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5478 - accuracy: 0.1064 - val_loss: 1.4194 - val_accuracy: 0.1027\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5413 - accuracy: 0.1032 - val_loss: 1.1936 - val_accuracy: 0.0902\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5735 - accuracy: 0.1000 - val_loss: 1.2057 - val_accuracy: 0.0957\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5120 - accuracy: 0.1052 - val_loss: 1.1790 - val_accuracy: 0.1052\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5264 - accuracy: 0.1022 - val_loss: 1.1855 - val_accuracy: 0.0977\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5359 - accuracy: 0.1010 - val_loss: 1.2739 - val_accuracy: 0.1117\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5390 - accuracy: 0.1002 - val_loss: 1.2170 - val_accuracy: 0.1067\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5233 - accuracy: 0.1015 - val_loss: 1.2142 - val_accuracy: 0.1077\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5714 - accuracy: 0.1020 - val_loss: 1.5052 - val_accuracy: 0.1077\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5314 - accuracy: 0.1035 - val_loss: 1.2720 - val_accuracy: 0.0952\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5208 - accuracy: 0.0926 - val_loss: 1.1697 - val_accuracy: 0.0952\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5013 - accuracy: 0.1026 - val_loss: 1.2789 - val_accuracy: 0.0962\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.4946 - accuracy: 0.0985 - val_loss: 1.1874 - val_accuracy: 0.0962\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5199 - accuracy: 0.1027 - val_loss: 1.2799 - val_accuracy: 0.1052\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5206 - accuracy: 0.0989 - val_loss: 1.4394 - val_accuracy: 0.1017\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5172 - accuracy: 0.1031 - val_loss: 1.4892 - val_accuracy: 0.0917\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5022 - accuracy: 0.1060 - val_loss: 1.2328 - val_accuracy: 0.0917\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5099 - accuracy: 0.1046 - val_loss: 1.2020 - val_accuracy: 0.0972\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.4943 - accuracy: 0.1015 - val_loss: 1.1769 - val_accuracy: 0.0967\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5187 - accuracy: 0.0959 - val_loss: 1.1851 - val_accuracy: 0.0962\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5113 - accuracy: 0.1020 - val_loss: 1.1931 - val_accuracy: 0.0957\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.4942 - accuracy: 0.0938 - val_loss: 1.1900 - val_accuracy: 0.0942\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.4986 - accuracy: 0.0983 - val_loss: 1.1657 - val_accuracy: 0.0912\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.5106 - accuracy: 0.0906 - val_loss: 1.2058 - val_accuracy: 0.1017\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.4881 - accuracy: 0.0979 - val_loss: 1.1944 - val_accuracy: 0.1042\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 1.4937 - accuracy: 0.0996 - val_loss: 1.2579 - val_accuracy: 0.0927\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3\n",
      "0   0.026367  0.026595  0.028552  0.028122\n",
      "1   0.028450  0.028987  0.026366  0.025903\n",
      "2   0.028953  0.026854  0.027764  0.027637\n",
      "3   0.029804  0.030055  0.027852  0.027636\n",
      "4   0.029093  0.028284  0.028251  0.028271\n",
      "5   0.030503  0.028401  0.028396  0.027413\n",
      "6   0.029115  0.028414  0.028836  0.027557\n",
      "7   0.028812  0.029579  0.028265  0.027543\n",
      "8   0.029688  0.028476  0.028658  0.030983\n",
      "9   0.029247  0.029237  0.031558  0.029039\n",
      "10  0.029210  0.028866  0.030199  0.027901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 5s 11ms/step - loss: 6.3415 - accuracy: 0.0910 - val_loss: 1.2570 - val_accuracy: 0.0988\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.9684 - accuracy: 0.0963 - val_loss: 1.4150 - val_accuracy: 0.0883\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.7707 - accuracy: 0.0934 - val_loss: 2.1638 - val_accuracy: 0.0908\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.7449 - accuracy: 0.0939 - val_loss: 1.4816 - val_accuracy: 0.0858\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.7541 - accuracy: 0.0938 - val_loss: 1.2205 - val_accuracy: 0.0863\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6758 - accuracy: 0.0975 - val_loss: 1.2987 - val_accuracy: 0.0973\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6360 - accuracy: 0.0946 - val_loss: 1.3173 - val_accuracy: 0.0958\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6606 - accuracy: 0.0996 - val_loss: 1.2054 - val_accuracy: 0.0943\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.7109 - accuracy: 0.0995 - val_loss: 1.2589 - val_accuracy: 0.0938\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6201 - accuracy: 0.0946 - val_loss: 1.3326 - val_accuracy: 0.0933\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5867 - accuracy: 0.0960 - val_loss: 2.0894 - val_accuracy: 0.1052\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6471 - accuracy: 0.1030 - val_loss: 1.3647 - val_accuracy: 0.1077\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6421 - accuracy: 0.1002 - val_loss: 1.1900 - val_accuracy: 0.0898\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5896 - accuracy: 0.0991 - val_loss: 1.2144 - val_accuracy: 0.0893\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5816 - accuracy: 0.0999 - val_loss: 1.3617 - val_accuracy: 0.0913\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5752 - accuracy: 0.0933 - val_loss: 1.3350 - val_accuracy: 0.0938\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5901 - accuracy: 0.0975 - val_loss: 1.2185 - val_accuracy: 0.0873\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5433 - accuracy: 0.1014 - val_loss: 1.5669 - val_accuracy: 0.0943\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5628 - accuracy: 0.0988 - val_loss: 1.2522 - val_accuracy: 0.1007\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5467 - accuracy: 0.0969 - val_loss: 1.3183 - val_accuracy: 0.0933\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.6085 - accuracy: 0.1000 - val_loss: 1.2689 - val_accuracy: 0.0923\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5391 - accuracy: 0.1014 - val_loss: 1.2127 - val_accuracy: 0.0988\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5437 - accuracy: 0.0978 - val_loss: 1.3488 - val_accuracy: 0.0958\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5536 - accuracy: 0.1015 - val_loss: 1.3913 - val_accuracy: 0.0973\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6018 - accuracy: 0.1002 - val_loss: 1.2138 - val_accuracy: 0.1052\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5211 - accuracy: 0.0984 - val_loss: 1.3424 - val_accuracy: 0.1037\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5164 - accuracy: 0.1026 - val_loss: 1.2789 - val_accuracy: 0.1027\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5787 - accuracy: 0.0945 - val_loss: 1.3643 - val_accuracy: 0.1112\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5205 - accuracy: 0.1019 - val_loss: 1.3014 - val_accuracy: 0.1007\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5712 - accuracy: 0.1035 - val_loss: 1.2393 - val_accuracy: 0.0863\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5413 - accuracy: 0.0964 - val_loss: 1.5065 - val_accuracy: 0.0958\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5319 - accuracy: 0.1014 - val_loss: 1.2141 - val_accuracy: 0.1057\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5526 - accuracy: 0.0973 - val_loss: 1.2011 - val_accuracy: 0.0903\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5362 - accuracy: 0.0979 - val_loss: 1.2156 - val_accuracy: 0.1102\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5112 - accuracy: 0.0995 - val_loss: 1.4864 - val_accuracy: 0.0973\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5100 - accuracy: 0.1010 - val_loss: 1.1926 - val_accuracy: 0.0908\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5100 - accuracy: 0.1017 - val_loss: 1.2080 - val_accuracy: 0.0963\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.4974 - accuracy: 0.1022 - val_loss: 1.2120 - val_accuracy: 0.0943\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.5711 - accuracy: 0.1041 - val_loss: 1.2029 - val_accuracy: 0.0943\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5083 - accuracy: 0.0964 - val_loss: 1.1824 - val_accuracy: 0.0968\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5125 - accuracy: 0.0986 - val_loss: 1.1815 - val_accuracy: 0.0998\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5120 - accuracy: 0.1075 - val_loss: 1.3580 - val_accuracy: 0.0928\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5096 - accuracy: 0.0990 - val_loss: 1.1911 - val_accuracy: 0.0913\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.4852 - accuracy: 0.1019 - val_loss: 1.2109 - val_accuracy: 0.0973\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5111 - accuracy: 0.0974 - val_loss: 1.2409 - val_accuracy: 0.0993\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.4906 - accuracy: 0.0999 - val_loss: 1.1827 - val_accuracy: 0.0943\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.5288 - accuracy: 0.1035 - val_loss: 1.1802 - val_accuracy: 0.0943\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.4974 - accuracy: 0.0921 - val_loss: 1.2773 - val_accuracy: 0.0978\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.4912 - accuracy: 0.0965 - val_loss: 1.2501 - val_accuracy: 0.0928\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 1.4947 - accuracy: 0.1012 - val_loss: 1.2602 - val_accuracy: 0.0963\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3  nmaes_l4\n",
      "0   0.026367  0.026595  0.028552  0.028122  0.026822\n",
      "1   0.028450  0.028987  0.026366  0.025903  0.026774\n",
      "2   0.028953  0.026854  0.027764  0.027637  0.028060\n",
      "3   0.029804  0.030055  0.027852  0.027636  0.027801\n",
      "4   0.029093  0.028284  0.028251  0.028271  0.028876\n",
      "5   0.030503  0.028401  0.028396  0.027413  0.031583\n",
      "6   0.029115  0.028414  0.028836  0.027557  0.028279\n",
      "7   0.028812  0.029579  0.028265  0.027543  0.028320\n",
      "8   0.029688  0.028476  0.028658  0.030983  0.028613\n",
      "9   0.029247  0.029237  0.031558  0.029039  0.028627\n",
      "10  0.029210  0.028866  0.030199  0.027901  0.029137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 6s 13ms/step - loss: 5.6930 - accuracy: 0.0933 - val_loss: 1.5069 - val_accuracy: 0.0943\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.8968 - accuracy: 0.0903 - val_loss: 1.2466 - val_accuracy: 0.0958\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.8234 - accuracy: 0.0979 - val_loss: 1.9380 - val_accuracy: 0.0898\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.8012 - accuracy: 0.0968 - val_loss: 2.4784 - val_accuracy: 0.0883\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.7241 - accuracy: 0.0903 - val_loss: 1.2508 - val_accuracy: 0.0933\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.6609 - accuracy: 0.1023 - val_loss: 1.2435 - val_accuracy: 0.0903\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.6390 - accuracy: 0.0994 - val_loss: 1.3894 - val_accuracy: 0.0943\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6175 - accuracy: 0.0953 - val_loss: 1.2810 - val_accuracy: 0.0983\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.6339 - accuracy: 0.0927 - val_loss: 1.4308 - val_accuracy: 0.0948\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.6013 - accuracy: 0.0951 - val_loss: 1.2544 - val_accuracy: 0.0913\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5799 - accuracy: 0.0959 - val_loss: 1.2516 - val_accuracy: 0.0943\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5961 - accuracy: 0.0993 - val_loss: 1.6848 - val_accuracy: 0.1067\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5731 - accuracy: 0.1023 - val_loss: 1.2219 - val_accuracy: 0.1052\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5766 - accuracy: 0.0980 - val_loss: 1.2334 - val_accuracy: 0.1017\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5493 - accuracy: 0.1046 - val_loss: 1.2563 - val_accuracy: 0.0938\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5453 - accuracy: 0.0993 - val_loss: 1.2168 - val_accuracy: 0.0953\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5556 - accuracy: 0.1021 - val_loss: 1.2354 - val_accuracy: 0.0948\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5312 - accuracy: 0.0974 - val_loss: 1.2382 - val_accuracy: 0.0978\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5778 - accuracy: 0.0949 - val_loss: 1.2784 - val_accuracy: 0.0898\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5611 - accuracy: 0.0909 - val_loss: 1.3497 - val_accuracy: 0.0933\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5620 - accuracy: 0.0912 - val_loss: 1.1782 - val_accuracy: 0.1087\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5012 - accuracy: 0.0995 - val_loss: 1.4191 - val_accuracy: 0.0923\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5557 - accuracy: 0.1009 - val_loss: 1.3733 - val_accuracy: 0.0973\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5375 - accuracy: 0.0965 - val_loss: 1.1972 - val_accuracy: 0.1082\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5334 - accuracy: 0.0980 - val_loss: 1.2028 - val_accuracy: 0.0958\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5196 - accuracy: 0.0948 - val_loss: 1.2436 - val_accuracy: 0.0988\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.5261 - accuracy: 0.1011 - val_loss: 1.3649 - val_accuracy: 0.0948\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5013 - accuracy: 0.1008 - val_loss: 1.4586 - val_accuracy: 0.0988\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5241 - accuracy: 0.1014 - val_loss: 1.1976 - val_accuracy: 0.0903\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5062 - accuracy: 0.1056 - val_loss: 1.5001 - val_accuracy: 0.1072\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5479 - accuracy: 0.0971 - val_loss: 1.7410 - val_accuracy: 0.1012\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5045 - accuracy: 0.1018 - val_loss: 1.2122 - val_accuracy: 0.0988\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5536 - accuracy: 0.0994 - val_loss: 1.4296 - val_accuracy: 0.0968\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5060 - accuracy: 0.1008 - val_loss: 1.3154 - val_accuracy: 0.0998\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5176 - accuracy: 0.0986 - val_loss: 1.3420 - val_accuracy: 0.1087\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5020 - accuracy: 0.0983 - val_loss: 1.3237 - val_accuracy: 0.0933\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4906 - accuracy: 0.0970 - val_loss: 1.2075 - val_accuracy: 0.0938\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5088 - accuracy: 0.1005 - val_loss: 1.2229 - val_accuracy: 0.0958\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5002 - accuracy: 0.1005 - val_loss: 1.3502 - val_accuracy: 0.1057\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4744 - accuracy: 0.0974 - val_loss: 1.3076 - val_accuracy: 0.0998\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4844 - accuracy: 0.0945 - val_loss: 1.2202 - val_accuracy: 0.0933\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4826 - accuracy: 0.0989 - val_loss: 1.4007 - val_accuracy: 0.0958\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5088 - accuracy: 0.0991 - val_loss: 1.2660 - val_accuracy: 0.0958\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5546 - accuracy: 0.1015 - val_loss: 1.2155 - val_accuracy: 0.0968\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5220 - accuracy: 0.0985 - val_loss: 1.2493 - val_accuracy: 0.0928\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4980 - accuracy: 0.0969 - val_loss: 1.1910 - val_accuracy: 0.1082\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4805 - accuracy: 0.1000 - val_loss: 1.2713 - val_accuracy: 0.1072\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4979 - accuracy: 0.0956 - val_loss: 1.2001 - val_accuracy: 0.0883\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4837 - accuracy: 0.0933 - val_loss: 1.3211 - val_accuracy: 0.0948\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.4947 - accuracy: 0.0979 - val_loss: 1.1819 - val_accuracy: 0.1072\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3  nmaes_l4  nmaes_l5\n",
      "0   0.026367  0.026595  0.028552  0.028122  0.026822  0.026414\n",
      "1   0.028450  0.028987  0.026366  0.025903  0.026774  0.027577\n",
      "2   0.028953  0.026854  0.027764  0.027637  0.028060  0.027208\n",
      "3   0.029804  0.030055  0.027852  0.027636  0.027801  0.027444\n",
      "4   0.029093  0.028284  0.028251  0.028271  0.028876  0.028015\n",
      "5   0.030503  0.028401  0.028396  0.027413  0.031583  0.027947\n",
      "6   0.029115  0.028414  0.028836  0.027557  0.028279  0.031677\n",
      "7   0.028812  0.029579  0.028265  0.027543  0.028320  0.028183\n",
      "8   0.029688  0.028476  0.028658  0.030983  0.028613  0.028888\n",
      "9   0.029247  0.029237  0.031558  0.029039  0.028627  0.028211\n",
      "10  0.029210  0.028866  0.030199  0.027901  0.029137  0.028341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 6s 15ms/step - loss: 6.9517 - accuracy: 0.0980 - val_loss: 2.3240 - val_accuracy: 0.1052\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.9100 - accuracy: 0.0920 - val_loss: 3.4244 - val_accuracy: 0.0918\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.9088 - accuracy: 0.0928 - val_loss: 2.1578 - val_accuracy: 0.0958\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.9385 - accuracy: 0.0938 - val_loss: 1.4502 - val_accuracy: 0.0898\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.7744 - accuracy: 0.1030 - val_loss: 1.8946 - val_accuracy: 0.1032\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.7131 - accuracy: 0.1000 - val_loss: 1.8450 - val_accuracy: 0.1067\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.6492 - accuracy: 0.0980 - val_loss: 1.2256 - val_accuracy: 0.1022\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.6946 - accuracy: 0.0948 - val_loss: 1.2510 - val_accuracy: 0.0988\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.6159 - accuracy: 0.0987 - val_loss: 1.8101 - val_accuracy: 0.1067\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5690 - accuracy: 0.0982 - val_loss: 1.4762 - val_accuracy: 0.1067\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5626 - accuracy: 0.1039 - val_loss: 1.2267 - val_accuracy: 0.0923\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.6378 - accuracy: 0.0970 - val_loss: 1.2247 - val_accuracy: 0.0938\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5699 - accuracy: 0.0980 - val_loss: 1.2087 - val_accuracy: 0.1002\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5606 - accuracy: 0.1010 - val_loss: 1.6775 - val_accuracy: 0.0963\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5905 - accuracy: 0.0898 - val_loss: 1.3803 - val_accuracy: 0.1067\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.5378 - accuracy: 0.1055 - val_loss: 1.2859 - val_accuracy: 0.0963\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5567 - accuracy: 0.0982 - val_loss: 1.4271 - val_accuracy: 0.0958\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5464 - accuracy: 0.0977 - val_loss: 1.4050 - val_accuracy: 0.0938\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5559 - accuracy: 0.0940 - val_loss: 1.2190 - val_accuracy: 0.1002\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5350 - accuracy: 0.1005 - val_loss: 1.2053 - val_accuracy: 0.0968\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5078 - accuracy: 0.0969 - val_loss: 1.2140 - val_accuracy: 0.0978\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5119 - accuracy: 0.0977 - val_loss: 1.3888 - val_accuracy: 0.0923\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5248 - accuracy: 0.1001 - val_loss: 1.2727 - val_accuracy: 0.0993\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5249 - accuracy: 0.0919 - val_loss: 1.1788 - val_accuracy: 0.1062\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5254 - accuracy: 0.0997 - val_loss: 1.3532 - val_accuracy: 0.0948\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5240 - accuracy: 0.1033 - val_loss: 1.2924 - val_accuracy: 0.0948\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5564 - accuracy: 0.0969 - val_loss: 1.2121 - val_accuracy: 0.1012\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5525 - accuracy: 0.0949 - val_loss: 1.3242 - val_accuracy: 0.1077\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5068 - accuracy: 0.0973 - val_loss: 1.4560 - val_accuracy: 0.0893\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5011 - accuracy: 0.0987 - val_loss: 1.4597 - val_accuracy: 0.0918\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5449 - accuracy: 0.0993 - val_loss: 1.3002 - val_accuracy: 0.0963\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.5695 - accuracy: 0.1030 - val_loss: 1.2571 - val_accuracy: 0.0933\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 1.5619 - accuracy: 0.1011 - val_loss: 1.1614 - val_accuracy: 0.0948\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5202 - accuracy: 0.0977 - val_loss: 1.2034 - val_accuracy: 0.1027\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.4934 - accuracy: 0.1015 - val_loss: 1.1467 - val_accuracy: 0.1032\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5071 - accuracy: 0.0983 - val_loss: 1.2159 - val_accuracy: 0.1042\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5016 - accuracy: 0.0995 - val_loss: 1.4310 - val_accuracy: 0.0983\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5083 - accuracy: 0.1013 - val_loss: 1.2375 - val_accuracy: 0.0938\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4987 - accuracy: 0.0962 - val_loss: 1.1937 - val_accuracy: 0.0993\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.4752 - accuracy: 0.1035 - val_loss: 1.2566 - val_accuracy: 0.0943\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.6247 - accuracy: 0.0999 - val_loss: 2.1175 - val_accuracy: 0.0923\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5091 - accuracy: 0.0980 - val_loss: 1.2491 - val_accuracy: 0.1077\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.4777 - accuracy: 0.0990 - val_loss: 1.2172 - val_accuracy: 0.0943\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.4822 - accuracy: 0.0887 - val_loss: 1.1959 - val_accuracy: 0.0943\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5078 - accuracy: 0.1019 - val_loss: 1.2300 - val_accuracy: 0.0938\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.4905 - accuracy: 0.1048 - val_loss: 1.1815 - val_accuracy: 0.0948\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.5308 - accuracy: 0.0987 - val_loss: 1.1998 - val_accuracy: 0.0913\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.4803 - accuracy: 0.1013 - val_loss: 1.2452 - val_accuracy: 0.0888\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.4935 - accuracy: 0.0993 - val_loss: 1.2426 - val_accuracy: 0.0998\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 1.4919 - accuracy: 0.1000 - val_loss: 1.1831 - val_accuracy: 0.0913\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3  nmaes_l4  nmaes_l5  nmaes_l6\n",
      "0   0.026367  0.026595  0.028552  0.028122  0.026822  0.026414  0.026160\n",
      "1   0.028450  0.028987  0.026366  0.025903  0.026774  0.027577  0.026387\n",
      "2   0.028953  0.026854  0.027764  0.027637  0.028060  0.027208  0.026186\n",
      "3   0.029804  0.030055  0.027852  0.027636  0.027801  0.027444  0.026647\n",
      "4   0.029093  0.028284  0.028251  0.028271  0.028876  0.028015  0.026872\n",
      "5   0.030503  0.028401  0.028396  0.027413  0.031583  0.027947  0.026963\n",
      "6   0.029115  0.028414  0.028836  0.027557  0.028279  0.031677  0.027151\n",
      "7   0.028812  0.029579  0.028265  0.027543  0.028320  0.028183  0.027106\n",
      "8   0.029688  0.028476  0.028658  0.030983  0.028613  0.028888  0.028742\n",
      "9   0.029247  0.029237  0.031558  0.029039  0.028627  0.028211  0.028064\n",
      "10  0.029210  0.028866  0.030199  0.027901  0.029137  0.028341  0.027797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 7s 16ms/step - loss: 5.6049 - accuracy: 0.0931 - val_loss: 2.1454 - val_accuracy: 0.1022\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.9499 - accuracy: 0.0866 - val_loss: 1.2728 - val_accuracy: 0.0908\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.9349 - accuracy: 0.0945 - val_loss: 1.3713 - val_accuracy: 0.0853\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.7573 - accuracy: 0.0901 - val_loss: 1.2636 - val_accuracy: 0.0903\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.7028 - accuracy: 0.0950 - val_loss: 1.4361 - val_accuracy: 0.0918\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.7699 - accuracy: 0.0923 - val_loss: 1.1845 - val_accuracy: 0.0973\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.6102 - accuracy: 0.0891 - val_loss: 1.4798 - val_accuracy: 0.1062\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.6119 - accuracy: 0.0987 - val_loss: 1.2387 - val_accuracy: 0.1067\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.6557 - accuracy: 0.0921 - val_loss: 1.3351 - val_accuracy: 0.0963\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.6406 - accuracy: 0.0988 - val_loss: 1.3905 - val_accuracy: 0.1012\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.6039 - accuracy: 0.0928 - val_loss: 1.4476 - val_accuracy: 0.0888\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.6042 - accuracy: 0.1039 - val_loss: 1.2740 - val_accuracy: 0.1052\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5640 - accuracy: 0.1029 - val_loss: 1.5608 - val_accuracy: 0.0983\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5583 - accuracy: 0.1037 - val_loss: 1.2116 - val_accuracy: 0.1072\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5690 - accuracy: 0.0960 - val_loss: 1.2079 - val_accuracy: 0.1077\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5241 - accuracy: 0.0944 - val_loss: 1.2293 - val_accuracy: 0.1067\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5534 - accuracy: 0.0977 - val_loss: 1.2237 - val_accuracy: 0.1027\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5446 - accuracy: 0.0914 - val_loss: 1.2201 - val_accuracy: 0.0928\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5144 - accuracy: 0.1022 - val_loss: 1.2398 - val_accuracy: 0.0983\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5360 - accuracy: 0.0952 - val_loss: 1.1790 - val_accuracy: 0.1022\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4985 - accuracy: 0.0984 - val_loss: 1.1767 - val_accuracy: 0.0988\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5207 - accuracy: 0.0929 - val_loss: 1.2232 - val_accuracy: 0.1037\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5233 - accuracy: 0.1010 - val_loss: 1.4562 - val_accuracy: 0.0913\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5138 - accuracy: 0.0999 - val_loss: 1.1780 - val_accuracy: 0.0983\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4948 - accuracy: 0.0950 - val_loss: 1.1925 - val_accuracy: 0.0913\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5093 - accuracy: 0.1034 - val_loss: 1.1899 - val_accuracy: 0.0878\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4750 - accuracy: 0.1007 - val_loss: 1.1778 - val_accuracy: 0.1082\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5053 - accuracy: 0.0999 - val_loss: 1.2604 - val_accuracy: 0.0908\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5368 - accuracy: 0.0988 - val_loss: 1.2112 - val_accuracy: 0.1022\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5264 - accuracy: 0.0943 - val_loss: 1.2177 - val_accuracy: 0.0933\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4646 - accuracy: 0.0984 - val_loss: 1.2005 - val_accuracy: 0.0958\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4802 - accuracy: 0.0974 - val_loss: 1.2889 - val_accuracy: 0.1067\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5105 - accuracy: 0.1033 - val_loss: 1.2324 - val_accuracy: 0.1047\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.5443 - accuracy: 0.0975 - val_loss: 1.3520 - val_accuracy: 0.1037\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5129 - accuracy: 0.1007 - val_loss: 1.1872 - val_accuracy: 0.1057\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4968 - accuracy: 0.1023 - val_loss: 1.2252 - val_accuracy: 0.1017\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4871 - accuracy: 0.0949 - val_loss: 1.2121 - val_accuracy: 0.1007\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4873 - accuracy: 0.1034 - val_loss: 1.3860 - val_accuracy: 0.0988\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4880 - accuracy: 0.0992 - val_loss: 1.1918 - val_accuracy: 0.1052\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4667 - accuracy: 0.1063 - val_loss: 1.2143 - val_accuracy: 0.0983\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4658 - accuracy: 0.0972 - val_loss: 1.1830 - val_accuracy: 0.0923\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5183 - accuracy: 0.0929 - val_loss: 1.3189 - val_accuracy: 0.1052\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.5200 - accuracy: 0.0979 - val_loss: 1.2366 - val_accuracy: 0.1027\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4946 - accuracy: 0.0989 - val_loss: 1.2844 - val_accuracy: 0.0963\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4867 - accuracy: 0.1027 - val_loss: 1.3438 - val_accuracy: 0.1012\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5442 - accuracy: 0.1014 - val_loss: 1.1911 - val_accuracy: 0.0923\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 3s 14ms/step - loss: 1.4852 - accuracy: 0.0967 - val_loss: 1.1986 - val_accuracy: 0.1002\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4760 - accuracy: 0.0983 - val_loss: 1.2118 - val_accuracy: 0.1027\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.4666 - accuracy: 0.1000 - val_loss: 1.2081 - val_accuracy: 0.0918\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 4s 14ms/step - loss: 1.6483 - accuracy: 0.0993 - val_loss: 1.1977 - val_accuracy: 0.0913\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3  nmaes_l4  nmaes_l5  nmaes_l6  \\\n",
      "0   0.026367  0.026595  0.028552  0.028122  0.026822  0.026414  0.026160   \n",
      "1   0.028450  0.028987  0.026366  0.025903  0.026774  0.027577  0.026387   \n",
      "2   0.028953  0.026854  0.027764  0.027637  0.028060  0.027208  0.026186   \n",
      "3   0.029804  0.030055  0.027852  0.027636  0.027801  0.027444  0.026647   \n",
      "4   0.029093  0.028284  0.028251  0.028271  0.028876  0.028015  0.026872   \n",
      "5   0.030503  0.028401  0.028396  0.027413  0.031583  0.027947  0.026963   \n",
      "6   0.029115  0.028414  0.028836  0.027557  0.028279  0.031677  0.027151   \n",
      "7   0.028812  0.029579  0.028265  0.027543  0.028320  0.028183  0.027106   \n",
      "8   0.029688  0.028476  0.028658  0.030983  0.028613  0.028888  0.028742   \n",
      "9   0.029247  0.029237  0.031558  0.029039  0.028627  0.028211  0.028064   \n",
      "10  0.029210  0.028866  0.030199  0.027901  0.029137  0.028341  0.027797   \n",
      "\n",
      "    nmaes_l7  \n",
      "0   0.027066  \n",
      "1   0.027864  \n",
      "2   0.028374  \n",
      "3   0.029179  \n",
      "4   0.029193  \n",
      "5   0.029073  \n",
      "6   0.028105  \n",
      "7   0.029382  \n",
      "8   0.028260  \n",
      "9   0.028293  \n",
      "10  0.028322  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 7s 17ms/step - loss: 6.7994 - accuracy: 0.0888 - val_loss: 2.5503 - val_accuracy: 0.0843\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.8494 - accuracy: 0.0924 - val_loss: 1.3776 - val_accuracy: 0.1052\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.6975 - accuracy: 0.0875 - val_loss: 1.6047 - val_accuracy: 0.0893\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.7060 - accuracy: 0.0913 - val_loss: 1.2130 - val_accuracy: 0.0883\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.6440 - accuracy: 0.0943 - val_loss: 1.2430 - val_accuracy: 0.0948\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5699 - accuracy: 0.0981 - val_loss: 1.3071 - val_accuracy: 0.1047\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.6206 - accuracy: 0.0954 - val_loss: 1.2440 - val_accuracy: 0.0968\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5732 - accuracy: 0.0989 - val_loss: 1.3964 - val_accuracy: 0.1002\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5692 - accuracy: 0.0981 - val_loss: 1.2067 - val_accuracy: 0.1017\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5713 - accuracy: 0.1073 - val_loss: 1.2648 - val_accuracy: 0.1002\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5525 - accuracy: 0.1019 - val_loss: 1.3527 - val_accuracy: 0.0958\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.6484 - accuracy: 0.0953 - val_loss: 1.2778 - val_accuracy: 0.0978\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5267 - accuracy: 0.1040 - val_loss: 1.3315 - val_accuracy: 0.1107\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5222 - accuracy: 0.1023 - val_loss: 1.1850 - val_accuracy: 0.0943\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4966 - accuracy: 0.0943 - val_loss: 1.2839 - val_accuracy: 0.1047\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5321 - accuracy: 0.1034 - val_loss: 1.2598 - val_accuracy: 0.0983\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4914 - accuracy: 0.0962 - val_loss: 1.1997 - val_accuracy: 0.0988\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4948 - accuracy: 0.0988 - val_loss: 1.2165 - val_accuracy: 0.0918\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5167 - accuracy: 0.0972 - val_loss: 1.4031 - val_accuracy: 0.0988\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5166 - accuracy: 0.0986 - val_loss: 1.2436 - val_accuracy: 0.0978\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4693 - accuracy: 0.1074 - val_loss: 1.6665 - val_accuracy: 0.1042\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5222 - accuracy: 0.1018 - val_loss: 1.2421 - val_accuracy: 0.0933\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4953 - accuracy: 0.1049 - val_loss: 1.2401 - val_accuracy: 0.0958\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4923 - accuracy: 0.1008 - val_loss: 1.1738 - val_accuracy: 0.0998\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4902 - accuracy: 0.0931 - val_loss: 1.2610 - val_accuracy: 0.0968\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4757 - accuracy: 0.0978 - val_loss: 1.1815 - val_accuracy: 0.0863\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5427 - accuracy: 0.0973 - val_loss: 1.3101 - val_accuracy: 0.0938\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4862 - accuracy: 0.0918 - val_loss: 1.2309 - val_accuracy: 0.0928\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4888 - accuracy: 0.1012 - val_loss: 1.2882 - val_accuracy: 0.0973\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4860 - accuracy: 0.0938 - val_loss: 1.2273 - val_accuracy: 0.0903\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5632 - accuracy: 0.0951 - val_loss: 1.4692 - val_accuracy: 0.1097\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5206 - accuracy: 0.0996 - val_loss: 1.2734 - val_accuracy: 0.1002\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5144 - accuracy: 0.1037 - val_loss: 1.2715 - val_accuracy: 0.0973\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5163 - accuracy: 0.0973 - val_loss: 1.1606 - val_accuracy: 0.0983\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4620 - accuracy: 0.0984 - val_loss: 1.2322 - val_accuracy: 0.0978\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4981 - accuracy: 0.1024 - val_loss: 1.2198 - val_accuracy: 0.0983\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4621 - accuracy: 0.0933 - val_loss: 1.1816 - val_accuracy: 0.1077\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4735 - accuracy: 0.0951 - val_loss: 1.3251 - val_accuracy: 0.1002\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5406 - accuracy: 0.0908 - val_loss: 1.1909 - val_accuracy: 0.0948\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5043 - accuracy: 0.0989 - val_loss: 1.5066 - val_accuracy: 0.0943\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5072 - accuracy: 0.0984 - val_loss: 1.2363 - val_accuracy: 0.1017\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5038 - accuracy: 0.0984 - val_loss: 1.4544 - val_accuracy: 0.0923\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5139 - accuracy: 0.0984 - val_loss: 1.1647 - val_accuracy: 0.1027\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4755 - accuracy: 0.0998 - val_loss: 1.1850 - val_accuracy: 0.1077\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4837 - accuracy: 0.0964 - val_loss: 1.2131 - val_accuracy: 0.0988\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4694 - accuracy: 0.0976 - val_loss: 1.3351 - val_accuracy: 0.1022\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4678 - accuracy: 0.0984 - val_loss: 1.2106 - val_accuracy: 0.0938\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.4931 - accuracy: 0.1014 - val_loss: 1.1748 - val_accuracy: 0.1082\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5479 - accuracy: 0.0947 - val_loss: 1.2274 - val_accuracy: 0.0973\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4663 - accuracy: 0.1030 - val_loss: 1.1777 - val_accuracy: 0.0943\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3  nmaes_l4  nmaes_l5  nmaes_l6  \\\n",
      "0   0.026367  0.026595  0.028552  0.028122  0.026822  0.026414  0.026160   \n",
      "1   0.028450  0.028987  0.026366  0.025903  0.026774  0.027577  0.026387   \n",
      "2   0.028953  0.026854  0.027764  0.027637  0.028060  0.027208  0.026186   \n",
      "3   0.029804  0.030055  0.027852  0.027636  0.027801  0.027444  0.026647   \n",
      "4   0.029093  0.028284  0.028251  0.028271  0.028876  0.028015  0.026872   \n",
      "5   0.030503  0.028401  0.028396  0.027413  0.031583  0.027947  0.026963   \n",
      "6   0.029115  0.028414  0.028836  0.027557  0.028279  0.031677  0.027151   \n",
      "7   0.028812  0.029579  0.028265  0.027543  0.028320  0.028183  0.027106   \n",
      "8   0.029688  0.028476  0.028658  0.030983  0.028613  0.028888  0.028742   \n",
      "9   0.029247  0.029237  0.031558  0.029039  0.028627  0.028211  0.028064   \n",
      "10  0.029210  0.028866  0.030199  0.027901  0.029137  0.028341  0.027797   \n",
      "\n",
      "    nmaes_l7  nmaes_l8  \n",
      "0   0.027066  0.026467  \n",
      "1   0.027864  0.025771  \n",
      "2   0.028374  0.026779  \n",
      "3   0.029179  0.027347  \n",
      "4   0.029193  0.027710  \n",
      "5   0.029073  0.027257  \n",
      "6   0.028105  0.027565  \n",
      "7   0.029382  0.027450  \n",
      "8   0.028260  0.029367  \n",
      "9   0.028293  0.028660  \n",
      "10  0.028322  0.028102  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 8s 18ms/step - loss: 8.0939 - accuracy: 0.0893 - val_loss: 1.3455 - val_accuracy: 0.1033\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 2.1044 - accuracy: 0.0897 - val_loss: 1.6631 - val_accuracy: 0.0883\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.8068 - accuracy: 0.0918 - val_loss: 1.2530 - val_accuracy: 0.0888\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.8100 - accuracy: 0.0906 - val_loss: 1.2601 - val_accuracy: 0.0833\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.8494 - accuracy: 0.0976 - val_loss: 3.8062 - val_accuracy: 0.0983\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.8437 - accuracy: 0.0887 - val_loss: 1.2941 - val_accuracy: 0.0998\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.6564 - accuracy: 0.0856 - val_loss: 1.2512 - val_accuracy: 0.0983\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5685 - accuracy: 0.0912 - val_loss: 2.6063 - val_accuracy: 0.1088\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.6441 - accuracy: 0.0917 - val_loss: 1.2038 - val_accuracy: 0.0938\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.5803 - accuracy: 0.0913 - val_loss: 1.2633 - val_accuracy: 0.0908\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5668 - accuracy: 0.0947 - val_loss: 2.3441 - val_accuracy: 0.0868\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.6343 - accuracy: 0.0954 - val_loss: 1.1859 - val_accuracy: 0.1003\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5604 - accuracy: 0.0966 - val_loss: 1.2806 - val_accuracy: 0.1068\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.6281 - accuracy: 0.0926 - val_loss: 1.2916 - val_accuracy: 0.0878\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5320 - accuracy: 0.0934 - val_loss: 1.2089 - val_accuracy: 0.0913\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5139 - accuracy: 0.0964 - val_loss: 1.4847 - val_accuracy: 0.0923\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5814 - accuracy: 0.0973 - val_loss: 1.2860 - val_accuracy: 0.0963\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5212 - accuracy: 0.0998 - val_loss: 1.2019 - val_accuracy: 0.0943\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5183 - accuracy: 0.0917 - val_loss: 1.4604 - val_accuracy: 0.1053\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5188 - accuracy: 0.0946 - val_loss: 1.5168 - val_accuracy: 0.0923\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5413 - accuracy: 0.0984 - val_loss: 1.1788 - val_accuracy: 0.0963\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.4963 - accuracy: 0.0974 - val_loss: 1.2531 - val_accuracy: 0.0918\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5739 - accuracy: 0.0931 - val_loss: 1.3437 - val_accuracy: 0.0873\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5081 - accuracy: 0.0934 - val_loss: 1.2096 - val_accuracy: 0.1043\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5052 - accuracy: 0.0911 - val_loss: 1.3072 - val_accuracy: 0.0968\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5076 - accuracy: 0.0991 - val_loss: 1.4022 - val_accuracy: 0.0928\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5117 - accuracy: 0.0967 - val_loss: 1.1996 - val_accuracy: 0.0963\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.4791 - accuracy: 0.0942 - val_loss: 1.1775 - val_accuracy: 0.0978\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5078 - accuracy: 0.0938 - val_loss: 1.1848 - val_accuracy: 0.0973\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5181 - accuracy: 0.0992 - val_loss: 1.1873 - val_accuracy: 0.0988\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4833 - accuracy: 0.0962 - val_loss: 1.1975 - val_accuracy: 0.0953\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.4677 - accuracy: 0.0983 - val_loss: 1.1849 - val_accuracy: 0.0983\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.4869 - accuracy: 0.1004 - val_loss: 1.2532 - val_accuracy: 0.0868\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.4915 - accuracy: 0.0993 - val_loss: 1.7232 - val_accuracy: 0.0948\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5002 - accuracy: 0.0963 - val_loss: 1.2010 - val_accuracy: 0.0958\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 1.4884 - accuracy: 0.0974 - val_loss: 1.3374 - val_accuracy: 0.0903\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.4836 - accuracy: 0.0981 - val_loss: 1.2046 - val_accuracy: 0.1008\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5035 - accuracy: 0.0983 - val_loss: 1.3558 - val_accuracy: 0.0938\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5288 - accuracy: 0.0931 - val_loss: 1.1863 - val_accuracy: 0.0898\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.4952 - accuracy: 0.0944 - val_loss: 1.1802 - val_accuracy: 0.0953\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5680 - accuracy: 0.0988 - val_loss: 1.8410 - val_accuracy: 0.0903\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.5254 - accuracy: 0.0959 - val_loss: 1.1868 - val_accuracy: 0.0933\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4920 - accuracy: 0.0974 - val_loss: 1.2110 - val_accuracy: 0.0908\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4688 - accuracy: 0.0958 - val_loss: 1.1845 - val_accuracy: 0.1048\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4707 - accuracy: 0.0911 - val_loss: 1.1868 - val_accuracy: 0.0983\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.4761 - accuracy: 0.1015 - val_loss: 1.2193 - val_accuracy: 0.1048\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 4s 18ms/step - loss: 1.4571 - accuracy: 0.0948 - val_loss: 1.2305 - val_accuracy: 0.1038\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 4s 18ms/step - loss: 1.4958 - accuracy: 0.0947 - val_loss: 1.2143 - val_accuracy: 0.1008\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 4s 18ms/step - loss: 1.5162 - accuracy: 0.0951 - val_loss: 1.1999 - val_accuracy: 0.0898\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 1.4909 - accuracy: 0.0979 - val_loss: 1.2432 - val_accuracy: 0.1008\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3  nmaes_l4  nmaes_l5  nmaes_l6  \\\n",
      "0   0.026367  0.026595  0.028552  0.028122  0.026822  0.026414  0.026160   \n",
      "1   0.028450  0.028987  0.026366  0.025903  0.026774  0.027577  0.026387   \n",
      "2   0.028953  0.026854  0.027764  0.027637  0.028060  0.027208  0.026186   \n",
      "3   0.029804  0.030055  0.027852  0.027636  0.027801  0.027444  0.026647   \n",
      "4   0.029093  0.028284  0.028251  0.028271  0.028876  0.028015  0.026872   \n",
      "5   0.030503  0.028401  0.028396  0.027413  0.031583  0.027947  0.026963   \n",
      "6   0.029115  0.028414  0.028836  0.027557  0.028279  0.031677  0.027151   \n",
      "7   0.028812  0.029579  0.028265  0.027543  0.028320  0.028183  0.027106   \n",
      "8   0.029688  0.028476  0.028658  0.030983  0.028613  0.028888  0.028742   \n",
      "9   0.029247  0.029237  0.031558  0.029039  0.028627  0.028211  0.028064   \n",
      "10  0.029210  0.028866  0.030199  0.027901  0.029137  0.028341  0.027797   \n",
      "\n",
      "    nmaes_l7  nmaes_l8  nmaes_l9  \n",
      "0   0.027066  0.026467  0.025973  \n",
      "1   0.027864  0.025771  0.025479  \n",
      "2   0.028374  0.026779  0.025826  \n",
      "3   0.029179  0.027347  0.026220  \n",
      "4   0.029193  0.027710  0.027473  \n",
      "5   0.029073  0.027257  0.027067  \n",
      "6   0.028105  0.027565  0.030286  \n",
      "7   0.029382  0.027450  0.030257  \n",
      "8   0.028260  0.029367  0.031818  \n",
      "9   0.028293  0.028660  0.032603  \n",
      "10  0.028322  0.028102  0.029495  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 7s 19ms/step - loss: 6.9914 - accuracy: 0.0888 - val_loss: 1.7062 - val_accuracy: 0.1043\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 2.1095 - accuracy: 0.0938 - val_loss: 1.6331 - val_accuracy: 0.0923\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.9569 - accuracy: 0.0923 - val_loss: 2.4804 - val_accuracy: 0.0868\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 4s 18ms/step - loss: 1.9298 - accuracy: 0.0917 - val_loss: 1.8874 - val_accuracy: 0.0913\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.7643 - accuracy: 0.0953 - val_loss: 1.2289 - val_accuracy: 0.1003\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.6374 - accuracy: 0.0947 - val_loss: 1.2193 - val_accuracy: 0.0933\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.7144 - accuracy: 0.0933 - val_loss: 1.3095 - val_accuracy: 0.0918\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.6305 - accuracy: 0.0921 - val_loss: 1.2778 - val_accuracy: 0.0898\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.6944 - accuracy: 0.0920 - val_loss: 1.9054 - val_accuracy: 0.0968\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 4s 18ms/step - loss: 1.6598 - accuracy: 0.0925 - val_loss: 1.2617 - val_accuracy: 0.0988\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.6634 - accuracy: 0.0971 - val_loss: 1.4786 - val_accuracy: 0.1058\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5735 - accuracy: 0.0926 - val_loss: 1.4520 - val_accuracy: 0.0978\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5413 - accuracy: 0.0976 - val_loss: 1.3345 - val_accuracy: 0.0928\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5308 - accuracy: 0.0997 - val_loss: 1.2006 - val_accuracy: 0.0948\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5498 - accuracy: 0.1009 - val_loss: 2.1273 - val_accuracy: 0.0858\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5881 - accuracy: 0.0969 - val_loss: 1.6078 - val_accuracy: 0.1038\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5158 - accuracy: 0.0992 - val_loss: 1.4537 - val_accuracy: 0.1068\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5553 - accuracy: 0.1007 - val_loss: 1.3547 - val_accuracy: 0.0918\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.6116 - accuracy: 0.0971 - val_loss: 1.4983 - val_accuracy: 0.1108\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5150 - accuracy: 0.0922 - val_loss: 1.4203 - val_accuracy: 0.0943\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 1.5307 - accuracy: 0.0966 - val_loss: 1.3211 - val_accuracy: 0.0958\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5430 - accuracy: 0.0969 - val_loss: 1.1761 - val_accuracy: 0.0953\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.4936 - accuracy: 0.0953 - val_loss: 1.4163 - val_accuracy: 0.0928\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5306 - accuracy: 0.0907 - val_loss: 1.4675 - val_accuracy: 0.1018\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5363 - accuracy: 0.0992 - val_loss: 1.2289 - val_accuracy: 0.0993\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.4935 - accuracy: 0.0951 - val_loss: 2.1085 - val_accuracy: 0.0938\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5049 - accuracy: 0.0999 - val_loss: 1.2188 - val_accuracy: 0.0978\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5089 - accuracy: 0.0947 - val_loss: 1.5931 - val_accuracy: 0.0923\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5010 - accuracy: 0.0952 - val_loss: 1.1970 - val_accuracy: 0.1003\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5125 - accuracy: 0.0994 - val_loss: 1.4574 - val_accuracy: 0.1003\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5309 - accuracy: 0.1056 - val_loss: 1.1929 - val_accuracy: 0.1108\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 4s 18ms/step - loss: 1.5278 - accuracy: 0.0946 - val_loss: 1.2479 - val_accuracy: 0.0993\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5034 - accuracy: 0.1033 - val_loss: 1.4344 - val_accuracy: 0.0928\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.4792 - accuracy: 0.1008 - val_loss: 1.2287 - val_accuracy: 0.0963\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5011 - accuracy: 0.1008 - val_loss: 1.2451 - val_accuracy: 0.0948\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.4619 - accuracy: 0.0989 - val_loss: 1.2225 - val_accuracy: 0.0973\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 4s 18ms/step - loss: 1.5067 - accuracy: 0.1001 - val_loss: 1.1745 - val_accuracy: 0.0928\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.4980 - accuracy: 0.0993 - val_loss: 1.1942 - val_accuracy: 0.1088\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 4s 18ms/step - loss: 1.4962 - accuracy: 0.1006 - val_loss: 1.2942 - val_accuracy: 0.0993\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5413 - accuracy: 0.0876 - val_loss: 1.4073 - val_accuracy: 0.0903\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5628 - accuracy: 0.0922 - val_loss: 1.2516 - val_accuracy: 0.1063\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.6197 - accuracy: 0.0956 - val_loss: 1.4707 - val_accuracy: 0.0988\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.6076 - accuracy: 0.0993 - val_loss: 1.3459 - val_accuracy: 0.0953\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5428 - accuracy: 0.0937 - val_loss: 1.1909 - val_accuracy: 0.0923\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 1.5372 - accuracy: 0.0951 - val_loss: 1.3623 - val_accuracy: 0.0938\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.5650 - accuracy: 0.0962 - val_loss: 1.2628 - val_accuracy: 0.0898\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 5s 18ms/step - loss: 1.5126 - accuracy: 0.0963 - val_loss: 1.2422 - val_accuracy: 0.0933\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.4915 - accuracy: 0.1009 - val_loss: 1.3951 - val_accuracy: 0.0938\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 5s 20ms/step - loss: 1.4877 - accuracy: 0.1033 - val_loss: 1.2344 - val_accuracy: 0.1073\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 5s 19ms/step - loss: 1.4635 - accuracy: 0.1004 - val_loss: 1.2770 - val_accuracy: 0.0993\n",
      "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3  nmaes_l4  nmaes_l5  nmaes_l6  \\\n",
      "0   0.026367  0.026595  0.028552  0.028122  0.026822  0.026414  0.026160   \n",
      "1   0.028450  0.028987  0.026366  0.025903  0.026774  0.027577  0.026387   \n",
      "2   0.028953  0.026854  0.027764  0.027637  0.028060  0.027208  0.026186   \n",
      "3   0.029804  0.030055  0.027852  0.027636  0.027801  0.027444  0.026647   \n",
      "4   0.029093  0.028284  0.028251  0.028271  0.028876  0.028015  0.026872   \n",
      "5   0.030503  0.028401  0.028396  0.027413  0.031583  0.027947  0.026963   \n",
      "6   0.029115  0.028414  0.028836  0.027557  0.028279  0.031677  0.027151   \n",
      "7   0.028812  0.029579  0.028265  0.027543  0.028320  0.028183  0.027106   \n",
      "8   0.029688  0.028476  0.028658  0.030983  0.028613  0.028888  0.028742   \n",
      "9   0.029247  0.029237  0.031558  0.029039  0.028627  0.028211  0.028064   \n",
      "10  0.029210  0.028866  0.030199  0.027901  0.029137  0.028341  0.027797   \n",
      "\n",
      "    nmaes_l7  nmaes_l8  nmaes_l9  nmaes_l10  \n",
      "0   0.027066  0.026467  0.025973   0.027344  \n",
      "1   0.027864  0.025771  0.025479   0.027942  \n",
      "2   0.028374  0.026779  0.025826   0.027125  \n",
      "3   0.029179  0.027347  0.026220   0.029906  \n",
      "4   0.029193  0.027710  0.027473   0.029507  \n",
      "5   0.029073  0.027257  0.027067   0.029271  \n",
      "6   0.028105  0.027565  0.030286   0.031423  \n",
      "7   0.029382  0.027450  0.030257   0.030772  \n",
      "8   0.028260  0.029367  0.031818   0.030349  \n",
      "9   0.028293  0.028660  0.032603   0.029730  \n",
      "10  0.028322  0.028102  0.029495   0.033650  \n"
     ]
    }
   ],
   "source": [
    "nmaesdf = pd.DataFrame()\n",
    "for l in range(0, 11):\n",
    "    Rnn_xtrain, Rnn_ytrain = fetch_data(X_train, Y_train, 11, l+1)\n",
    "    Rnn_xtest, Rnn_ytest = fetch_data(X_test, Y_test, 11, l+1)\n",
    "    Rnn_model = LSTM_model(Rnn_xtrain, Rnn_ytrain, l+1, 11, 16)\n",
    "    Rnn_test = Rnn_reshape(Rnn_xtest, l+1, 16)\n",
    "    Rnn_pred = Rnn_model.predict(Rnn_test,verbose=0)\n",
    "    nmaes_l = nmaes_array(Rnn_ytest, Rnn_pred, 10)\n",
    "    nmaesdf['nmaes_l'+str(l)] = nmaes_l\n",
    "    print(nmaesdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'nmaesdf' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store nmaesdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nmaes_l0</th>\n",
       "      <th>nmaes_l1</th>\n",
       "      <th>nmaes_l2</th>\n",
       "      <th>nmaes_l3</th>\n",
       "      <th>nmaes_l4</th>\n",
       "      <th>nmaes_l5</th>\n",
       "      <th>nmaes_l6</th>\n",
       "      <th>nmaes_l7</th>\n",
       "      <th>nmaes_l8</th>\n",
       "      <th>nmaes_l9</th>\n",
       "      <th>nmaes_l10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.026595</td>\n",
       "      <td>0.028552</td>\n",
       "      <td>0.028122</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.026414</td>\n",
       "      <td>0.026160</td>\n",
       "      <td>0.027066</td>\n",
       "      <td>0.026467</td>\n",
       "      <td>0.025973</td>\n",
       "      <td>0.027344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028450</td>\n",
       "      <td>0.028987</td>\n",
       "      <td>0.026366</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.026387</td>\n",
       "      <td>0.027864</td>\n",
       "      <td>0.025771</td>\n",
       "      <td>0.025479</td>\n",
       "      <td>0.027942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028953</td>\n",
       "      <td>0.026854</td>\n",
       "      <td>0.027764</td>\n",
       "      <td>0.027637</td>\n",
       "      <td>0.028060</td>\n",
       "      <td>0.027208</td>\n",
       "      <td>0.026186</td>\n",
       "      <td>0.028374</td>\n",
       "      <td>0.026779</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.027125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029804</td>\n",
       "      <td>0.030055</td>\n",
       "      <td>0.027852</td>\n",
       "      <td>0.027636</td>\n",
       "      <td>0.027801</td>\n",
       "      <td>0.027444</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>0.029179</td>\n",
       "      <td>0.027347</td>\n",
       "      <td>0.026220</td>\n",
       "      <td>0.029906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029093</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>0.028251</td>\n",
       "      <td>0.028271</td>\n",
       "      <td>0.028876</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.029193</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0.029507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.028401</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>0.031583</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.026963</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>0.027257</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>0.029271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029115</td>\n",
       "      <td>0.028414</td>\n",
       "      <td>0.028836</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.028279</td>\n",
       "      <td>0.031677</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>0.031423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.028812</td>\n",
       "      <td>0.029579</td>\n",
       "      <td>0.028265</td>\n",
       "      <td>0.027543</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.028183</td>\n",
       "      <td>0.027106</td>\n",
       "      <td>0.029382</td>\n",
       "      <td>0.027450</td>\n",
       "      <td>0.030257</td>\n",
       "      <td>0.030772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.029688</td>\n",
       "      <td>0.028476</td>\n",
       "      <td>0.028658</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.028613</td>\n",
       "      <td>0.028888</td>\n",
       "      <td>0.028742</td>\n",
       "      <td>0.028260</td>\n",
       "      <td>0.029367</td>\n",
       "      <td>0.031818</td>\n",
       "      <td>0.030349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.029247</td>\n",
       "      <td>0.029237</td>\n",
       "      <td>0.031558</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.028211</td>\n",
       "      <td>0.028064</td>\n",
       "      <td>0.028293</td>\n",
       "      <td>0.028660</td>\n",
       "      <td>0.032603</td>\n",
       "      <td>0.029730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>0.029137</td>\n",
       "      <td>0.028341</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>0.028322</td>\n",
       "      <td>0.028102</td>\n",
       "      <td>0.029495</td>\n",
       "      <td>0.033650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nmaes_l0  nmaes_l1  nmaes_l2  nmaes_l3  nmaes_l4  nmaes_l5  nmaes_l6  \\\n",
       "0   0.026367  0.026595  0.028552  0.028122  0.026822  0.026414  0.026160   \n",
       "1   0.028450  0.028987  0.026366  0.025903  0.026774  0.027577  0.026387   \n",
       "2   0.028953  0.026854  0.027764  0.027637  0.028060  0.027208  0.026186   \n",
       "3   0.029804  0.030055  0.027852  0.027636  0.027801  0.027444  0.026647   \n",
       "4   0.029093  0.028284  0.028251  0.028271  0.028876  0.028015  0.026872   \n",
       "5   0.030503  0.028401  0.028396  0.027413  0.031583  0.027947  0.026963   \n",
       "6   0.029115  0.028414  0.028836  0.027557  0.028279  0.031677  0.027151   \n",
       "7   0.028812  0.029579  0.028265  0.027543  0.028320  0.028183  0.027106   \n",
       "8   0.029688  0.028476  0.028658  0.030983  0.028613  0.028888  0.028742   \n",
       "9   0.029247  0.029237  0.031558  0.029039  0.028627  0.028211  0.028064   \n",
       "10  0.029210  0.028866  0.030199  0.027901  0.029137  0.028341  0.027797   \n",
       "\n",
       "    nmaes_l7  nmaes_l8  nmaes_l9  nmaes_l10  \n",
       "0   0.027066  0.026467  0.025973   0.027344  \n",
       "1   0.027864  0.025771  0.025479   0.027942  \n",
       "2   0.028374  0.026779  0.025826   0.027125  \n",
       "3   0.029179  0.027347  0.026220   0.029906  \n",
       "4   0.029193  0.027710  0.027473   0.029507  \n",
       "5   0.029073  0.027257  0.027067   0.029271  \n",
       "6   0.028105  0.027565  0.030286   0.031423  \n",
       "7   0.029382  0.027450  0.030257   0.030772  \n",
       "8   0.028260  0.029367  0.031818   0.030349  \n",
       "9   0.028293  0.028660  0.032603   0.029730  \n",
       "10  0.028322  0.028102  0.029495   0.033650  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmaesdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=11, step=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmaesdf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'NMAE'), Text(0.5, 0, 'lag')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, linep_ = plt.subplots(figsize = (10,6), dpi = 100)\n",
    "\n",
    "linep_ = sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l0\", label=\"h=0\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l1\", label=\"h=1\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l2\", label=\"h=2\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l3\", label=\"h=3\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l4\", label=\"h=4\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l5\", label=\"h=5\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l6\", label=\"h=6\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l7\", label=\"h=7\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l8\", label=\"h=8\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l9\", label=\"h=9\")\n",
    "sns.lineplot(data=nmaesdf, x=nmaesdf.index, y=\"nmaes_l10\", label=\"h=10\")\n",
    "linep_.set(title=\"NMAE vs lag\")\n",
    "\n",
    "linep_.set(xlabel='lag', ylabel='NMAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('lags1.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 5s 7ms/step - loss: 13.7929 - accuracy: 0.0139 - val_loss: 1.5981 - val_accuracy: 0.0140\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4532 - accuracy: 0.0160 - val_loss: 1.3255 - val_accuracy: 0.0185\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 2.0396 - accuracy: 0.0184 - val_loss: 1.3004 - val_accuracy: 0.0150\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.6769 - accuracy: 0.0143 - val_loss: 1.2758 - val_accuracy: 0.0145\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.6583 - accuracy: 0.0130 - val_loss: 1.3445 - val_accuracy: 0.0130\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.6394 - accuracy: 0.0147 - val_loss: 1.3469 - val_accuracy: 0.0130\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.6182 - accuracy: 0.0127 - val_loss: 1.3580 - val_accuracy: 0.0130\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.6062 - accuracy: 0.0175 - val_loss: 1.2577 - val_accuracy: 0.0140\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.6228 - accuracy: 0.0143 - val_loss: 1.4299 - val_accuracy: 0.0160\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.6124 - accuracy: 0.0180 - val_loss: 1.2613 - val_accuracy: 0.0135\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.6013 - accuracy: 0.0163 - val_loss: 1.2718 - val_accuracy: 0.0165\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5958 - accuracy: 0.0173 - val_loss: 1.2601 - val_accuracy: 0.0155\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5933 - accuracy: 0.0150 - val_loss: 1.3656 - val_accuracy: 0.0130\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5913 - accuracy: 0.0159 - val_loss: 1.2755 - val_accuracy: 0.0135\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5813 - accuracy: 0.0150 - val_loss: 1.2692 - val_accuracy: 0.0145\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5800 - accuracy: 0.0158 - val_loss: 1.2983 - val_accuracy: 0.0170\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5800 - accuracy: 0.0180 - val_loss: 1.2575 - val_accuracy: 0.0165\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5729 - accuracy: 0.0163 - val_loss: 1.3142 - val_accuracy: 0.0170\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5801 - accuracy: 0.0185 - val_loss: 1.2782 - val_accuracy: 0.0150\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5694 - accuracy: 0.0169 - val_loss: 1.2639 - val_accuracy: 0.0110\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.5763 - accuracy: 0.0189 - val_loss: 1.2660 - val_accuracy: 0.0125\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5721 - accuracy: 0.0169 - val_loss: 1.2467 - val_accuracy: 0.0150\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.5658 - accuracy: 0.0198 - val_loss: 1.2808 - val_accuracy: 0.0185\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5714 - accuracy: 0.0204 - val_loss: 1.2979 - val_accuracy: 0.0160\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5664 - accuracy: 0.0201 - val_loss: 1.2542 - val_accuracy: 0.0160\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.5747 - accuracy: 0.0187 - val_loss: 1.2520 - val_accuracy: 0.0170\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.6104 - accuracy: 0.0189 - val_loss: 1.2573 - val_accuracy: 0.0155\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5854 - accuracy: 0.0182 - val_loss: 1.2427 - val_accuracy: 0.0165\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5740 - accuracy: 0.0197 - val_loss: 1.2626 - val_accuracy: 0.0145\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.5776 - accuracy: 0.0192 - val_loss: 1.2409 - val_accuracy: 0.0170\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5642 - accuracy: 0.0217 - val_loss: 1.2491 - val_accuracy: 0.0165\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5680 - accuracy: 0.0183 - val_loss: 1.2773 - val_accuracy: 0.0175\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5651 - accuracy: 0.0194 - val_loss: 1.2975 - val_accuracy: 0.0160\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.5683 - accuracy: 0.0170 - val_loss: 1.3066 - val_accuracy: 0.0175\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.5673 - accuracy: 0.0170 - val_loss: 1.2535 - val_accuracy: 0.0140\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5662 - accuracy: 0.0179 - val_loss: 1.2552 - val_accuracy: 0.0135\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5646 - accuracy: 0.0182 - val_loss: 1.2578 - val_accuracy: 0.0140\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5648 - accuracy: 0.0199 - val_loss: 1.2578 - val_accuracy: 0.0165\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5652 - accuracy: 0.0168 - val_loss: 1.2638 - val_accuracy: 0.0150\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5651 - accuracy: 0.0198 - val_loss: 1.2614 - val_accuracy: 0.0125\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.5659 - accuracy: 0.0209 - val_loss: 1.3366 - val_accuracy: 0.0165\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5621 - accuracy: 0.0187 - val_loss: 1.2662 - val_accuracy: 0.0145\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5640 - accuracy: 0.0174 - val_loss: 1.2495 - val_accuracy: 0.0155\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5608 - accuracy: 0.0189 - val_loss: 1.2592 - val_accuracy: 0.0155\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5600 - accuracy: 0.0197 - val_loss: 1.2839 - val_accuracy: 0.0160\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5656 - accuracy: 0.0179 - val_loss: 1.3239 - val_accuracy: 0.0145\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5562 - accuracy: 0.0209 - val_loss: 1.2533 - val_accuracy: 0.0221\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5578 - accuracy: 0.0211 - val_loss: 1.2693 - val_accuracy: 0.0165\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5646 - accuracy: 0.0203 - val_loss: 1.2798 - val_accuracy: 0.0140\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5564 - accuracy: 0.0163 - val_loss: 1.2899 - val_accuracy: 0.0165\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 5s 9ms/step - loss: 8.9590 - accuracy: 0.0147 - val_loss: 1.7201 - val_accuracy: 0.0175\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.9105 - accuracy: 0.0164 - val_loss: 1.3686 - val_accuracy: 0.0155\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.7696 - accuracy: 0.0144 - val_loss: 1.3917 - val_accuracy: 0.0165\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.7224 - accuracy: 0.0118 - val_loss: 1.4357 - val_accuracy: 0.0140\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6380 - accuracy: 0.0153 - val_loss: 1.4385 - val_accuracy: 0.0135\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6568 - accuracy: 0.0160 - val_loss: 1.4854 - val_accuracy: 0.0150\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 1.6671 - accuracy: 0.0172 - val_loss: 1.3330 - val_accuracy: 0.0170\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6361 - accuracy: 0.0174 - val_loss: 1.3300 - val_accuracy: 0.0150\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6239 - accuracy: 0.0163 - val_loss: 1.2965 - val_accuracy: 0.0155\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6105 - accuracy: 0.0144 - val_loss: 1.5344 - val_accuracy: 0.0155\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6098 - accuracy: 0.0158 - val_loss: 1.4660 - val_accuracy: 0.0185\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6167 - accuracy: 0.0179 - val_loss: 1.4893 - val_accuracy: 0.0160\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6140 - accuracy: 0.0144 - val_loss: 1.2950 - val_accuracy: 0.0145\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5979 - accuracy: 0.0175 - val_loss: 1.3153 - val_accuracy: 0.0175\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5978 - accuracy: 0.0175 - val_loss: 1.4130 - val_accuracy: 0.0160\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6109 - accuracy: 0.0159 - val_loss: 1.2611 - val_accuracy: 0.0155\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5835 - accuracy: 0.0204 - val_loss: 1.3775 - val_accuracy: 0.0150\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6017 - accuracy: 0.0145 - val_loss: 1.3776 - val_accuracy: 0.0180\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5960 - accuracy: 0.0185 - val_loss: 1.2962 - val_accuracy: 0.0195\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 1.5881 - accuracy: 0.0211 - val_loss: 1.3644 - val_accuracy: 0.0160\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5940 - accuracy: 0.0222 - val_loss: 1.2743 - val_accuracy: 0.0150\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5817 - accuracy: 0.0182 - val_loss: 1.3955 - val_accuracy: 0.0201\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 1.5900 - accuracy: 0.0197 - val_loss: 1.3128 - val_accuracy: 0.0145\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5889 - accuracy: 0.0173 - val_loss: 1.4096 - val_accuracy: 0.0135\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5848 - accuracy: 0.0213 - val_loss: 1.2512 - val_accuracy: 0.0175\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5980 - accuracy: 0.0211 - val_loss: 1.2756 - val_accuracy: 0.0190\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5744 - accuracy: 0.0209 - val_loss: 1.2649 - val_accuracy: 0.0165\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5896 - accuracy: 0.0173 - val_loss: 1.4020 - val_accuracy: 0.0206\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5838 - accuracy: 0.0189 - val_loss: 1.2466 - val_accuracy: 0.0180\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5862 - accuracy: 0.0170 - val_loss: 1.2679 - val_accuracy: 0.0150\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5779 - accuracy: 0.0199 - val_loss: 1.2784 - val_accuracy: 0.0201\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5749 - accuracy: 0.0208 - val_loss: 1.4361 - val_accuracy: 0.0155\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5787 - accuracy: 0.0191 - val_loss: 1.3094 - val_accuracy: 0.0170\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5667 - accuracy: 0.0199 - val_loss: 1.3726 - val_accuracy: 0.0221\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5755 - accuracy: 0.0167 - val_loss: 1.3844 - val_accuracy: 0.0155\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5718 - accuracy: 0.0214 - val_loss: 1.2683 - val_accuracy: 0.0180\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5787 - accuracy: 0.0208 - val_loss: 1.2640 - val_accuracy: 0.0195\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5685 - accuracy: 0.0206 - val_loss: 1.3395 - val_accuracy: 0.0170\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 1.5824 - accuracy: 0.0202 - val_loss: 1.2783 - val_accuracy: 0.0175\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5832 - accuracy: 0.0206 - val_loss: 1.2649 - val_accuracy: 0.0160\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.6277 - accuracy: 0.0199 - val_loss: 1.2618 - val_accuracy: 0.0175\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5966 - accuracy: 0.0192 - val_loss: 1.3962 - val_accuracy: 0.0170\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 1.5799 - accuracy: 0.0165 - val_loss: 1.2528 - val_accuracy: 0.0140\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5724 - accuracy: 0.0196 - val_loss: 1.2634 - val_accuracy: 0.0160\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5722 - accuracy: 0.0158 - val_loss: 1.2473 - val_accuracy: 0.0185\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5694 - accuracy: 0.0216 - val_loss: 1.2484 - val_accuracy: 0.0165\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5717 - accuracy: 0.0184 - val_loss: 1.2530 - val_accuracy: 0.0150\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5742 - accuracy: 0.0188 - val_loss: 1.3473 - val_accuracy: 0.0195\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5982 - accuracy: 0.0212 - val_loss: 1.2921 - val_accuracy: 0.0195\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 1.5633 - accuracy: 0.0184 - val_loss: 1.2682 - val_accuracy: 0.0140\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 5s 9ms/step - loss: 8.4869 - accuracy: 0.0167 - val_loss: 1.4387 - val_accuracy: 0.0165\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.9798 - accuracy: 0.0164 - val_loss: 1.3746 - val_accuracy: 0.0130\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.7029 - accuracy: 0.0174 - val_loss: 1.3234 - val_accuracy: 0.0125\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6726 - accuracy: 0.0170 - val_loss: 1.3218 - val_accuracy: 0.0145\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6799 - accuracy: 0.0149 - val_loss: 1.3675 - val_accuracy: 0.0180\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6388 - accuracy: 0.0129 - val_loss: 1.2933 - val_accuracy: 0.0165\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6445 - accuracy: 0.0138 - val_loss: 1.4677 - val_accuracy: 0.0130\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6463 - accuracy: 0.0149 - val_loss: 1.2904 - val_accuracy: 0.0170\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6421 - accuracy: 0.0182 - val_loss: 1.2685 - val_accuracy: 0.0160\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6240 - accuracy: 0.0168 - val_loss: 1.3073 - val_accuracy: 0.0140\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6278 - accuracy: 0.0160 - val_loss: 1.3145 - val_accuracy: 0.0165\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6139 - accuracy: 0.0175 - val_loss: 1.2806 - val_accuracy: 0.0155\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6130 - accuracy: 0.0168 - val_loss: 1.5529 - val_accuracy: 0.0150\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6210 - accuracy: 0.0153 - val_loss: 1.2744 - val_accuracy: 0.0185\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6053 - accuracy: 0.0173 - val_loss: 1.2741 - val_accuracy: 0.0160\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6243 - accuracy: 0.0138 - val_loss: 1.3055 - val_accuracy: 0.0180\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6071 - accuracy: 0.0155 - val_loss: 1.3258 - val_accuracy: 0.0175\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6093 - accuracy: 0.0182 - val_loss: 1.2769 - val_accuracy: 0.0140\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6020 - accuracy: 0.0206 - val_loss: 1.3187 - val_accuracy: 0.0195\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6064 - accuracy: 0.0192 - val_loss: 1.3596 - val_accuracy: 0.0170\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6477 - accuracy: 0.0189 - val_loss: 1.2974 - val_accuracy: 0.0150\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5877 - accuracy: 0.0194 - val_loss: 1.3119 - val_accuracy: 0.0145\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6107 - accuracy: 0.0163 - val_loss: 1.2851 - val_accuracy: 0.0185\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5858 - accuracy: 0.0197 - val_loss: 1.2752 - val_accuracy: 0.0155\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5961 - accuracy: 0.0179 - val_loss: 1.2483 - val_accuracy: 0.0150\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5948 - accuracy: 0.0144 - val_loss: 1.3786 - val_accuracy: 0.0170\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6219 - accuracy: 0.0197 - val_loss: 1.6346 - val_accuracy: 0.0201\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6049 - accuracy: 0.0169 - val_loss: 1.2503 - val_accuracy: 0.0145\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6018 - accuracy: 0.0203 - val_loss: 1.2824 - val_accuracy: 0.0175\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5870 - accuracy: 0.0198 - val_loss: 1.2752 - val_accuracy: 0.0170\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5802 - accuracy: 0.0201 - val_loss: 1.3843 - val_accuracy: 0.0211\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6007 - accuracy: 0.0182 - val_loss: 1.2606 - val_accuracy: 0.0145\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5827 - accuracy: 0.0204 - val_loss: 1.2520 - val_accuracy: 0.0145\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5876 - accuracy: 0.0170 - val_loss: 1.4593 - val_accuracy: 0.0226\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6149 - accuracy: 0.0174 - val_loss: 1.2732 - val_accuracy: 0.0185\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5730 - accuracy: 0.0178 - val_loss: 1.3092 - val_accuracy: 0.0170\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5665 - accuracy: 0.0187 - val_loss: 1.5664 - val_accuracy: 0.0185\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5630 - accuracy: 0.0183 - val_loss: 1.2392 - val_accuracy: 0.0201\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5962 - accuracy: 0.0211 - val_loss: 1.2545 - val_accuracy: 0.0180\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5948 - accuracy: 0.0172 - val_loss: 1.2723 - val_accuracy: 0.0165\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5897 - accuracy: 0.0192 - val_loss: 1.5197 - val_accuracy: 0.0140\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.6005 - accuracy: 0.0179 - val_loss: 1.2847 - val_accuracy: 0.0170\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5886 - accuracy: 0.0175 - val_loss: 1.2434 - val_accuracy: 0.0165\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5709 - accuracy: 0.0174 - val_loss: 1.2669 - val_accuracy: 0.0150\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5646 - accuracy: 0.0188 - val_loss: 1.2619 - val_accuracy: 0.0190\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5667 - accuracy: 0.0183 - val_loss: 1.2763 - val_accuracy: 0.0170\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5655 - accuracy: 0.0199 - val_loss: 1.2563 - val_accuracy: 0.0195\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5763 - accuracy: 0.0194 - val_loss: 1.2430 - val_accuracy: 0.0175\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5544 - accuracy: 0.0188 - val_loss: 1.2475 - val_accuracy: 0.0175\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 1.5559 - accuracy: 0.0188 - val_loss: 1.6418 - val_accuracy: 0.0180\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 6s 12ms/step - loss: 6.6669 - accuracy: 0.0147 - val_loss: 3.0777 - val_accuracy: 0.0140\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 2.0652 - accuracy: 0.0168 - val_loss: 1.6352 - val_accuracy: 0.0190\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.8753 - accuracy: 0.0181 - val_loss: 1.3030 - val_accuracy: 0.0140\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6584 - accuracy: 0.0198 - val_loss: 1.3901 - val_accuracy: 0.0155\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6571 - accuracy: 0.0168 - val_loss: 1.3347 - val_accuracy: 0.0170\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.6855 - accuracy: 0.0149 - val_loss: 1.2966 - val_accuracy: 0.0165\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.7158 - accuracy: 0.0149 - val_loss: 1.3717 - val_accuracy: 0.0140\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.7073 - accuracy: 0.0153 - val_loss: 1.4428 - val_accuracy: 0.0160\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6403 - accuracy: 0.0172 - val_loss: 1.2868 - val_accuracy: 0.0170\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6567 - accuracy: 0.0158 - val_loss: 1.2891 - val_accuracy: 0.0165\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6452 - accuracy: 0.0168 - val_loss: 1.3688 - val_accuracy: 0.0160\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.6614 - accuracy: 0.0157 - val_loss: 1.3435 - val_accuracy: 0.0165\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6021 - accuracy: 0.0187 - val_loss: 1.2748 - val_accuracy: 0.0165\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6098 - accuracy: 0.0155 - val_loss: 1.6940 - val_accuracy: 0.0150\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6296 - accuracy: 0.0168 - val_loss: 1.9456 - val_accuracy: 0.0150\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6109 - accuracy: 0.0196 - val_loss: 1.3639 - val_accuracy: 0.0165\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6254 - accuracy: 0.0177 - val_loss: 1.2693 - val_accuracy: 0.0175\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.6266 - accuracy: 0.0157 - val_loss: 1.2805 - val_accuracy: 0.0150\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6053 - accuracy: 0.0177 - val_loss: 1.4010 - val_accuracy: 0.0201\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6006 - accuracy: 0.0196 - val_loss: 1.2569 - val_accuracy: 0.0165\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5855 - accuracy: 0.0208 - val_loss: 1.2728 - val_accuracy: 0.0145\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5754 - accuracy: 0.0179 - val_loss: 1.3123 - val_accuracy: 0.0140\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5989 - accuracy: 0.0191 - val_loss: 1.2728 - val_accuracy: 0.0170\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5962 - accuracy: 0.0208 - val_loss: 1.3160 - val_accuracy: 0.0190\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5960 - accuracy: 0.0194 - val_loss: 1.3886 - val_accuracy: 0.0206\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5963 - accuracy: 0.0203 - val_loss: 1.2944 - val_accuracy: 0.0145\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6001 - accuracy: 0.0209 - val_loss: 1.2683 - val_accuracy: 0.0201\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5688 - accuracy: 0.0204 - val_loss: 1.2900 - val_accuracy: 0.0165\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5825 - accuracy: 0.0203 - val_loss: 1.5438 - val_accuracy: 0.0201\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5895 - accuracy: 0.0198 - val_loss: 1.2624 - val_accuracy: 0.0170\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5980 - accuracy: 0.0183 - val_loss: 1.3110 - val_accuracy: 0.0145\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.6019 - accuracy: 0.0201 - val_loss: 1.2463 - val_accuracy: 0.0195\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5723 - accuracy: 0.0163 - val_loss: 1.2602 - val_accuracy: 0.0185\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5837 - accuracy: 0.0199 - val_loss: 1.2540 - val_accuracy: 0.0165\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 1.5945 - accuracy: 0.0206 - val_loss: 1.4229 - val_accuracy: 0.0195\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5801 - accuracy: 0.0243 - val_loss: 1.7477 - val_accuracy: 0.0180\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5653 - accuracy: 0.0218 - val_loss: 1.3314 - val_accuracy: 0.0185\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5709 - accuracy: 0.0188 - val_loss: 1.2597 - val_accuracy: 0.0185\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5880 - accuracy: 0.0233 - val_loss: 1.4195 - val_accuracy: 0.0190\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5614 - accuracy: 0.0219 - val_loss: 1.3518 - val_accuracy: 0.0201\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5591 - accuracy: 0.0196 - val_loss: 1.3735 - val_accuracy: 0.0195\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5709 - accuracy: 0.0202 - val_loss: 1.2653 - val_accuracy: 0.0201\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5497 - accuracy: 0.0197 - val_loss: 1.3661 - val_accuracy: 0.0190\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5599 - accuracy: 0.0211 - val_loss: 1.3568 - val_accuracy: 0.0201\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5815 - accuracy: 0.0188 - val_loss: 1.2728 - val_accuracy: 0.0180\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5574 - accuracy: 0.0201 - val_loss: 1.2555 - val_accuracy: 0.0211\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5695 - accuracy: 0.0198 - val_loss: 1.2534 - val_accuracy: 0.0165\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5519 - accuracy: 0.0234 - val_loss: 1.2499 - val_accuracy: 0.0155\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5537 - accuracy: 0.0209 - val_loss: 1.2526 - val_accuracy: 0.0211\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5480 - accuracy: 0.0174 - val_loss: 1.2534 - val_accuracy: 0.0206\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 6s 13ms/step - loss: 6.9726 - accuracy: 0.0191 - val_loss: 1.3545 - val_accuracy: 0.0135\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.8964 - accuracy: 0.0129 - val_loss: 1.3145 - val_accuracy: 0.0135\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.7698 - accuracy: 0.0149 - val_loss: 1.8571 - val_accuracy: 0.0125\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.7076 - accuracy: 0.0159 - val_loss: 1.3321 - val_accuracy: 0.0150\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6688 - accuracy: 0.0160 - val_loss: 1.9367 - val_accuracy: 0.0140\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.7733 - accuracy: 0.0165 - val_loss: 1.6792 - val_accuracy: 0.0170\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.7118 - accuracy: 0.0153 - val_loss: 1.2857 - val_accuracy: 0.0145\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6296 - accuracy: 0.0155 - val_loss: 1.5922 - val_accuracy: 0.0160\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6447 - accuracy: 0.0173 - val_loss: 1.3742 - val_accuracy: 0.0201\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.7209 - accuracy: 0.0172 - val_loss: 1.4085 - val_accuracy: 0.0185\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6204 - accuracy: 0.0142 - val_loss: 1.2806 - val_accuracy: 0.0155\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5995 - accuracy: 0.0183 - val_loss: 1.3606 - val_accuracy: 0.0175\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6056 - accuracy: 0.0157 - val_loss: 1.5963 - val_accuracy: 0.0160\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6140 - accuracy: 0.0148 - val_loss: 1.4599 - val_accuracy: 0.0160\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6525 - accuracy: 0.0183 - val_loss: 1.4424 - val_accuracy: 0.0150\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6188 - accuracy: 0.0197 - val_loss: 1.6403 - val_accuracy: 0.0185\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6227 - accuracy: 0.0192 - val_loss: 1.3249 - val_accuracy: 0.0170\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6071 - accuracy: 0.0196 - val_loss: 1.2765 - val_accuracy: 0.0221\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6009 - accuracy: 0.0196 - val_loss: 1.2678 - val_accuracy: 0.0160\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5773 - accuracy: 0.0181 - val_loss: 1.3685 - val_accuracy: 0.0180\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5935 - accuracy: 0.0194 - val_loss: 1.2439 - val_accuracy: 0.0185\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5765 - accuracy: 0.0184 - val_loss: 1.2545 - val_accuracy: 0.0195\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5784 - accuracy: 0.0189 - val_loss: 1.2691 - val_accuracy: 0.0201\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5614 - accuracy: 0.0186 - val_loss: 1.4824 - val_accuracy: 0.0190\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5709 - accuracy: 0.0216 - val_loss: 1.2850 - val_accuracy: 0.0206\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5999 - accuracy: 0.0206 - val_loss: 1.4101 - val_accuracy: 0.0211\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6735 - accuracy: 0.0198 - val_loss: 1.2559 - val_accuracy: 0.0241\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5943 - accuracy: 0.0193 - val_loss: 1.5332 - val_accuracy: 0.0140\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.6701 - accuracy: 0.0164 - val_loss: 1.2581 - val_accuracy: 0.0150\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5801 - accuracy: 0.0219 - val_loss: 1.2558 - val_accuracy: 0.0241\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6058 - accuracy: 0.0213 - val_loss: 1.3514 - val_accuracy: 0.0216\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5813 - accuracy: 0.0199 - val_loss: 1.5628 - val_accuracy: 0.0201\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5672 - accuracy: 0.0228 - val_loss: 1.3535 - val_accuracy: 0.0185\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5778 - accuracy: 0.0214 - val_loss: 1.4141 - val_accuracy: 0.0180\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5894 - accuracy: 0.0173 - val_loss: 1.3054 - val_accuracy: 0.0195\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5695 - accuracy: 0.0201 - val_loss: 1.2737 - val_accuracy: 0.0180\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5534 - accuracy: 0.0206 - val_loss: 1.2582 - val_accuracy: 0.0185\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5688 - accuracy: 0.0177 - val_loss: 1.3585 - val_accuracy: 0.0170\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5749 - accuracy: 0.0183 - val_loss: 1.2777 - val_accuracy: 0.0165\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5754 - accuracy: 0.0211 - val_loss: 1.2603 - val_accuracy: 0.0231\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5900 - accuracy: 0.0207 - val_loss: 1.3169 - val_accuracy: 0.0190\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 1.5902 - accuracy: 0.0183 - val_loss: 1.3914 - val_accuracy: 0.0165\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5849 - accuracy: 0.0188 - val_loss: 1.7434 - val_accuracy: 0.0185\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5696 - accuracy: 0.0179 - val_loss: 1.2429 - val_accuracy: 0.0145\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 1.5661 - accuracy: 0.0198 - val_loss: 1.2893 - val_accuracy: 0.0175\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5618 - accuracy: 0.0188 - val_loss: 1.2608 - val_accuracy: 0.0216\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5532 - accuracy: 0.0177 - val_loss: 1.2337 - val_accuracy: 0.0180\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5499 - accuracy: 0.0201 - val_loss: 1.3161 - val_accuracy: 0.0140\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5538 - accuracy: 0.0187 - val_loss: 1.2780 - val_accuracy: 0.0175\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5355 - accuracy: 0.0189 - val_loss: 1.3949 - val_accuracy: 0.0155\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 6s 13ms/step - loss: 6.4936 - accuracy: 0.0173 - val_loss: 3.6451 - val_accuracy: 0.0165\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.9850 - accuracy: 0.0140 - val_loss: 1.5383 - val_accuracy: 0.0160\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.7421 - accuracy: 0.0132 - val_loss: 1.3331 - val_accuracy: 0.0165\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.7132 - accuracy: 0.0158 - val_loss: 1.3955 - val_accuracy: 0.0140\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.7357 - accuracy: 0.0142 - val_loss: 1.6585 - val_accuracy: 0.0160\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6883 - accuracy: 0.0132 - val_loss: 1.2766 - val_accuracy: 0.0176\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.7496 - accuracy: 0.0150 - val_loss: 1.2743 - val_accuracy: 0.0155\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6328 - accuracy: 0.0143 - val_loss: 1.4422 - val_accuracy: 0.0135\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6228 - accuracy: 0.0150 - val_loss: 1.3598 - val_accuracy: 0.0171\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6485 - accuracy: 0.0172 - val_loss: 1.3124 - val_accuracy: 0.0165\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6243 - accuracy: 0.0188 - val_loss: 1.2833 - val_accuracy: 0.0176\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6226 - accuracy: 0.0202 - val_loss: 1.2760 - val_accuracy: 0.0196\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.7124 - accuracy: 0.0206 - val_loss: 1.6287 - val_accuracy: 0.0176\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.6117 - accuracy: 0.0193 - val_loss: 1.3951 - val_accuracy: 0.0206\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6618 - accuracy: 0.0202 - val_loss: 1.5414 - val_accuracy: 0.0201\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6300 - accuracy: 0.0196 - val_loss: 1.2736 - val_accuracy: 0.0206\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5841 - accuracy: 0.0193 - val_loss: 1.3359 - val_accuracy: 0.0186\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5978 - accuracy: 0.0207 - val_loss: 1.3774 - val_accuracy: 0.0191\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6296 - accuracy: 0.0198 - val_loss: 1.4227 - val_accuracy: 0.0171\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5880 - accuracy: 0.0206 - val_loss: 1.3471 - val_accuracy: 0.0226\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5779 - accuracy: 0.0164 - val_loss: 1.2495 - val_accuracy: 0.0231\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5720 - accuracy: 0.0214 - val_loss: 1.3107 - val_accuracy: 0.0211\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5812 - accuracy: 0.0202 - val_loss: 1.3787 - val_accuracy: 0.0191\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5889 - accuracy: 0.0198 - val_loss: 1.2937 - val_accuracy: 0.0206\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5955 - accuracy: 0.0182 - val_loss: 1.3847 - val_accuracy: 0.0165\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5647 - accuracy: 0.0194 - val_loss: 1.3034 - val_accuracy: 0.0221\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5911 - accuracy: 0.0207 - val_loss: 1.2527 - val_accuracy: 0.0261\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5746 - accuracy: 0.0202 - val_loss: 1.6194 - val_accuracy: 0.0226\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5936 - accuracy: 0.0227 - val_loss: 1.2515 - val_accuracy: 0.0231\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6145 - accuracy: 0.0219 - val_loss: 1.6920 - val_accuracy: 0.0176\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5736 - accuracy: 0.0184 - val_loss: 1.3148 - val_accuracy: 0.0206\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5733 - accuracy: 0.0223 - val_loss: 1.3658 - val_accuracy: 0.0201\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5801 - accuracy: 0.0209 - val_loss: 1.2719 - val_accuracy: 0.0266\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5576 - accuracy: 0.0239 - val_loss: 1.3775 - val_accuracy: 0.0256\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5774 - accuracy: 0.0228 - val_loss: 1.2739 - val_accuracy: 0.0246\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 1.5777 - accuracy: 0.0207 - val_loss: 1.4066 - val_accuracy: 0.0216\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5610 - accuracy: 0.0252 - val_loss: 1.3395 - val_accuracy: 0.0191\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5597 - accuracy: 0.0239 - val_loss: 1.3739 - val_accuracy: 0.0261\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.6233 - accuracy: 0.0193 - val_loss: 1.2577 - val_accuracy: 0.0206\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5806 - accuracy: 0.0181 - val_loss: 1.2497 - val_accuracy: 0.0211\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5680 - accuracy: 0.0206 - val_loss: 1.2590 - val_accuracy: 0.0186\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5636 - accuracy: 0.0208 - val_loss: 1.3821 - val_accuracy: 0.0176\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5567 - accuracy: 0.0217 - val_loss: 1.3093 - val_accuracy: 0.0171\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5564 - accuracy: 0.0202 - val_loss: 1.3879 - val_accuracy: 0.0201\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5613 - accuracy: 0.0223 - val_loss: 1.2425 - val_accuracy: 0.0231\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5401 - accuracy: 0.0206 - val_loss: 1.2872 - val_accuracy: 0.0181\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5591 - accuracy: 0.0236 - val_loss: 1.2490 - val_accuracy: 0.0165\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5332 - accuracy: 0.0221 - val_loss: 1.2306 - val_accuracy: 0.0201\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5581 - accuracy: 0.0236 - val_loss: 1.5492 - val_accuracy: 0.0251\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 1.5392 - accuracy: 0.0251 - val_loss: 1.2347 - val_accuracy: 0.0216\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 7s 17ms/step - loss: 6.7837 - accuracy: 0.0162 - val_loss: 1.4128 - val_accuracy: 0.0171\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.9509 - accuracy: 0.0176 - val_loss: 1.3192 - val_accuracy: 0.0135\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 2.6290 - accuracy: 0.0137 - val_loss: 1.3775 - val_accuracy: 0.0150\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.7372 - accuracy: 0.0134 - val_loss: 1.3986 - val_accuracy: 0.0155\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.8129 - accuracy: 0.0158 - val_loss: 1.8656 - val_accuracy: 0.0171\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6953 - accuracy: 0.0162 - val_loss: 1.4614 - val_accuracy: 0.0160\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.6286 - accuracy: 0.0124 - val_loss: 1.2704 - val_accuracy: 0.0171\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.6685 - accuracy: 0.0174 - val_loss: 1.3729 - val_accuracy: 0.0176\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.7031 - accuracy: 0.0176 - val_loss: 1.2457 - val_accuracy: 0.0206\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6081 - accuracy: 0.0172 - val_loss: 1.3070 - val_accuracy: 0.0150\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6169 - accuracy: 0.0186 - val_loss: 1.5427 - val_accuracy: 0.0130\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6324 - accuracy: 0.0173 - val_loss: 1.2873 - val_accuracy: 0.0160\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5876 - accuracy: 0.0174 - val_loss: 1.3773 - val_accuracy: 0.0196\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5975 - accuracy: 0.0167 - val_loss: 1.2705 - val_accuracy: 0.0150\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6004 - accuracy: 0.0162 - val_loss: 1.2675 - val_accuracy: 0.0201\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.6391 - accuracy: 0.0201 - val_loss: 1.2937 - val_accuracy: 0.0196\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5815 - accuracy: 0.0174 - val_loss: 1.3539 - val_accuracy: 0.0201\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5956 - accuracy: 0.0189 - val_loss: 1.2811 - val_accuracy: 0.0165\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5881 - accuracy: 0.0219 - val_loss: 1.3002 - val_accuracy: 0.0165\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5846 - accuracy: 0.0197 - val_loss: 1.4393 - val_accuracy: 0.0211\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6162 - accuracy: 0.0216 - val_loss: 1.4732 - val_accuracy: 0.0176\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5709 - accuracy: 0.0191 - val_loss: 1.2984 - val_accuracy: 0.0231\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5796 - accuracy: 0.0213 - val_loss: 1.3496 - val_accuracy: 0.0206\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5825 - accuracy: 0.0219 - val_loss: 1.2504 - val_accuracy: 0.0191\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5899 - accuracy: 0.0193 - val_loss: 1.3374 - val_accuracy: 0.0165\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5689 - accuracy: 0.0211 - val_loss: 1.3144 - val_accuracy: 0.0206\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5759 - accuracy: 0.0201 - val_loss: 1.2627 - val_accuracy: 0.0206\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5503 - accuracy: 0.0187 - val_loss: 1.3035 - val_accuracy: 0.0196\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5810 - accuracy: 0.0193 - val_loss: 1.2535 - val_accuracy: 0.0181\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5813 - accuracy: 0.0181 - val_loss: 1.2865 - val_accuracy: 0.0171\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5863 - accuracy: 0.0172 - val_loss: 1.2838 - val_accuracy: 0.0171\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5548 - accuracy: 0.0182 - val_loss: 1.2997 - val_accuracy: 0.0191\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5663 - accuracy: 0.0214 - val_loss: 1.2781 - val_accuracy: 0.0150\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5738 - accuracy: 0.0224 - val_loss: 1.6672 - val_accuracy: 0.0196\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5512 - accuracy: 0.0199 - val_loss: 1.2817 - val_accuracy: 0.0186\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5681 - accuracy: 0.0206 - val_loss: 1.2563 - val_accuracy: 0.0191\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5492 - accuracy: 0.0212 - val_loss: 1.3008 - val_accuracy: 0.0181\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5440 - accuracy: 0.0233 - val_loss: 1.2567 - val_accuracy: 0.0216\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6126 - accuracy: 0.0174 - val_loss: 1.3656 - val_accuracy: 0.0216\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5567 - accuracy: 0.0209 - val_loss: 1.2426 - val_accuracy: 0.0201\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6176 - accuracy: 0.0223 - val_loss: 1.2583 - val_accuracy: 0.0216\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6400 - accuracy: 0.0182 - val_loss: 1.2360 - val_accuracy: 0.0145\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.6956 - accuracy: 0.0176 - val_loss: 1.4183 - val_accuracy: 0.0176\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5773 - accuracy: 0.0201 - val_loss: 1.2409 - val_accuracy: 0.0186\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5603 - accuracy: 0.0188 - val_loss: 1.3359 - val_accuracy: 0.0165\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5436 - accuracy: 0.0179 - val_loss: 1.2324 - val_accuracy: 0.0186\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.5545 - accuracy: 0.0211 - val_loss: 1.2548 - val_accuracy: 0.0196\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5713 - accuracy: 0.0176 - val_loss: 1.4135 - val_accuracy: 0.0171\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5456 - accuracy: 0.0178 - val_loss: 1.2899 - val_accuracy: 0.0171\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5385 - accuracy: 0.0189 - val_loss: 1.3163 - val_accuracy: 0.0226\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 6s 16ms/step - loss: 8.0662 - accuracy: 0.0164 - val_loss: 2.2575 - val_accuracy: 0.0140\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 1.8585 - accuracy: 0.0142 - val_loss: 1.8585 - val_accuracy: 0.0165\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.7344 - accuracy: 0.0145 - val_loss: 1.5339 - val_accuracy: 0.0135\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.9132 - accuracy: 0.0132 - val_loss: 1.3210 - val_accuracy: 0.0150\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6542 - accuracy: 0.0147 - val_loss: 1.4314 - val_accuracy: 0.0165\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6847 - accuracy: 0.0163 - val_loss: 1.6322 - val_accuracy: 0.0160\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.7122 - accuracy: 0.0158 - val_loss: 1.5437 - val_accuracy: 0.0171\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6375 - accuracy: 0.0149 - val_loss: 1.2616 - val_accuracy: 0.0135\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6043 - accuracy: 0.0179 - val_loss: 1.3236 - val_accuracy: 0.0160\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.7241 - accuracy: 0.0176 - val_loss: 1.7413 - val_accuracy: 0.0176\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5771 - accuracy: 0.0171 - val_loss: 1.4696 - val_accuracy: 0.0135\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6104 - accuracy: 0.0142 - val_loss: 1.3197 - val_accuracy: 0.0160\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5865 - accuracy: 0.0187 - val_loss: 1.3197 - val_accuracy: 0.0171\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5755 - accuracy: 0.0154 - val_loss: 1.3939 - val_accuracy: 0.0155\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.6492 - accuracy: 0.0181 - val_loss: 1.8668 - val_accuracy: 0.0191\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.6290 - accuracy: 0.0181 - val_loss: 1.5797 - val_accuracy: 0.0171\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.6213 - accuracy: 0.0142 - val_loss: 1.6056 - val_accuracy: 0.0226\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6247 - accuracy: 0.0188 - val_loss: 1.3403 - val_accuracy: 0.0140\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5731 - accuracy: 0.0184 - val_loss: 1.2708 - val_accuracy: 0.0155\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5483 - accuracy: 0.0203 - val_loss: 1.2680 - val_accuracy: 0.0160\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5639 - accuracy: 0.0192 - val_loss: 1.3807 - val_accuracy: 0.0165\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5519 - accuracy: 0.0202 - val_loss: 1.2600 - val_accuracy: 0.0236\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5631 - accuracy: 0.0203 - val_loss: 1.5079 - val_accuracy: 0.0160\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6216 - accuracy: 0.0172 - val_loss: 1.4099 - val_accuracy: 0.0150\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6201 - accuracy: 0.0172 - val_loss: 1.2568 - val_accuracy: 0.0150\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5712 - accuracy: 0.0193 - val_loss: 1.2473 - val_accuracy: 0.0186\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5562 - accuracy: 0.0173 - val_loss: 1.2796 - val_accuracy: 0.0206\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5738 - accuracy: 0.0206 - val_loss: 1.3422 - val_accuracy: 0.0211\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 2.0290 - accuracy: 0.0163 - val_loss: 1.4748 - val_accuracy: 0.0176\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5730 - accuracy: 0.0177 - val_loss: 1.3103 - val_accuracy: 0.0186\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5551 - accuracy: 0.0201 - val_loss: 1.3281 - val_accuracy: 0.0135\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5526 - accuracy: 0.0172 - val_loss: 1.2522 - val_accuracy: 0.0165\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5785 - accuracy: 0.0162 - val_loss: 1.2506 - val_accuracy: 0.0140\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5502 - accuracy: 0.0178 - val_loss: 1.2590 - val_accuracy: 0.0140\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5613 - accuracy: 0.0148 - val_loss: 1.3016 - val_accuracy: 0.0150\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5509 - accuracy: 0.0183 - val_loss: 1.2726 - val_accuracy: 0.0186\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5443 - accuracy: 0.0174 - val_loss: 1.2320 - val_accuracy: 0.0181\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5658 - accuracy: 0.0172 - val_loss: 1.2483 - val_accuracy: 0.0181\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.6341 - accuracy: 0.0169 - val_loss: 1.2353 - val_accuracy: 0.0176\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5775 - accuracy: 0.0176 - val_loss: 1.2401 - val_accuracy: 0.0191\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5489 - accuracy: 0.0198 - val_loss: 1.3460 - val_accuracy: 0.0165\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5623 - accuracy: 0.0184 - val_loss: 1.3257 - val_accuracy: 0.0165\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5454 - accuracy: 0.0193 - val_loss: 1.3213 - val_accuracy: 0.0191\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5466 - accuracy: 0.0218 - val_loss: 1.3682 - val_accuracy: 0.0176\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5487 - accuracy: 0.0198 - val_loss: 1.2545 - val_accuracy: 0.0165\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 1.5467 - accuracy: 0.0192 - val_loss: 1.2638 - val_accuracy: 0.0165\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5420 - accuracy: 0.0207 - val_loss: 1.2688 - val_accuracy: 0.0145\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5339 - accuracy: 0.0189 - val_loss: 1.2367 - val_accuracy: 0.0226\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5446 - accuracy: 0.0235 - val_loss: 1.3808 - val_accuracy: 0.0211\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 3s 14ms/step - loss: 1.5544 - accuracy: 0.0221 - val_loss: 1.2580 - val_accuracy: 0.0160\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 6s 17ms/step - loss: 5.3276 - accuracy: 0.0162 - val_loss: 1.3545 - val_accuracy: 0.0140\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.8351 - accuracy: 0.0149 - val_loss: 2.2198 - val_accuracy: 0.0145\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 2.0887 - accuracy: 0.0161 - val_loss: 2.3420 - val_accuracy: 0.0160\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.8607 - accuracy: 0.0142 - val_loss: 1.3189 - val_accuracy: 0.0130\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6359 - accuracy: 0.0148 - val_loss: 1.3076 - val_accuracy: 0.0155\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6579 - accuracy: 0.0130 - val_loss: 1.3614 - val_accuracy: 0.0130\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6585 - accuracy: 0.0158 - val_loss: 1.8718 - val_accuracy: 0.0155\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6615 - accuracy: 0.0156 - val_loss: 1.3503 - val_accuracy: 0.0171\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.7420 - accuracy: 0.0186 - val_loss: 1.4661 - val_accuracy: 0.0135\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.7011 - accuracy: 0.0167 - val_loss: 1.2684 - val_accuracy: 0.0140\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6362 - accuracy: 0.0167 - val_loss: 1.3372 - val_accuracy: 0.0171\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6240 - accuracy: 0.0153 - val_loss: 2.0266 - val_accuracy: 0.0130\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6112 - accuracy: 0.0153 - val_loss: 2.1043 - val_accuracy: 0.0135\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6044 - accuracy: 0.0145 - val_loss: 1.5490 - val_accuracy: 0.0160\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6296 - accuracy: 0.0151 - val_loss: 1.2841 - val_accuracy: 0.0155\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5966 - accuracy: 0.0153 - val_loss: 1.2959 - val_accuracy: 0.0145\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5679 - accuracy: 0.0171 - val_loss: 1.9946 - val_accuracy: 0.0140\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5931 - accuracy: 0.0140 - val_loss: 1.3193 - val_accuracy: 0.0145\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5911 - accuracy: 0.0167 - val_loss: 1.3633 - val_accuracy: 0.0165\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6161 - accuracy: 0.0188 - val_loss: 1.3731 - val_accuracy: 0.0160\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5813 - accuracy: 0.0147 - val_loss: 1.7519 - val_accuracy: 0.0176\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6793 - accuracy: 0.0174 - val_loss: 1.2529 - val_accuracy: 0.0155\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5899 - accuracy: 0.0178 - val_loss: 1.2569 - val_accuracy: 0.0176\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5540 - accuracy: 0.0192 - val_loss: 1.2545 - val_accuracy: 0.0171\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5847 - accuracy: 0.0188 - val_loss: 1.2580 - val_accuracy: 0.0186\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5454 - accuracy: 0.0172 - val_loss: 1.2465 - val_accuracy: 0.0155\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5736 - accuracy: 0.0204 - val_loss: 1.3380 - val_accuracy: 0.0145\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5727 - accuracy: 0.0208 - val_loss: 1.2337 - val_accuracy: 0.0176\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5515 - accuracy: 0.0189 - val_loss: 1.4368 - val_accuracy: 0.0196\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5732 - accuracy: 0.0197 - val_loss: 1.2656 - val_accuracy: 0.0181\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5452 - accuracy: 0.0199 - val_loss: 1.2425 - val_accuracy: 0.0155\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5568 - accuracy: 0.0203 - val_loss: 1.2606 - val_accuracy: 0.0196\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5709 - accuracy: 0.0206 - val_loss: 1.2828 - val_accuracy: 0.0176\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5511 - accuracy: 0.0206 - val_loss: 1.2725 - val_accuracy: 0.0165\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6035 - accuracy: 0.0191 - val_loss: 1.3062 - val_accuracy: 0.0171\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5873 - accuracy: 0.0199 - val_loss: 1.4980 - val_accuracy: 0.0191\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5514 - accuracy: 0.0208 - val_loss: 1.2538 - val_accuracy: 0.0186\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5292 - accuracy: 0.0207 - val_loss: 1.5804 - val_accuracy: 0.0216\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5519 - accuracy: 0.0192 - val_loss: 1.2625 - val_accuracy: 0.0165\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5300 - accuracy: 0.0206 - val_loss: 1.2558 - val_accuracy: 0.0196\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5328 - accuracy: 0.0204 - val_loss: 1.3110 - val_accuracy: 0.0155\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5424 - accuracy: 0.0212 - val_loss: 1.2392 - val_accuracy: 0.0196\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6852 - accuracy: 0.0177 - val_loss: 1.5321 - val_accuracy: 0.0171\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5600 - accuracy: 0.0154 - val_loss: 1.3109 - val_accuracy: 0.0140\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5625 - accuracy: 0.0184 - val_loss: 1.2367 - val_accuracy: 0.0196\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5564 - accuracy: 0.0211 - val_loss: 1.2407 - val_accuracy: 0.0186\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.5450 - accuracy: 0.0189 - val_loss: 1.3696 - val_accuracy: 0.0165\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5431 - accuracy: 0.0183 - val_loss: 1.2700 - val_accuracy: 0.0135\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5438 - accuracy: 0.0189 - val_loss: 1.2364 - val_accuracy: 0.0181\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5396 - accuracy: 0.0196 - val_loss: 1.2512 - val_accuracy: 0.0196\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 8s 18ms/step - loss: 6.8393 - accuracy: 0.0130 - val_loss: 2.8431 - val_accuracy: 0.0145\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.9830 - accuracy: 0.0140 - val_loss: 1.3212 - val_accuracy: 0.0135\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6765 - accuracy: 0.0142 - val_loss: 1.6628 - val_accuracy: 0.0165\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6789 - accuracy: 0.0134 - val_loss: 1.4181 - val_accuracy: 0.0176\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6925 - accuracy: 0.0133 - val_loss: 1.3292 - val_accuracy: 0.0160\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6779 - accuracy: 0.0162 - val_loss: 1.5146 - val_accuracy: 0.0155\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.6611 - accuracy: 0.0158 - val_loss: 1.6420 - val_accuracy: 0.0160\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6241 - accuracy: 0.0163 - val_loss: 1.5038 - val_accuracy: 0.0181\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6257 - accuracy: 0.0149 - val_loss: 1.6470 - val_accuracy: 0.0135\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6537 - accuracy: 0.0156 - val_loss: 1.3848 - val_accuracy: 0.0155\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 4s 15ms/step - loss: 1.6019 - accuracy: 0.0184 - val_loss: 1.3205 - val_accuracy: 0.0150\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6252 - accuracy: 0.0144 - val_loss: 1.5822 - val_accuracy: 0.0165\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.6124 - accuracy: 0.0189 - val_loss: 1.4212 - val_accuracy: 0.0155\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6906 - accuracy: 0.0162 - val_loss: 1.5612 - val_accuracy: 0.0171\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5714 - accuracy: 0.0172 - val_loss: 1.4360 - val_accuracy: 0.0181\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5892 - accuracy: 0.0146 - val_loss: 1.4406 - val_accuracy: 0.0176\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6372 - accuracy: 0.0177 - val_loss: 1.2809 - val_accuracy: 0.0196\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5753 - accuracy: 0.0172 - val_loss: 1.3455 - val_accuracy: 0.0165\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5828 - accuracy: 0.0217 - val_loss: 1.3559 - val_accuracy: 0.0201\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5732 - accuracy: 0.0235 - val_loss: 1.2522 - val_accuracy: 0.0165\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5683 - accuracy: 0.0216 - val_loss: 1.3641 - val_accuracy: 0.0181\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5843 - accuracy: 0.0211 - val_loss: 1.2509 - val_accuracy: 0.0216\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5513 - accuracy: 0.0222 - val_loss: 1.2975 - val_accuracy: 0.0211\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5588 - accuracy: 0.0199 - val_loss: 1.4101 - val_accuracy: 0.0216\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5534 - accuracy: 0.0223 - val_loss: 1.2654 - val_accuracy: 0.0181\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5668 - accuracy: 0.0222 - val_loss: 1.2564 - val_accuracy: 0.0186\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5482 - accuracy: 0.0222 - val_loss: 1.3681 - val_accuracy: 0.0186\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5826 - accuracy: 0.0222 - val_loss: 1.5872 - val_accuracy: 0.0196\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5659 - accuracy: 0.0225 - val_loss: 1.2958 - val_accuracy: 0.0186\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5510 - accuracy: 0.0212 - val_loss: 1.2362 - val_accuracy: 0.0211\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5420 - accuracy: 0.0198 - val_loss: 1.2533 - val_accuracy: 0.0191\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5539 - accuracy: 0.0223 - val_loss: 1.3341 - val_accuracy: 0.0196\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5420 - accuracy: 0.0222 - val_loss: 1.3732 - val_accuracy: 0.0176\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5407 - accuracy: 0.0223 - val_loss: 1.3223 - val_accuracy: 0.0181\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5388 - accuracy: 0.0198 - val_loss: 1.3847 - val_accuracy: 0.0181\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5280 - accuracy: 0.0253 - val_loss: 1.2590 - val_accuracy: 0.0176\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5293 - accuracy: 0.0226 - val_loss: 1.2513 - val_accuracy: 0.0206\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5305 - accuracy: 0.0263 - val_loss: 1.2570 - val_accuracy: 0.0211\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5303 - accuracy: 0.0217 - val_loss: 1.2381 - val_accuracy: 0.0206\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5321 - accuracy: 0.0257 - val_loss: 1.3118 - val_accuracy: 0.0186\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5254 - accuracy: 0.0237 - val_loss: 1.4309 - val_accuracy: 0.0221\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5349 - accuracy: 0.0256 - val_loss: 1.3386 - val_accuracy: 0.0165\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5191 - accuracy: 0.0252 - val_loss: 1.3188 - val_accuracy: 0.0216\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5235 - accuracy: 0.0226 - val_loss: 1.5240 - val_accuracy: 0.0171\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5310 - accuracy: 0.0220 - val_loss: 1.3111 - val_accuracy: 0.0206\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5082 - accuracy: 0.0230 - val_loss: 1.2645 - val_accuracy: 0.0211\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5243 - accuracy: 0.0263 - val_loss: 1.4254 - val_accuracy: 0.0216\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5148 - accuracy: 0.0218 - val_loss: 1.3524 - val_accuracy: 0.0221\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.5369 - accuracy: 0.0230 - val_loss: 1.4287 - val_accuracy: 0.0196\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5307 - accuracy: 0.0191 - val_loss: 1.2705 - val_accuracy: 0.0211\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 7s 19ms/step - loss: 10.5768 - accuracy: 0.0157 - val_loss: 1.5497 - val_accuracy: 0.0166\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.0179 - accuracy: 0.0134 - val_loss: 1.3895 - val_accuracy: 0.0176\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.6753 - accuracy: 0.0161 - val_loss: 1.3098 - val_accuracy: 0.0161\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.6682 - accuracy: 0.0154 - val_loss: 2.5979 - val_accuracy: 0.0146\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.7378 - accuracy: 0.0147 - val_loss: 1.7101 - val_accuracy: 0.0135\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.6452 - accuracy: 0.0159 - val_loss: 1.3396 - val_accuracy: 0.0156\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.7709 - accuracy: 0.0123 - val_loss: 1.3214 - val_accuracy: 0.0140\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.8220 - accuracy: 0.0159 - val_loss: 1.2899 - val_accuracy: 0.0130\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6151 - accuracy: 0.0156 - val_loss: 1.3572 - val_accuracy: 0.0140\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.6079 - accuracy: 0.0167 - val_loss: 1.4306 - val_accuracy: 0.0161\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.6619 - accuracy: 0.0124 - val_loss: 2.0355 - val_accuracy: 0.0156\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.6157 - accuracy: 0.0169 - val_loss: 1.6722 - val_accuracy: 0.0176\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.6648 - accuracy: 0.0184 - val_loss: 1.2519 - val_accuracy: 0.0146\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5815 - accuracy: 0.0161 - val_loss: 1.6555 - val_accuracy: 0.0161\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.6026 - accuracy: 0.0174 - val_loss: 1.5688 - val_accuracy: 0.0151\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.6141 - accuracy: 0.0171 - val_loss: 1.2989 - val_accuracy: 0.0161\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.7144 - accuracy: 0.0198 - val_loss: 1.5591 - val_accuracy: 0.0196\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6192 - accuracy: 0.0202 - val_loss: 1.2439 - val_accuracy: 0.0156\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5867 - accuracy: 0.0179 - val_loss: 1.2663 - val_accuracy: 0.0211\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5746 - accuracy: 0.0183 - val_loss: 1.2632 - val_accuracy: 0.0186\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.6331 - accuracy: 0.0189 - val_loss: 1.3770 - val_accuracy: 0.0186\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5536 - accuracy: 0.0198 - val_loss: 1.3628 - val_accuracy: 0.0181\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5669 - accuracy: 0.0226 - val_loss: 1.5820 - val_accuracy: 0.0161\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5751 - accuracy: 0.0209 - val_loss: 1.2689 - val_accuracy: 0.0156\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5541 - accuracy: 0.0197 - val_loss: 1.2868 - val_accuracy: 0.0181\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.6177 - accuracy: 0.0201 - val_loss: 1.7853 - val_accuracy: 0.0171\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.6019 - accuracy: 0.0171 - val_loss: 2.0682 - val_accuracy: 0.0171\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.6041 - accuracy: 0.0176 - val_loss: 1.2401 - val_accuracy: 0.0176\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5621 - accuracy: 0.0201 - val_loss: 1.2274 - val_accuracy: 0.0146\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5389 - accuracy: 0.0197 - val_loss: 1.2680 - val_accuracy: 0.0176\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5657 - accuracy: 0.0213 - val_loss: 1.2944 - val_accuracy: 0.0146\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5481 - accuracy: 0.0206 - val_loss: 1.2568 - val_accuracy: 0.0156\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 4s 17ms/step - loss: 1.5344 - accuracy: 0.0221 - val_loss: 1.2831 - val_accuracy: 0.0161\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5448 - accuracy: 0.0177 - val_loss: 1.2389 - val_accuracy: 0.0191\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5471 - accuracy: 0.0232 - val_loss: 1.2848 - val_accuracy: 0.0161\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5386 - accuracy: 0.0223 - val_loss: 1.2622 - val_accuracy: 0.0171\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5359 - accuracy: 0.0207 - val_loss: 1.5741 - val_accuracy: 0.0176\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5376 - accuracy: 0.0223 - val_loss: 1.3441 - val_accuracy: 0.0216\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5340 - accuracy: 0.0227 - val_loss: 1.3811 - val_accuracy: 0.0161\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5530 - accuracy: 0.0222 - val_loss: 1.2789 - val_accuracy: 0.0196\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5513 - accuracy: 0.0193 - val_loss: 1.3384 - val_accuracy: 0.0191\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5244 - accuracy: 0.0222 - val_loss: 1.2546 - val_accuracy: 0.0216\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5557 - accuracy: 0.0220 - val_loss: 1.3754 - val_accuracy: 0.0191\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5567 - accuracy: 0.0233 - val_loss: 1.3782 - val_accuracy: 0.0201\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5323 - accuracy: 0.0197 - val_loss: 1.3041 - val_accuracy: 0.0156\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5487 - accuracy: 0.0215 - val_loss: 1.2477 - val_accuracy: 0.0196\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5246 - accuracy: 0.0198 - val_loss: 1.2309 - val_accuracy: 0.0166\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5319 - accuracy: 0.0228 - val_loss: 1.2454 - val_accuracy: 0.0181\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 4s 18ms/step - loss: 1.5327 - accuracy: 0.0204 - val_loss: 1.4099 - val_accuracy: 0.0196\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5624 - accuracy: 0.0176 - val_loss: 1.3401 - val_accuracy: 0.0140\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 8s 20ms/step - loss: 10.1477 - accuracy: 0.0157 - val_loss: 1.3073 - val_accuracy: 0.0166\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.7598 - accuracy: 0.0146 - val_loss: 1.5465 - val_accuracy: 0.0151\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.6712 - accuracy: 0.0194 - val_loss: 1.5372 - val_accuracy: 0.0161\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.8785 - accuracy: 0.0151 - val_loss: 1.4447 - val_accuracy: 0.0186\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.7326 - accuracy: 0.0141 - val_loss: 1.3929 - val_accuracy: 0.0161\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.6107 - accuracy: 0.0163 - val_loss: 1.5309 - val_accuracy: 0.0156\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.7339 - accuracy: 0.0148 - val_loss: 1.2726 - val_accuracy: 0.0161\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.6475 - accuracy: 0.0147 - val_loss: 2.2799 - val_accuracy: 0.0176\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6903 - accuracy: 0.0141 - val_loss: 1.3028 - val_accuracy: 0.0156\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5770 - accuracy: 0.0179 - val_loss: 1.3386 - val_accuracy: 0.0161\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6077 - accuracy: 0.0143 - val_loss: 1.2516 - val_accuracy: 0.0176\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5877 - accuracy: 0.0168 - val_loss: 1.3175 - val_accuracy: 0.0156\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.6532 - accuracy: 0.0143 - val_loss: 1.2775 - val_accuracy: 0.0151\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.6095 - accuracy: 0.0174 - val_loss: 1.2521 - val_accuracy: 0.0176\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6224 - accuracy: 0.0149 - val_loss: 1.2702 - val_accuracy: 0.0156\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5542 - accuracy: 0.0129 - val_loss: 1.2743 - val_accuracy: 0.0176\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6424 - accuracy: 0.0169 - val_loss: 1.6966 - val_accuracy: 0.0171\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6084 - accuracy: 0.0177 - val_loss: 2.0261 - val_accuracy: 0.0135\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5829 - accuracy: 0.0154 - val_loss: 1.5042 - val_accuracy: 0.0151\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5810 - accuracy: 0.0193 - val_loss: 1.5349 - val_accuracy: 0.0156\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5690 - accuracy: 0.0161 - val_loss: 1.3603 - val_accuracy: 0.0166\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5652 - accuracy: 0.0161 - val_loss: 1.4727 - val_accuracy: 0.0140\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5800 - accuracy: 0.0153 - val_loss: 1.4846 - val_accuracy: 0.0156\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5858 - accuracy: 0.0162 - val_loss: 1.3070 - val_accuracy: 0.0146\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5774 - accuracy: 0.0133 - val_loss: 1.2882 - val_accuracy: 0.0135\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5481 - accuracy: 0.0146 - val_loss: 1.2748 - val_accuracy: 0.0161\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5535 - accuracy: 0.0174 - val_loss: 1.2511 - val_accuracy: 0.0130\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5836 - accuracy: 0.0172 - val_loss: 1.2386 - val_accuracy: 0.0171\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5706 - accuracy: 0.0169 - val_loss: 1.5607 - val_accuracy: 0.0140\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5573 - accuracy: 0.0164 - val_loss: 1.5389 - val_accuracy: 0.0140\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5622 - accuracy: 0.0162 - val_loss: 1.3366 - val_accuracy: 0.0176\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5519 - accuracy: 0.0147 - val_loss: 1.2881 - val_accuracy: 0.0161\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5529 - accuracy: 0.0177 - val_loss: 1.4264 - val_accuracy: 0.0166\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5638 - accuracy: 0.0149 - val_loss: 1.3181 - val_accuracy: 0.0151\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5539 - accuracy: 0.0163 - val_loss: 1.5453 - val_accuracy: 0.0166\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5419 - accuracy: 0.0186 - val_loss: 1.4192 - val_accuracy: 0.0161\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5548 - accuracy: 0.0176 - val_loss: 1.9140 - val_accuracy: 0.0166\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5569 - accuracy: 0.0163 - val_loss: 1.2953 - val_accuracy: 0.0176\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5266 - accuracy: 0.0181 - val_loss: 1.2322 - val_accuracy: 0.0181\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5344 - accuracy: 0.0163 - val_loss: 1.3087 - val_accuracy: 0.0176\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5456 - accuracy: 0.0152 - val_loss: 1.6832 - val_accuracy: 0.0146\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.5431 - accuracy: 0.0164 - val_loss: 1.2591 - val_accuracy: 0.0140\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5302 - accuracy: 0.0169 - val_loss: 1.6947 - val_accuracy: 0.0161\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5536 - accuracy: 0.0146 - val_loss: 1.2430 - val_accuracy: 0.0181\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5405 - accuracy: 0.0176 - val_loss: 1.3594 - val_accuracy: 0.0176\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5353 - accuracy: 0.0167 - val_loss: 1.2753 - val_accuracy: 0.0181\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5398 - accuracy: 0.0192 - val_loss: 1.6390 - val_accuracy: 0.0161\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5490 - accuracy: 0.0184 - val_loss: 1.3989 - val_accuracy: 0.0176\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5320 - accuracy: 0.0164 - val_loss: 1.5668 - val_accuracy: 0.0146\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5285 - accuracy: 0.0174 - val_loss: 1.4695 - val_accuracy: 0.0196\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 8s 23ms/step - loss: 5.7658 - accuracy: 0.0163 - val_loss: 1.4449 - val_accuracy: 0.0151\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.8783 - accuracy: 0.0201 - val_loss: 1.3827 - val_accuracy: 0.0140\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.9853 - accuracy: 0.0147 - val_loss: 1.5130 - val_accuracy: 0.0166\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.7029 - accuracy: 0.0139 - val_loss: 1.3227 - val_accuracy: 0.0151\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.6795 - accuracy: 0.0141 - val_loss: 1.5190 - val_accuracy: 0.0166\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.6851 - accuracy: 0.0158 - val_loss: 2.3773 - val_accuracy: 0.0156\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.6888 - accuracy: 0.0192 - val_loss: 1.4632 - val_accuracy: 0.0156\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.7479 - accuracy: 0.0151 - val_loss: 1.3377 - val_accuracy: 0.0130\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.6481 - accuracy: 0.0182 - val_loss: 1.3581 - val_accuracy: 0.0161\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.6068 - accuracy: 0.0163 - val_loss: 1.3166 - val_accuracy: 0.0161\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6477 - accuracy: 0.0164 - val_loss: 3.1630 - val_accuracy: 0.0146\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.7299 - accuracy: 0.0169 - val_loss: 1.5347 - val_accuracy: 0.0156\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5792 - accuracy: 0.0184 - val_loss: 1.2670 - val_accuracy: 0.0161\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.6382 - accuracy: 0.0191 - val_loss: 1.3019 - val_accuracy: 0.0156\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5829 - accuracy: 0.0154 - val_loss: 1.4694 - val_accuracy: 0.0156\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5928 - accuracy: 0.0172 - val_loss: 1.3606 - val_accuracy: 0.0176\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5859 - accuracy: 0.0189 - val_loss: 1.4985 - val_accuracy: 0.0191\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5785 - accuracy: 0.0192 - val_loss: 1.5403 - val_accuracy: 0.0171\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.6590 - accuracy: 0.0162 - val_loss: 2.2473 - val_accuracy: 0.0166\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.6179 - accuracy: 0.0179 - val_loss: 1.3182 - val_accuracy: 0.0156\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5837 - accuracy: 0.0207 - val_loss: 1.2880 - val_accuracy: 0.0156\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5507 - accuracy: 0.0187 - val_loss: 1.3484 - val_accuracy: 0.0166\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5333 - accuracy: 0.0198 - val_loss: 1.4125 - val_accuracy: 0.0176\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5463 - accuracy: 0.0242 - val_loss: 1.6885 - val_accuracy: 0.0206\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.6306 - accuracy: 0.0186 - val_loss: 1.5022 - val_accuracy: 0.0181\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.6043 - accuracy: 0.0186 - val_loss: 1.9978 - val_accuracy: 0.0166\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.6071 - accuracy: 0.0201 - val_loss: 1.2671 - val_accuracy: 0.0166\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5386 - accuracy: 0.0220 - val_loss: 1.8819 - val_accuracy: 0.0161\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5677 - accuracy: 0.0225 - val_loss: 1.2411 - val_accuracy: 0.0181\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5645 - accuracy: 0.0191 - val_loss: 1.3740 - val_accuracy: 0.0161\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5375 - accuracy: 0.0217 - val_loss: 1.2482 - val_accuracy: 0.0191\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5323 - accuracy: 0.0217 - val_loss: 1.2441 - val_accuracy: 0.0221\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5294 - accuracy: 0.0228 - val_loss: 1.3730 - val_accuracy: 0.0201\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5344 - accuracy: 0.0257 - val_loss: 1.3248 - val_accuracy: 0.0161\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5411 - accuracy: 0.0220 - val_loss: 1.2507 - val_accuracy: 0.0161\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5442 - accuracy: 0.0212 - val_loss: 2.1008 - val_accuracy: 0.0196\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5355 - accuracy: 0.0231 - val_loss: 1.2415 - val_accuracy: 0.0176\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5938 - accuracy: 0.0187 - val_loss: 1.3297 - val_accuracy: 0.0156\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5339 - accuracy: 0.0194 - val_loss: 1.5247 - val_accuracy: 0.0171\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5364 - accuracy: 0.0210 - val_loss: 1.2286 - val_accuracy: 0.0161\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5265 - accuracy: 0.0187 - val_loss: 1.3450 - val_accuracy: 0.0186\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5514 - accuracy: 0.0217 - val_loss: 1.2397 - val_accuracy: 0.0181\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5453 - accuracy: 0.0236 - val_loss: 1.2442 - val_accuracy: 0.0161\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5231 - accuracy: 0.0211 - val_loss: 1.4010 - val_accuracy: 0.0186\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5209 - accuracy: 0.0210 - val_loss: 1.5023 - val_accuracy: 0.0211\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5230 - accuracy: 0.0212 - val_loss: 1.4539 - val_accuracy: 0.0151\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5270 - accuracy: 0.0184 - val_loss: 1.7283 - val_accuracy: 0.0166\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5228 - accuracy: 0.0220 - val_loss: 1.2568 - val_accuracy: 0.0140\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5260 - accuracy: 0.0227 - val_loss: 1.2510 - val_accuracy: 0.0166\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5283 - accuracy: 0.0202 - val_loss: 1.2445 - val_accuracy: 0.0186\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 9s 24ms/step - loss: 7.9882 - accuracy: 0.0174 - val_loss: 2.6415 - val_accuracy: 0.0125\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.8826 - accuracy: 0.0152 - val_loss: 5.9502 - val_accuracy: 0.0171\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 2.0359 - accuracy: 0.0162 - val_loss: 1.9013 - val_accuracy: 0.0151\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.7375 - accuracy: 0.0143 - val_loss: 1.6877 - val_accuracy: 0.0161\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.9767 - accuracy: 0.0154 - val_loss: 1.4980 - val_accuracy: 0.0161\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.7135 - accuracy: 0.0152 - val_loss: 1.6724 - val_accuracy: 0.0140\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.6122 - accuracy: 0.0142 - val_loss: 3.4359 - val_accuracy: 0.0146\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.6716 - accuracy: 0.0147 - val_loss: 1.7307 - val_accuracy: 0.0140\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.6107 - accuracy: 0.0147 - val_loss: 1.7848 - val_accuracy: 0.0181\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.6366 - accuracy: 0.0159 - val_loss: 1.6535 - val_accuracy: 0.0151\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.6077 - accuracy: 0.0166 - val_loss: 3.1614 - val_accuracy: 0.0140\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.7280 - accuracy: 0.0178 - val_loss: 1.4309 - val_accuracy: 0.0161\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 1.6036 - accuracy: 0.0153 - val_loss: 1.7288 - val_accuracy: 0.0156\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5975 - accuracy: 0.0183 - val_loss: 1.5505 - val_accuracy: 0.0135\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.6238 - accuracy: 0.0166 - val_loss: 1.4144 - val_accuracy: 0.0166\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.5828 - accuracy: 0.0147 - val_loss: 1.3417 - val_accuracy: 0.0135\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.6002 - accuracy: 0.0178 - val_loss: 1.5804 - val_accuracy: 0.0140\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5873 - accuracy: 0.0157 - val_loss: 2.0245 - val_accuracy: 0.0140\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.6290 - accuracy: 0.0144 - val_loss: 2.0934 - val_accuracy: 0.0161\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.6138 - accuracy: 0.0154 - val_loss: 1.5006 - val_accuracy: 0.0156\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.5780 - accuracy: 0.0183 - val_loss: 1.2739 - val_accuracy: 0.0181\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5753 - accuracy: 0.0187 - val_loss: 1.6130 - val_accuracy: 0.0181\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.6121 - accuracy: 0.0167 - val_loss: 2.5124 - val_accuracy: 0.0156\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5885 - accuracy: 0.0176 - val_loss: 1.5493 - val_accuracy: 0.0156\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5563 - accuracy: 0.0220 - val_loss: 1.3515 - val_accuracy: 0.0171\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5610 - accuracy: 0.0207 - val_loss: 1.7438 - val_accuracy: 0.0196\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.5830 - accuracy: 0.0192 - val_loss: 2.3084 - val_accuracy: 0.0156\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5939 - accuracy: 0.0176 - val_loss: 1.3989 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5537 - accuracy: 0.0193 - val_loss: 1.4982 - val_accuracy: 0.0206\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5572 - accuracy: 0.0172 - val_loss: 2.4001 - val_accuracy: 0.0171\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.5949 - accuracy: 0.0171 - val_loss: 2.3595 - val_accuracy: 0.0161\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5698 - accuracy: 0.0158 - val_loss: 1.3845 - val_accuracy: 0.0156\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5468 - accuracy: 0.0162 - val_loss: 2.8778 - val_accuracy: 0.0135\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.5784 - accuracy: 0.0161 - val_loss: 1.7531 - val_accuracy: 0.0186\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5418 - accuracy: 0.0172 - val_loss: 1.5982 - val_accuracy: 0.0176\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5680 - accuracy: 0.0178 - val_loss: 1.2647 - val_accuracy: 0.0166\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5357 - accuracy: 0.0208 - val_loss: 1.7944 - val_accuracy: 0.0161\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5837 - accuracy: 0.0176 - val_loss: 2.0535 - val_accuracy: 0.0166\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5613 - accuracy: 0.0157 - val_loss: 1.5814 - val_accuracy: 0.0151\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.7713 - accuracy: 0.0162 - val_loss: 1.3020 - val_accuracy: 0.0135\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.8465 - accuracy: 0.0151 - val_loss: 1.2846 - val_accuracy: 0.0146\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.6493 - accuracy: 0.0164 - val_loss: 1.7173 - val_accuracy: 0.0156\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.6108 - accuracy: 0.0152 - val_loss: 1.3776 - val_accuracy: 0.0156\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.5454 - accuracy: 0.0184 - val_loss: 1.2688 - val_accuracy: 0.0161\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.5349 - accuracy: 0.0168 - val_loss: 1.4607 - val_accuracy: 0.0181\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5510 - accuracy: 0.0152 - val_loss: 1.5135 - val_accuracy: 0.0176\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5334 - accuracy: 0.0169 - val_loss: 1.3608 - val_accuracy: 0.0176\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.5258 - accuracy: 0.0166 - val_loss: 1.3868 - val_accuracy: 0.0151\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 1.5918 - accuracy: 0.0157 - val_loss: 2.6047 - val_accuracy: 0.0156\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 1.7511 - accuracy: 0.0157 - val_loss: 1.2569 - val_accuracy: 0.0135\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 7s 22ms/step - loss: 6.0207 - accuracy: 0.0161 - val_loss: 1.4158 - val_accuracy: 0.0156\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 4s 18ms/step - loss: 1.9572 - accuracy: 0.0168 - val_loss: 1.2830 - val_accuracy: 0.0135\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.8987 - accuracy: 0.0151 - val_loss: 1.4153 - val_accuracy: 0.0146\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.7252 - accuracy: 0.0169 - val_loss: 1.4604 - val_accuracy: 0.0151\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 5s 19ms/step - loss: 1.9530 - accuracy: 0.0127 - val_loss: 2.1869 - val_accuracy: 0.0135\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.7492 - accuracy: 0.0136 - val_loss: 1.2748 - val_accuracy: 0.0166\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.7278 - accuracy: 0.0151 - val_loss: 1.6883 - val_accuracy: 0.0166\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.7025 - accuracy: 0.0163 - val_loss: 1.2883 - val_accuracy: 0.0161\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.6611 - accuracy: 0.0128 - val_loss: 1.3584 - val_accuracy: 0.0166\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.6987 - accuracy: 0.0147 - val_loss: 1.2603 - val_accuracy: 0.0171\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 5s 19ms/step - loss: 1.6495 - accuracy: 0.0164 - val_loss: 2.9179 - val_accuracy: 0.0166\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.8439 - accuracy: 0.0159 - val_loss: 1.7583 - val_accuracy: 0.0146\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.7088 - accuracy: 0.0149 - val_loss: 1.5401 - val_accuracy: 0.0156\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.6503 - accuracy: 0.0163 - val_loss: 1.3246 - val_accuracy: 0.0156\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5622 - accuracy: 0.0154 - val_loss: 1.2383 - val_accuracy: 0.0161\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.6829 - accuracy: 0.0141 - val_loss: 1.2434 - val_accuracy: 0.0140\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5507 - accuracy: 0.0156 - val_loss: 1.2507 - val_accuracy: 0.0140\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5847 - accuracy: 0.0149 - val_loss: 1.2828 - val_accuracy: 0.0156\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5737 - accuracy: 0.0163 - val_loss: 1.2557 - val_accuracy: 0.0171\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.9997 - accuracy: 0.0166 - val_loss: 2.3771 - val_accuracy: 0.0166\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.7779 - accuracy: 0.0148 - val_loss: 1.2660 - val_accuracy: 0.0166\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5792 - accuracy: 0.0152 - val_loss: 1.2390 - val_accuracy: 0.0156\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5465 - accuracy: 0.0157 - val_loss: 1.3446 - val_accuracy: 0.0125\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5701 - accuracy: 0.0156 - val_loss: 1.4960 - val_accuracy: 0.0140\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5757 - accuracy: 0.0172 - val_loss: 1.5686 - val_accuracy: 0.0151\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5632 - accuracy: 0.0163 - val_loss: 1.2318 - val_accuracy: 0.0166\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5424 - accuracy: 0.0148 - val_loss: 1.2499 - val_accuracy: 0.0161\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5546 - accuracy: 0.0159 - val_loss: 1.2406 - val_accuracy: 0.0146\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5744 - accuracy: 0.0148 - val_loss: 1.2621 - val_accuracy: 0.0140\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5508 - accuracy: 0.0149 - val_loss: 1.2832 - val_accuracy: 0.0166\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5641 - accuracy: 0.0147 - val_loss: 1.2302 - val_accuracy: 0.0140\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5567 - accuracy: 0.0154 - val_loss: 1.2797 - val_accuracy: 0.0161\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5349 - accuracy: 0.0164 - val_loss: 1.3168 - val_accuracy: 0.0181\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.6143 - accuracy: 0.0166 - val_loss: 1.2442 - val_accuracy: 0.0181\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5608 - accuracy: 0.0172 - val_loss: 1.2596 - val_accuracy: 0.0166\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5575 - accuracy: 0.0171 - val_loss: 1.2390 - val_accuracy: 0.0171\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5489 - accuracy: 0.0169 - val_loss: 1.2548 - val_accuracy: 0.0140\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5445 - accuracy: 0.0173 - val_loss: 1.2369 - val_accuracy: 0.0161\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5494 - accuracy: 0.0207 - val_loss: 1.2401 - val_accuracy: 0.0156\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5403 - accuracy: 0.0198 - val_loss: 1.3127 - val_accuracy: 0.0171\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5337 - accuracy: 0.0139 - val_loss: 1.3294 - val_accuracy: 0.0191\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5398 - accuracy: 0.0179 - val_loss: 1.2569 - val_accuracy: 0.0151\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5498 - accuracy: 0.0176 - val_loss: 1.2902 - val_accuracy: 0.0171\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5408 - accuracy: 0.0184 - val_loss: 1.2459 - val_accuracy: 0.0181\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5469 - accuracy: 0.0183 - val_loss: 1.2555 - val_accuracy: 0.0156\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5252 - accuracy: 0.0200 - val_loss: 1.2939 - val_accuracy: 0.0166\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5307 - accuracy: 0.0183 - val_loss: 1.2302 - val_accuracy: 0.0161\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5219 - accuracy: 0.0169 - val_loss: 1.3113 - val_accuracy: 0.0146\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5453 - accuracy: 0.0168 - val_loss: 1.2584 - val_accuracy: 0.0196\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5508 - accuracy: 0.0193 - val_loss: 1.2311 - val_accuracy: 0.0156\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 7s 23ms/step - loss: 7.3639 - accuracy: 0.0149 - val_loss: 1.5443 - val_accuracy: 0.0156\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 2.0090 - accuracy: 0.0174 - val_loss: 1.4748 - val_accuracy: 0.0156\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.9094 - accuracy: 0.0176 - val_loss: 1.3436 - val_accuracy: 0.0146\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.7304 - accuracy: 0.0171 - val_loss: 1.3273 - val_accuracy: 0.0166\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 5s 22ms/step - loss: 1.7744 - accuracy: 0.0151 - val_loss: 1.2653 - val_accuracy: 0.0136\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.6005 - accuracy: 0.0158 - val_loss: 1.2692 - val_accuracy: 0.0171\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.8290 - accuracy: 0.0162 - val_loss: 1.2518 - val_accuracy: 0.0171\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 5s 20ms/step - loss: 1.5872 - accuracy: 0.0148 - val_loss: 1.3777 - val_accuracy: 0.0141\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.6725 - accuracy: 0.0148 - val_loss: 1.2845 - val_accuracy: 0.0151\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5882 - accuracy: 0.0148 - val_loss: 1.2549 - val_accuracy: 0.0176\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.6595 - accuracy: 0.0137 - val_loss: 1.8377 - val_accuracy: 0.0166\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.6149 - accuracy: 0.0159 - val_loss: 1.2374 - val_accuracy: 0.0141\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5792 - accuracy: 0.0158 - val_loss: 1.2380 - val_accuracy: 0.0136\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5758 - accuracy: 0.0153 - val_loss: 1.3064 - val_accuracy: 0.0161\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5612 - accuracy: 0.0157 - val_loss: 1.2447 - val_accuracy: 0.0166\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5591 - accuracy: 0.0142 - val_loss: 1.2348 - val_accuracy: 0.0156\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5935 - accuracy: 0.0147 - val_loss: 1.5740 - val_accuracy: 0.0151\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5752 - accuracy: 0.0177 - val_loss: 1.2672 - val_accuracy: 0.0161\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5562 - accuracy: 0.0164 - val_loss: 1.2427 - val_accuracy: 0.0156\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5526 - accuracy: 0.0172 - val_loss: 1.2839 - val_accuracy: 0.0166\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5579 - accuracy: 0.0167 - val_loss: 1.2613 - val_accuracy: 0.0156\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5819 - accuracy: 0.0169 - val_loss: 1.5858 - val_accuracy: 0.0161\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5598 - accuracy: 0.0162 - val_loss: 1.2533 - val_accuracy: 0.0136\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 5s 22ms/step - loss: 1.5409 - accuracy: 0.0134 - val_loss: 1.2668 - val_accuracy: 0.0166\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5412 - accuracy: 0.0174 - val_loss: 1.2703 - val_accuracy: 0.0141\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5416 - accuracy: 0.0172 - val_loss: 1.3740 - val_accuracy: 0.0171\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5936 - accuracy: 0.0163 - val_loss: 1.2548 - val_accuracy: 0.0166\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5350 - accuracy: 0.0156 - val_loss: 1.2946 - val_accuracy: 0.0141\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5518 - accuracy: 0.0147 - val_loss: 1.2611 - val_accuracy: 0.0161\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 5s 22ms/step - loss: 1.5386 - accuracy: 0.0195 - val_loss: 1.2841 - val_accuracy: 0.0156\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5415 - accuracy: 0.0164 - val_loss: 1.2399 - val_accuracy: 0.0146\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5824 - accuracy: 0.0154 - val_loss: 1.2369 - val_accuracy: 0.0176\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5554 - accuracy: 0.0131 - val_loss: 1.2732 - val_accuracy: 0.0161\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5614 - accuracy: 0.0149 - val_loss: 1.2327 - val_accuracy: 0.0156\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5352 - accuracy: 0.0171 - val_loss: 1.3418 - val_accuracy: 0.0161\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5318 - accuracy: 0.0151 - val_loss: 1.2953 - val_accuracy: 0.0181\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5454 - accuracy: 0.0173 - val_loss: 1.2333 - val_accuracy: 0.0171\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5658 - accuracy: 0.0148 - val_loss: 1.2943 - val_accuracy: 0.0161\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5474 - accuracy: 0.0169 - val_loss: 1.2899 - val_accuracy: 0.0156\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5362 - accuracy: 0.0151 - val_loss: 1.2239 - val_accuracy: 0.0151\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5353 - accuracy: 0.0148 - val_loss: 1.3746 - val_accuracy: 0.0136\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5430 - accuracy: 0.0144 - val_loss: 1.2284 - val_accuracy: 0.0161\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5362 - accuracy: 0.0157 - val_loss: 1.2228 - val_accuracy: 0.0161\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5252 - accuracy: 0.0173 - val_loss: 1.3224 - val_accuracy: 0.0146\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5301 - accuracy: 0.0141 - val_loss: 1.2264 - val_accuracy: 0.0161\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5215 - accuracy: 0.0158 - val_loss: 1.2344 - val_accuracy: 0.0136\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5306 - accuracy: 0.0157 - val_loss: 1.2645 - val_accuracy: 0.0161\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5843 - accuracy: 0.0141 - val_loss: 1.2261 - val_accuracy: 0.0156\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5363 - accuracy: 0.0163 - val_loss: 1.2250 - val_accuracy: 0.0151\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 5s 21ms/step - loss: 1.5364 - accuracy: 0.0152 - val_loss: 1.5105 - val_accuracy: 0.0166\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 10s 28ms/step - loss: 8.5679 - accuracy: 0.0161 - val_loss: 3.6662 - val_accuracy: 0.0161\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.9192 - accuracy: 0.0167 - val_loss: 1.6656 - val_accuracy: 0.0151\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.7714 - accuracy: 0.0137 - val_loss: 1.3111 - val_accuracy: 0.0161\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.7736 - accuracy: 0.0156 - val_loss: 1.2576 - val_accuracy: 0.0166\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.8663 - accuracy: 0.0131 - val_loss: 1.5319 - val_accuracy: 0.0115\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.6032 - accuracy: 0.0161 - val_loss: 1.3839 - val_accuracy: 0.0161\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5974 - accuracy: 0.0173 - val_loss: 1.4366 - val_accuracy: 0.0146\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.7141 - accuracy: 0.0134 - val_loss: 1.2421 - val_accuracy: 0.0156\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.5765 - accuracy: 0.0167 - val_loss: 1.3346 - val_accuracy: 0.0156\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5867 - accuracy: 0.0167 - val_loss: 1.3226 - val_accuracy: 0.0141\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5805 - accuracy: 0.0161 - val_loss: 1.3948 - val_accuracy: 0.0151\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5776 - accuracy: 0.0168 - val_loss: 1.2340 - val_accuracy: 0.0166\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6411 - accuracy: 0.0181 - val_loss: 1.9957 - val_accuracy: 0.0181\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.7081 - accuracy: 0.0147 - val_loss: 1.3657 - val_accuracy: 0.0126\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6095 - accuracy: 0.0159 - val_loss: 1.2679 - val_accuracy: 0.0146\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5739 - accuracy: 0.0144 - val_loss: 1.2634 - val_accuracy: 0.0166\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5491 - accuracy: 0.0148 - val_loss: 1.3075 - val_accuracy: 0.0166\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.5386 - accuracy: 0.0171 - val_loss: 1.3053 - val_accuracy: 0.0156\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5705 - accuracy: 0.0164 - val_loss: 1.3954 - val_accuracy: 0.0186\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.5757 - accuracy: 0.0185 - val_loss: 1.5141 - val_accuracy: 0.0141\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.5753 - accuracy: 0.0142 - val_loss: 1.4644 - val_accuracy: 0.0176\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5804 - accuracy: 0.0146 - val_loss: 1.6428 - val_accuracy: 0.0161\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5691 - accuracy: 0.0164 - val_loss: 1.2549 - val_accuracy: 0.0161\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5788 - accuracy: 0.0178 - val_loss: 1.3604 - val_accuracy: 0.0151\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5606 - accuracy: 0.0216 - val_loss: 1.2754 - val_accuracy: 0.0136\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5593 - accuracy: 0.0186 - val_loss: 1.2327 - val_accuracy: 0.0161\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5325 - accuracy: 0.0172 - val_loss: 1.2613 - val_accuracy: 0.0166\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.7050 - accuracy: 0.0177 - val_loss: 1.3305 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5568 - accuracy: 0.0156 - val_loss: 1.2422 - val_accuracy: 0.0186\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.5375 - accuracy: 0.0166 - val_loss: 1.4471 - val_accuracy: 0.0156\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5613 - accuracy: 0.0173 - val_loss: 1.2937 - val_accuracy: 0.0191\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5314 - accuracy: 0.0154 - val_loss: 1.2406 - val_accuracy: 0.0166\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5439 - accuracy: 0.0173 - val_loss: 1.3417 - val_accuracy: 0.0201\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5387 - accuracy: 0.0174 - val_loss: 1.3531 - val_accuracy: 0.0151\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5794 - accuracy: 0.0181 - val_loss: 1.2418 - val_accuracy: 0.0181\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.5297 - accuracy: 0.0166 - val_loss: 1.4016 - val_accuracy: 0.0141\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5406 - accuracy: 0.0191 - val_loss: 1.4596 - val_accuracy: 0.0136\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5423 - accuracy: 0.0176 - val_loss: 1.2638 - val_accuracy: 0.0141\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5270 - accuracy: 0.0153 - val_loss: 1.2339 - val_accuracy: 0.0176\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5446 - accuracy: 0.0172 - val_loss: 1.2433 - val_accuracy: 0.0156\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.5243 - accuracy: 0.0178 - val_loss: 1.2485 - val_accuracy: 0.0156\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5301 - accuracy: 0.0146 - val_loss: 1.2328 - val_accuracy: 0.0151\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5271 - accuracy: 0.0167 - val_loss: 1.4270 - val_accuracy: 0.0151\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.5297 - accuracy: 0.0179 - val_loss: 1.2757 - val_accuracy: 0.0161\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5533 - accuracy: 0.0172 - val_loss: 1.2605 - val_accuracy: 0.0186\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5219 - accuracy: 0.0191 - val_loss: 1.2507 - val_accuracy: 0.0171\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5191 - accuracy: 0.0163 - val_loss: 1.2290 - val_accuracy: 0.0211\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5435 - accuracy: 0.0157 - val_loss: 1.3243 - val_accuracy: 0.0176\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5285 - accuracy: 0.0161 - val_loss: 1.2356 - val_accuracy: 0.0191\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.5089 - accuracy: 0.0163 - val_loss: 1.2269 - val_accuracy: 0.0196\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 9s 28ms/step - loss: 17.1455 - accuracy: 0.0162 - val_loss: 1.4514 - val_accuracy: 0.0156\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 2.1678 - accuracy: 0.0149 - val_loss: 1.7331 - val_accuracy: 0.0161\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.8275 - accuracy: 0.0166 - val_loss: 1.3452 - val_accuracy: 0.0136\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.7598 - accuracy: 0.0139 - val_loss: 1.5001 - val_accuracy: 0.0161\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 6s 24ms/step - loss: 1.8266 - accuracy: 0.0129 - val_loss: 1.9678 - val_accuracy: 0.0196\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.7261 - accuracy: 0.0154 - val_loss: 1.4168 - val_accuracy: 0.0181\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.7162 - accuracy: 0.0156 - val_loss: 1.3043 - val_accuracy: 0.0156\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.6441 - accuracy: 0.0166 - val_loss: 1.4388 - val_accuracy: 0.0166\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6319 - accuracy: 0.0164 - val_loss: 1.4525 - val_accuracy: 0.0171\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.6019 - accuracy: 0.0149 - val_loss: 1.2874 - val_accuracy: 0.0166\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.6309 - accuracy: 0.0188 - val_loss: 1.2641 - val_accuracy: 0.0146\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6489 - accuracy: 0.0169 - val_loss: 1.6605 - val_accuracy: 0.0141\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6089 - accuracy: 0.0171 - val_loss: 1.7480 - val_accuracy: 0.0161\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6707 - accuracy: 0.0163 - val_loss: 1.2371 - val_accuracy: 0.0181\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5971 - accuracy: 0.0156 - val_loss: 1.3683 - val_accuracy: 0.0171\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.6099 - accuracy: 0.0131 - val_loss: 1.7567 - val_accuracy: 0.0166\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6037 - accuracy: 0.0156 - val_loss: 1.2484 - val_accuracy: 0.0166\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.6237 - accuracy: 0.0163 - val_loss: 1.8870 - val_accuracy: 0.0186\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.6742 - accuracy: 0.0162 - val_loss: 1.2747 - val_accuracy: 0.0186\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.6318 - accuracy: 0.0167 - val_loss: 1.2261 - val_accuracy: 0.0161\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.6086 - accuracy: 0.0163 - val_loss: 1.2972 - val_accuracy: 0.0181\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5589 - accuracy: 0.0157 - val_loss: 1.3674 - val_accuracy: 0.0136\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.6155 - accuracy: 0.0134 - val_loss: 1.2570 - val_accuracy: 0.0136\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5743 - accuracy: 0.0148 - val_loss: 1.3544 - val_accuracy: 0.0166\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5782 - accuracy: 0.0157 - val_loss: 1.2828 - val_accuracy: 0.0151\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5813 - accuracy: 0.0172 - val_loss: 1.3181 - val_accuracy: 0.0146\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.5722 - accuracy: 0.0177 - val_loss: 1.2621 - val_accuracy: 0.0151\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5788 - accuracy: 0.0168 - val_loss: 1.2375 - val_accuracy: 0.0146\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.5595 - accuracy: 0.0159 - val_loss: 1.2930 - val_accuracy: 0.0166\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5328 - accuracy: 0.0144 - val_loss: 1.2508 - val_accuracy: 0.0171\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5542 - accuracy: 0.0161 - val_loss: 1.3075 - val_accuracy: 0.0166\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5491 - accuracy: 0.0144 - val_loss: 1.3753 - val_accuracy: 0.0156\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5337 - accuracy: 0.0159 - val_loss: 1.2523 - val_accuracy: 0.0161\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5438 - accuracy: 0.0157 - val_loss: 1.2214 - val_accuracy: 0.0141\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5606 - accuracy: 0.0131 - val_loss: 1.2381 - val_accuracy: 0.0141\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5848 - accuracy: 0.0159 - val_loss: 1.2945 - val_accuracy: 0.0171\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5298 - accuracy: 0.0178 - val_loss: 1.2447 - val_accuracy: 0.0176\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5669 - accuracy: 0.0181 - val_loss: 1.2487 - val_accuracy: 0.0171\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.5533 - accuracy: 0.0144 - val_loss: 1.2186 - val_accuracy: 0.0146\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5281 - accuracy: 0.0183 - val_loss: 1.2225 - val_accuracy: 0.0131\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5166 - accuracy: 0.0181 - val_loss: 1.2845 - val_accuracy: 0.0161\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5477 - accuracy: 0.0157 - val_loss: 1.2507 - val_accuracy: 0.0156\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5480 - accuracy: 0.0152 - val_loss: 1.2373 - val_accuracy: 0.0136\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5448 - accuracy: 0.0161 - val_loss: 1.2214 - val_accuracy: 0.0176\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5387 - accuracy: 0.0207 - val_loss: 1.3328 - val_accuracy: 0.0141\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5251 - accuracy: 0.0166 - val_loss: 1.2263 - val_accuracy: 0.0156\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5309 - accuracy: 0.0156 - val_loss: 1.2773 - val_accuracy: 0.0181\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 6s 25ms/step - loss: 1.5232 - accuracy: 0.0173 - val_loss: 1.2159 - val_accuracy: 0.0151\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5251 - accuracy: 0.0152 - val_loss: 1.2409 - val_accuracy: 0.0156\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.5266 - accuracy: 0.0182 - val_loss: 1.2356 - val_accuracy: 0.0166\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 9s 27ms/step - loss: 6.6962 - accuracy: 0.0181 - val_loss: 1.3604 - val_accuracy: 0.0151\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.7673 - accuracy: 0.0162 - val_loss: 1.8091 - val_accuracy: 0.0136\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.9274 - accuracy: 0.0154 - val_loss: 1.2746 - val_accuracy: 0.0120\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.6223 - accuracy: 0.0148 - val_loss: 1.3821 - val_accuracy: 0.0136\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.7063 - accuracy: 0.0154 - val_loss: 1.4224 - val_accuracy: 0.0166\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.6286 - accuracy: 0.0154 - val_loss: 1.2940 - val_accuracy: 0.0166\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6492 - accuracy: 0.0151 - val_loss: 1.2686 - val_accuracy: 0.0141\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6639 - accuracy: 0.0136 - val_loss: 3.1223 - val_accuracy: 0.0131\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.7421 - accuracy: 0.0158 - val_loss: 1.3837 - val_accuracy: 0.0166\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.6237 - accuracy: 0.0138 - val_loss: 1.2850 - val_accuracy: 0.0141\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.6121 - accuracy: 0.0185 - val_loss: 1.4898 - val_accuracy: 0.0156\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5749 - accuracy: 0.0161 - val_loss: 1.3337 - val_accuracy: 0.0141\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.6673 - accuracy: 0.0163 - val_loss: 1.2555 - val_accuracy: 0.0181\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5768 - accuracy: 0.0148 - val_loss: 1.3330 - val_accuracy: 0.0166\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5747 - accuracy: 0.0153 - val_loss: 1.2625 - val_accuracy: 0.0156\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.6518 - accuracy: 0.0136 - val_loss: 1.5844 - val_accuracy: 0.0156\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.6960 - accuracy: 0.0157 - val_loss: 2.0123 - val_accuracy: 0.0166\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.6045 - accuracy: 0.0163 - val_loss: 1.2970 - val_accuracy: 0.0161\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.5704 - accuracy: 0.0172 - val_loss: 1.2626 - val_accuracy: 0.0141\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5740 - accuracy: 0.0153 - val_loss: 1.4513 - val_accuracy: 0.0166\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5877 - accuracy: 0.0127 - val_loss: 1.2712 - val_accuracy: 0.0156\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.6302 - accuracy: 0.0154 - val_loss: 1.3884 - val_accuracy: 0.0166\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5654 - accuracy: 0.0167 - val_loss: 1.3379 - val_accuracy: 0.0136\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5377 - accuracy: 0.0152 - val_loss: 1.2509 - val_accuracy: 0.0141\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5364 - accuracy: 0.0147 - val_loss: 1.2402 - val_accuracy: 0.0166\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.5243 - accuracy: 0.0169 - val_loss: 1.2418 - val_accuracy: 0.0186\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.7134 - accuracy: 0.0152 - val_loss: 1.6134 - val_accuracy: 0.0171\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.8031 - accuracy: 0.0176 - val_loss: 1.4025 - val_accuracy: 0.0166\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5854 - accuracy: 0.0158 - val_loss: 1.2912 - val_accuracy: 0.0171\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.5581 - accuracy: 0.0152 - val_loss: 1.3028 - val_accuracy: 0.0171\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.6013 - accuracy: 0.0154 - val_loss: 1.3288 - val_accuracy: 0.0161\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.5742 - accuracy: 0.0171 - val_loss: 1.2833 - val_accuracy: 0.0161\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.5505 - accuracy: 0.0143 - val_loss: 1.4014 - val_accuracy: 0.0156\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5773 - accuracy: 0.0158 - val_loss: 1.3073 - val_accuracy: 0.0136\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5709 - accuracy: 0.0167 - val_loss: 1.2264 - val_accuracy: 0.0156\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5432 - accuracy: 0.0154 - val_loss: 1.3156 - val_accuracy: 0.0161\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5598 - accuracy: 0.0177 - val_loss: 1.2653 - val_accuracy: 0.0186\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5365 - accuracy: 0.0173 - val_loss: 1.2525 - val_accuracy: 0.0166\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 6s 26ms/step - loss: 1.5475 - accuracy: 0.0156 - val_loss: 1.2590 - val_accuracy: 0.0161\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5201 - accuracy: 0.0151 - val_loss: 1.2823 - val_accuracy: 0.0166\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5445 - accuracy: 0.0163 - val_loss: 1.4832 - val_accuracy: 0.0191\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.5318 - accuracy: 0.0153 - val_loss: 1.2323 - val_accuracy: 0.0131\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5333 - accuracy: 0.0132 - val_loss: 1.2331 - val_accuracy: 0.0166\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 1.5590 - accuracy: 0.0164 - val_loss: 1.2507 - val_accuracy: 0.0151\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.5366 - accuracy: 0.0153 - val_loss: 1.3424 - val_accuracy: 0.0171\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5177 - accuracy: 0.0166 - val_loss: 1.3442 - val_accuracy: 0.0186\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5230 - accuracy: 0.0162 - val_loss: 1.2368 - val_accuracy: 0.0171\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.5316 - accuracy: 0.0161 - val_loss: 1.3000 - val_accuracy: 0.0166\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.5509 - accuracy: 0.0157 - val_loss: 1.2845 - val_accuracy: 0.0171\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 7s 26ms/step - loss: 1.5387 - accuracy: 0.0154 - val_loss: 1.2320 - val_accuracy: 0.0161\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 10s 29ms/step - loss: 7.5827 - accuracy: 0.0178 - val_loss: 2.3990 - val_accuracy: 0.0156\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.7941 - accuracy: 0.0156 - val_loss: 1.2630 - val_accuracy: 0.0166\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.7835 - accuracy: 0.0149 - val_loss: 1.4101 - val_accuracy: 0.0156\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.7853 - accuracy: 0.0154 - val_loss: 1.2415 - val_accuracy: 0.0156\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.6619 - accuracy: 0.0157 - val_loss: 1.5436 - val_accuracy: 0.0171\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.7435 - accuracy: 0.0168 - val_loss: 3.1013 - val_accuracy: 0.0176\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.7347 - accuracy: 0.0176 - val_loss: 1.8846 - val_accuracy: 0.0136\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.6882 - accuracy: 0.0141 - val_loss: 1.3438 - val_accuracy: 0.0146\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.6197 - accuracy: 0.0137 - val_loss: 1.2505 - val_accuracy: 0.0161\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.6424 - accuracy: 0.0152 - val_loss: 1.3736 - val_accuracy: 0.0156\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5750 - accuracy: 0.0157 - val_loss: 1.2632 - val_accuracy: 0.0161\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6268 - accuracy: 0.0163 - val_loss: 1.3623 - val_accuracy: 0.0146\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 46.9354 - accuracy: 0.0158 - val_loss: 44.8888 - val_accuracy: 0.0131\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 70.6202 - accuracy: 0.0129 - val_loss: 22.8823 - val_accuracy: 0.0126\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 18.6756 - accuracy: 0.0154 - val_loss: 24.0915 - val_accuracy: 0.0171\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 25.2948 - accuracy: 0.0141 - val_loss: 20.3264 - val_accuracy: 0.0166\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 25.9468 - accuracy: 0.0159 - val_loss: 19.2180 - val_accuracy: 0.0141\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 24.3035 - accuracy: 0.0146 - val_loss: 25.3079 - val_accuracy: 0.0136\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 22.1081 - accuracy: 0.0154 - val_loss: 18.3067 - val_accuracy: 0.0181\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 18.8222 - accuracy: 0.0129 - val_loss: 15.5318 - val_accuracy: 0.0171\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 13.7020 - accuracy: 0.0154 - val_loss: 14.5070 - val_accuracy: 0.0156\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 15.3610 - accuracy: 0.0166 - val_loss: 12.0866 - val_accuracy: 0.0126\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 11.7148 - accuracy: 0.0172 - val_loss: 10.7069 - val_accuracy: 0.0146\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 9.3974 - accuracy: 0.0161 - val_loss: 7.3639 - val_accuracy: 0.0166\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 7.5984 - accuracy: 0.0171 - val_loss: 6.6079 - val_accuracy: 0.0186\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 6.7440 - accuracy: 0.0159 - val_loss: 5.0373 - val_accuracy: 0.0156\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 6.4504 - accuracy: 0.0158 - val_loss: 5.1503 - val_accuracy: 0.0166\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 5.7261 - accuracy: 0.0148 - val_loss: 4.7282 - val_accuracy: 0.0141\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 5.4262 - accuracy: 0.0144 - val_loss: 5.3948 - val_accuracy: 0.0201\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 4.9298 - accuracy: 0.0142 - val_loss: 3.3302 - val_accuracy: 0.0131\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 4.2310 - accuracy: 0.0158 - val_loss: 3.9500 - val_accuracy: 0.0126\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 3.7133 - accuracy: 0.0175 - val_loss: 3.3778 - val_accuracy: 0.0156\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 4.0073 - accuracy: 0.0161 - val_loss: 4.1260 - val_accuracy: 0.0196\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 4.2093 - accuracy: 0.0175 - val_loss: 3.8453 - val_accuracy: 0.0141\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 8.1686 - accuracy: 0.0146 - val_loss: 6.1571 - val_accuracy: 0.0156\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 7.7963 - accuracy: 0.0146 - val_loss: 4.5171 - val_accuracy: 0.0146\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 5.7036 - accuracy: 0.0171 - val_loss: 4.5049 - val_accuracy: 0.0136\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 4.7079 - accuracy: 0.0146 - val_loss: 3.3694 - val_accuracy: 0.0146\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 25.1727 - accuracy: 0.0148 - val_loss: 15.7785 - val_accuracy: 0.0171\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 13.2054 - accuracy: 0.0138 - val_loss: 4.2692 - val_accuracy: 0.0171\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 4.6733 - accuracy: 0.0134 - val_loss: 3.0388 - val_accuracy: 0.0161\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 7s 27ms/step - loss: 3.9881 - accuracy: 0.0148 - val_loss: 2.7343 - val_accuracy: 0.0141\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 3.4090 - accuracy: 0.0123 - val_loss: 2.3578 - val_accuracy: 0.0151\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 2.8313 - accuracy: 0.0144 - val_loss: 1.9043 - val_accuracy: 0.0146\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 2.4378 - accuracy: 0.0141 - val_loss: 1.6668 - val_accuracy: 0.0171\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 2.1771 - accuracy: 0.0156 - val_loss: 1.7016 - val_accuracy: 0.0156\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 2.0343 - accuracy: 0.0144 - val_loss: 1.4770 - val_accuracy: 0.0126\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 1.9628 - accuracy: 0.0148 - val_loss: 1.4440 - val_accuracy: 0.0131\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.9449 - accuracy: 0.0159 - val_loss: 1.4043 - val_accuracy: 0.0191\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 2.0010 - accuracy: 0.0158 - val_loss: 1.4658 - val_accuracy: 0.0131\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 11s 32ms/step - loss: 14.2305 - accuracy: 0.0163 - val_loss: 1.3899 - val_accuracy: 0.0161\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 2.1057 - accuracy: 0.0161 - val_loss: 1.8121 - val_accuracy: 0.0151\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.8542 - accuracy: 0.0158 - val_loss: 1.2779 - val_accuracy: 0.0151\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.8044 - accuracy: 0.0127 - val_loss: 1.3281 - val_accuracy: 0.0181\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6740 - accuracy: 0.0138 - val_loss: 1.2848 - val_accuracy: 0.0151\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.6553 - accuracy: 0.0159 - val_loss: 1.3059 - val_accuracy: 0.0176\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.6511 - accuracy: 0.0164 - val_loss: 1.3947 - val_accuracy: 0.0156\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.6596 - accuracy: 0.0162 - val_loss: 1.3216 - val_accuracy: 0.0166\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.6523 - accuracy: 0.0178 - val_loss: 1.2612 - val_accuracy: 0.0136\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6015 - accuracy: 0.0144 - val_loss: 1.3386 - val_accuracy: 0.0176\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.8517 - accuracy: 0.0139 - val_loss: 1.3470 - val_accuracy: 0.0156\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5902 - accuracy: 0.0164 - val_loss: 1.2658 - val_accuracy: 0.0141\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5724 - accuracy: 0.0149 - val_loss: 1.2626 - val_accuracy: 0.0161\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5881 - accuracy: 0.0172 - val_loss: 1.2599 - val_accuracy: 0.0166\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5896 - accuracy: 0.0147 - val_loss: 1.2415 - val_accuracy: 0.0166\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.6534 - accuracy: 0.0136 - val_loss: 1.4106 - val_accuracy: 0.0161\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6169 - accuracy: 0.0161 - val_loss: 1.2675 - val_accuracy: 0.0136\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5752 - accuracy: 0.0144 - val_loss: 1.2788 - val_accuracy: 0.0161\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.5819 - accuracy: 0.0123 - val_loss: 1.2737 - val_accuracy: 0.0166\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5625 - accuracy: 0.0152 - val_loss: 1.2977 - val_accuracy: 0.0151\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5863 - accuracy: 0.0127 - val_loss: 1.3496 - val_accuracy: 0.0161\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.5700 - accuracy: 0.0143 - val_loss: 1.2390 - val_accuracy: 0.0156\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5735 - accuracy: 0.0167 - val_loss: 1.2618 - val_accuracy: 0.0156\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5521 - accuracy: 0.0197 - val_loss: 1.2708 - val_accuracy: 0.0186\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5599 - accuracy: 0.0157 - val_loss: 1.2392 - val_accuracy: 0.0166\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5455 - accuracy: 0.0142 - val_loss: 1.2367 - val_accuracy: 0.0161\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5392 - accuracy: 0.0147 - val_loss: 1.4205 - val_accuracy: 0.0171\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5481 - accuracy: 0.0148 - val_loss: 1.2814 - val_accuracy: 0.0146\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5401 - accuracy: 0.0143 - val_loss: 1.2296 - val_accuracy: 0.0141\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5369 - accuracy: 0.0127 - val_loss: 1.2499 - val_accuracy: 0.0156\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5438 - accuracy: 0.0143 - val_loss: 1.2645 - val_accuracy: 0.0171\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5490 - accuracy: 0.0142 - val_loss: 1.2426 - val_accuracy: 0.0166\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5314 - accuracy: 0.0157 - val_loss: 1.2687 - val_accuracy: 0.0196\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5474 - accuracy: 0.0166 - val_loss: 1.2782 - val_accuracy: 0.0151\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5452 - accuracy: 0.0128 - val_loss: 1.2405 - val_accuracy: 0.0136\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5274 - accuracy: 0.0146 - val_loss: 1.2280 - val_accuracy: 0.0156\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5356 - accuracy: 0.0143 - val_loss: 1.2183 - val_accuracy: 0.0166\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5266 - accuracy: 0.0180 - val_loss: 1.2678 - val_accuracy: 0.0141\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5261 - accuracy: 0.0143 - val_loss: 1.3372 - val_accuracy: 0.0171\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5233 - accuracy: 0.0138 - val_loss: 1.2853 - val_accuracy: 0.0126\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.7046 - accuracy: 0.0137 - val_loss: 1.2486 - val_accuracy: 0.0161\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5511 - accuracy: 0.0134 - val_loss: 1.3648 - val_accuracy: 0.0171\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5244 - accuracy: 0.0143 - val_loss: 1.2258 - val_accuracy: 0.0136\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5213 - accuracy: 0.0156 - val_loss: 1.2670 - val_accuracy: 0.0166\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5231 - accuracy: 0.0133 - val_loss: 1.2843 - val_accuracy: 0.0141\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5985 - accuracy: 0.0166 - val_loss: 1.2352 - val_accuracy: 0.0186\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5335 - accuracy: 0.0129 - val_loss: 1.2956 - val_accuracy: 0.0156\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5333 - accuracy: 0.0172 - val_loss: 1.2245 - val_accuracy: 0.0161\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5193 - accuracy: 0.0137 - val_loss: 1.2212 - val_accuracy: 0.0136\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5202 - accuracy: 0.0139 - val_loss: 1.2459 - val_accuracy: 0.0141\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 11s 34ms/step - loss: 7.3043 - accuracy: 0.0154 - val_loss: 1.3786 - val_accuracy: 0.0151\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 2.6884 - accuracy: 0.0153 - val_loss: 1.5313 - val_accuracy: 0.0141\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.8458 - accuracy: 0.0165 - val_loss: 1.2850 - val_accuracy: 0.0181\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.7037 - accuracy: 0.0162 - val_loss: 2.6267 - val_accuracy: 0.0146\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.7462 - accuracy: 0.0154 - val_loss: 1.2754 - val_accuracy: 0.0156\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.7423 - accuracy: 0.0128 - val_loss: 1.2945 - val_accuracy: 0.0181\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.7347 - accuracy: 0.0139 - val_loss: 1.3892 - val_accuracy: 0.0151\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6802 - accuracy: 0.0157 - val_loss: 1.4453 - val_accuracy: 0.0156\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.7309 - accuracy: 0.0176 - val_loss: 1.4694 - val_accuracy: 0.0156\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 9s 34ms/step - loss: 1.6250 - accuracy: 0.0180 - val_loss: 1.4329 - val_accuracy: 0.0151\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5746 - accuracy: 0.0186 - val_loss: 1.4906 - val_accuracy: 0.0166\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.6182 - accuracy: 0.0168 - val_loss: 1.3592 - val_accuracy: 0.0191\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5593 - accuracy: 0.0168 - val_loss: 1.2546 - val_accuracy: 0.0191\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.6582 - accuracy: 0.0152 - val_loss: 1.2532 - val_accuracy: 0.0166\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5944 - accuracy: 0.0151 - val_loss: 1.2811 - val_accuracy: 0.0186\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.6242 - accuracy: 0.0161 - val_loss: 1.2423 - val_accuracy: 0.0136\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5662 - accuracy: 0.0186 - val_loss: 1.2549 - val_accuracy: 0.0166\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5534 - accuracy: 0.0166 - val_loss: 1.4689 - val_accuracy: 0.0151\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.6191 - accuracy: 0.0180 - val_loss: 1.2437 - val_accuracy: 0.0146\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5653 - accuracy: 0.0144 - val_loss: 1.3458 - val_accuracy: 0.0176\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.5775 - accuracy: 0.0180 - val_loss: 1.2394 - val_accuracy: 0.0146\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5336 - accuracy: 0.0149 - val_loss: 1.2718 - val_accuracy: 0.0246\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5364 - accuracy: 0.0190 - val_loss: 1.2922 - val_accuracy: 0.0161\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5614 - accuracy: 0.0161 - val_loss: 1.3248 - val_accuracy: 0.0166\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5480 - accuracy: 0.0172 - val_loss: 1.3925 - val_accuracy: 0.0166\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5874 - accuracy: 0.0182 - val_loss: 1.3567 - val_accuracy: 0.0176\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5469 - accuracy: 0.0190 - val_loss: 1.2254 - val_accuracy: 0.0161\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6432 - accuracy: 0.0168 - val_loss: 1.2853 - val_accuracy: 0.0151\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.5400 - accuracy: 0.0139 - val_loss: 1.2828 - val_accuracy: 0.0146\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5250 - accuracy: 0.0186 - val_loss: 1.3469 - val_accuracy: 0.0166\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 9s 34ms/step - loss: 1.5671 - accuracy: 0.0163 - val_loss: 1.2509 - val_accuracy: 0.0146\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.5195 - accuracy: 0.0183 - val_loss: 1.2659 - val_accuracy: 0.0176\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5426 - accuracy: 0.0193 - val_loss: 1.2552 - val_accuracy: 0.0161\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5651 - accuracy: 0.0192 - val_loss: 1.3104 - val_accuracy: 0.0176\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5587 - accuracy: 0.0191 - val_loss: 1.2358 - val_accuracy: 0.0156\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5221 - accuracy: 0.0153 - val_loss: 1.2367 - val_accuracy: 0.0196\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5205 - accuracy: 0.0198 - val_loss: 1.4066 - val_accuracy: 0.0151\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 1.5316 - accuracy: 0.0172 - val_loss: 1.3697 - val_accuracy: 0.0131\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5192 - accuracy: 0.0187 - val_loss: 1.2340 - val_accuracy: 0.0191\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5209 - accuracy: 0.0187 - val_loss: 1.2513 - val_accuracy: 0.0201\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 1.5651 - accuracy: 0.0191 - val_loss: 1.2366 - val_accuracy: 0.0171\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 1.5681 - accuracy: 0.0175 - val_loss: 1.2934 - val_accuracy: 0.0151\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5404 - accuracy: 0.0185 - val_loss: 1.2586 - val_accuracy: 0.0201\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5493 - accuracy: 0.0192 - val_loss: 1.3620 - val_accuracy: 0.0161\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5268 - accuracy: 0.0197 - val_loss: 1.2294 - val_accuracy: 0.0136\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5255 - accuracy: 0.0212 - val_loss: 1.2487 - val_accuracy: 0.0166\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5068 - accuracy: 0.0190 - val_loss: 1.2972 - val_accuracy: 0.0206\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5112 - accuracy: 0.0187 - val_loss: 1.3698 - val_accuracy: 0.0176\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5279 - accuracy: 0.0216 - val_loss: 1.2404 - val_accuracy: 0.0196\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5134 - accuracy: 0.0202 - val_loss: 1.2498 - val_accuracy: 0.0181\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 11s 34ms/step - loss: 13.3749 - accuracy: 0.0181 - val_loss: 1.3989 - val_accuracy: 0.0141\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 2.0608 - accuracy: 0.0166 - val_loss: 1.2972 - val_accuracy: 0.0166\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.7619 - accuracy: 0.0168 - val_loss: 2.4586 - val_accuracy: 0.0131\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.7504 - accuracy: 0.0180 - val_loss: 1.8419 - val_accuracy: 0.0206\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 9s 34ms/step - loss: 1.6937 - accuracy: 0.0165 - val_loss: 1.5143 - val_accuracy: 0.0161\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.6707 - accuracy: 0.0144 - val_loss: 1.2513 - val_accuracy: 0.0161\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.7748 - accuracy: 0.0175 - val_loss: 1.5205 - val_accuracy: 0.0166\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.7612 - accuracy: 0.0156 - val_loss: 1.3680 - val_accuracy: 0.0171\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5844 - accuracy: 0.0148 - val_loss: 1.4733 - val_accuracy: 0.0161\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6414 - accuracy: 0.0173 - val_loss: 2.0411 - val_accuracy: 0.0136\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.6475 - accuracy: 0.0188 - val_loss: 1.2325 - val_accuracy: 0.0141\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.6106 - accuracy: 0.0167 - val_loss: 1.3276 - val_accuracy: 0.0166\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5793 - accuracy: 0.0152 - val_loss: 1.2385 - val_accuracy: 0.0171\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5742 - accuracy: 0.0170 - val_loss: 1.2432 - val_accuracy: 0.0171\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6553 - accuracy: 0.0142 - val_loss: 1.4578 - val_accuracy: 0.0161\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6215 - accuracy: 0.0156 - val_loss: 1.2944 - val_accuracy: 0.0151\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5506 - accuracy: 0.0152 - val_loss: 1.2979 - val_accuracy: 0.0161\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5723 - accuracy: 0.0183 - val_loss: 1.2848 - val_accuracy: 0.0166\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5691 - accuracy: 0.0138 - val_loss: 1.2697 - val_accuracy: 0.0206\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5882 - accuracy: 0.0175 - val_loss: 1.5377 - val_accuracy: 0.0171\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5472 - accuracy: 0.0158 - val_loss: 1.2411 - val_accuracy: 0.0186\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5426 - accuracy: 0.0158 - val_loss: 1.2393 - val_accuracy: 0.0171\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5401 - accuracy: 0.0177 - val_loss: 1.2322 - val_accuracy: 0.0151\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5662 - accuracy: 0.0121 - val_loss: 1.2348 - val_accuracy: 0.0141\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5470 - accuracy: 0.0166 - val_loss: 1.3355 - val_accuracy: 0.0161\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5605 - accuracy: 0.0149 - val_loss: 1.2806 - val_accuracy: 0.0171\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5349 - accuracy: 0.0166 - val_loss: 1.2568 - val_accuracy: 0.0156\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5289 - accuracy: 0.0163 - val_loss: 1.4894 - val_accuracy: 0.0161\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5425 - accuracy: 0.0154 - val_loss: 1.2954 - val_accuracy: 0.0141\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5696 - accuracy: 0.0156 - val_loss: 1.2692 - val_accuracy: 0.0156\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5272 - accuracy: 0.0182 - val_loss: 1.2306 - val_accuracy: 0.0156\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5258 - accuracy: 0.0167 - val_loss: 1.2572 - val_accuracy: 0.0151\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5502 - accuracy: 0.0151 - val_loss: 1.2348 - val_accuracy: 0.0171\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 1.5444 - accuracy: 0.0147 - val_loss: 1.2421 - val_accuracy: 0.0131\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5273 - accuracy: 0.0177 - val_loss: 1.2566 - val_accuracy: 0.0171\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5271 - accuracy: 0.0171 - val_loss: 1.3911 - val_accuracy: 0.0141\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.5279 - accuracy: 0.0152 - val_loss: 1.2466 - val_accuracy: 0.0181\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 9s 34ms/step - loss: 1.5362 - accuracy: 0.0178 - val_loss: 1.3714 - val_accuracy: 0.0161\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.5258 - accuracy: 0.0175 - val_loss: 1.2429 - val_accuracy: 0.0146\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5395 - accuracy: 0.0183 - val_loss: 1.2975 - val_accuracy: 0.0136\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.5205 - accuracy: 0.0163 - val_loss: 1.2352 - val_accuracy: 0.0191\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5172 - accuracy: 0.0176 - val_loss: 1.4333 - val_accuracy: 0.0146\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5269 - accuracy: 0.0180 - val_loss: 1.2610 - val_accuracy: 0.0156\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5161 - accuracy: 0.0161 - val_loss: 1.2273 - val_accuracy: 0.0136\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5308 - accuracy: 0.0190 - val_loss: 1.3275 - val_accuracy: 0.0161\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 1.6330 - accuracy: 0.0131 - val_loss: 1.2380 - val_accuracy: 0.0156\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5186 - accuracy: 0.0127 - val_loss: 1.3102 - val_accuracy: 0.0161\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.5279 - accuracy: 0.0148 - val_loss: 1.2235 - val_accuracy: 0.0156\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5225 - accuracy: 0.0166 - val_loss: 1.2409 - val_accuracy: 0.0161\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5177 - accuracy: 0.0131 - val_loss: 1.3244 - val_accuracy: 0.0136\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 12s 40ms/step - loss: 12.4679 - accuracy: 0.0152 - val_loss: 3.0587 - val_accuracy: 0.0141\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 3.0242 - accuracy: 0.0155 - val_loss: 1.5295 - val_accuracy: 0.0156\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 2.3350 - accuracy: 0.0138 - val_loss: 3.4174 - val_accuracy: 0.0156\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 2.2130 - accuracy: 0.0151 - val_loss: 1.9933 - val_accuracy: 0.0121\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 2.0272 - accuracy: 0.0156 - val_loss: 2.6094 - val_accuracy: 0.0131\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.9130 - accuracy: 0.0143 - val_loss: 1.9583 - val_accuracy: 0.0151\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.9520 - accuracy: 0.0146 - val_loss: 2.1137 - val_accuracy: 0.0161\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.7477 - accuracy: 0.0157 - val_loss: 1.5400 - val_accuracy: 0.0146\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.9165 - accuracy: 0.0161 - val_loss: 2.8249 - val_accuracy: 0.0136\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.7569 - accuracy: 0.0136 - val_loss: 1.4217 - val_accuracy: 0.0166\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6833 - accuracy: 0.0149 - val_loss: 1.5937 - val_accuracy: 0.0176\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.6342 - accuracy: 0.0176 - val_loss: 1.2983 - val_accuracy: 0.0151\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.6601 - accuracy: 0.0152 - val_loss: 1.4402 - val_accuracy: 0.0141\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.6201 - accuracy: 0.0167 - val_loss: 1.2520 - val_accuracy: 0.0166\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.6142 - accuracy: 0.0138 - val_loss: 1.3490 - val_accuracy: 0.0136\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.6005 - accuracy: 0.0134 - val_loss: 1.2366 - val_accuracy: 0.0151\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 9s 34ms/step - loss: 1.6004 - accuracy: 0.0168 - val_loss: 1.2232 - val_accuracy: 0.0141\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5746 - accuracy: 0.0163 - val_loss: 1.2609 - val_accuracy: 0.0156\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.5875 - accuracy: 0.0129 - val_loss: 1.2383 - val_accuracy: 0.0151\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.5599 - accuracy: 0.0152 - val_loss: 1.2405 - val_accuracy: 0.0156\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5750 - accuracy: 0.0161 - val_loss: 1.2323 - val_accuracy: 0.0206\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.5549 - accuracy: 0.0183 - val_loss: 1.3276 - val_accuracy: 0.0166\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5713 - accuracy: 0.0188 - val_loss: 1.2348 - val_accuracy: 0.0151\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.5561 - accuracy: 0.0162 - val_loss: 1.3378 - val_accuracy: 0.0161\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5909 - accuracy: 0.0161 - val_loss: 1.6429 - val_accuracy: 0.0146\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5552 - accuracy: 0.0141 - val_loss: 1.2731 - val_accuracy: 0.0141\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5431 - accuracy: 0.0173 - val_loss: 1.3724 - val_accuracy: 0.0161\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5452 - accuracy: 0.0163 - val_loss: 1.4565 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 9s 34ms/step - loss: 1.5518 - accuracy: 0.0160 - val_loss: 1.2585 - val_accuracy: 0.0146\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 9s 34ms/step - loss: 1.5414 - accuracy: 0.0146 - val_loss: 1.2607 - val_accuracy: 0.0141\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5393 - accuracy: 0.0147 - val_loss: 1.2848 - val_accuracy: 0.0191\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.6356 - accuracy: 0.0142 - val_loss: 1.2582 - val_accuracy: 0.0136\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5611 - accuracy: 0.0156 - val_loss: 1.2639 - val_accuracy: 0.0176\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5482 - accuracy: 0.0165 - val_loss: 1.2675 - val_accuracy: 0.0166\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5290 - accuracy: 0.0201 - val_loss: 1.2265 - val_accuracy: 0.0156\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5331 - accuracy: 0.0152 - val_loss: 1.2359 - val_accuracy: 0.0191\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5250 - accuracy: 0.0173 - val_loss: 1.2776 - val_accuracy: 0.0131\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5272 - accuracy: 0.0187 - val_loss: 1.2471 - val_accuracy: 0.0151\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5384 - accuracy: 0.0141 - val_loss: 1.2781 - val_accuracy: 0.0176\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5149 - accuracy: 0.0162 - val_loss: 1.2251 - val_accuracy: 0.0171\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5430 - accuracy: 0.0165 - val_loss: 1.2322 - val_accuracy: 0.0186\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5249 - accuracy: 0.0137 - val_loss: 1.2843 - val_accuracy: 0.0206\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5240 - accuracy: 0.0188 - val_loss: 1.4015 - val_accuracy: 0.0156\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5419 - accuracy: 0.0176 - val_loss: 1.2305 - val_accuracy: 0.0181\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 8s 34ms/step - loss: 1.5275 - accuracy: 0.0160 - val_loss: 1.2670 - val_accuracy: 0.0181\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5240 - accuracy: 0.0168 - val_loss: 1.2215 - val_accuracy: 0.0181\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5272 - accuracy: 0.0178 - val_loss: 1.2399 - val_accuracy: 0.0191\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5146 - accuracy: 0.0175 - val_loss: 1.2353 - val_accuracy: 0.0166\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 9s 34ms/step - loss: 1.5263 - accuracy: 0.0183 - val_loss: 1.3305 - val_accuracy: 0.0151\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 8s 33ms/step - loss: 1.5590 - accuracy: 0.0160 - val_loss: 1.3048 - val_accuracy: 0.0166\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 12s 39ms/step - loss: 10.5340 - accuracy: 0.0160 - val_loss: 8.5878 - val_accuracy: 0.0126\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 2.0161 - accuracy: 0.0161 - val_loss: 8.2687 - val_accuracy: 0.0161\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.8099 - accuracy: 0.0180 - val_loss: 8.2915 - val_accuracy: 0.0141\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.7860 - accuracy: 0.0162 - val_loss: 7.8987 - val_accuracy: 0.0126\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.6584 - accuracy: 0.0155 - val_loss: 7.1658 - val_accuracy: 0.0161\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.7309 - accuracy: 0.0162 - val_loss: 7.9726 - val_accuracy: 0.0156\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.6656 - accuracy: 0.0175 - val_loss: 6.7661 - val_accuracy: 0.0151\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.6777 - accuracy: 0.0151 - val_loss: 7.4586 - val_accuracy: 0.0191\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6305 - accuracy: 0.0142 - val_loss: 8.0126 - val_accuracy: 0.0136\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.6063 - accuracy: 0.0172 - val_loss: 8.0416 - val_accuracy: 0.0136\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.6073 - accuracy: 0.0162 - val_loss: 8.3946 - val_accuracy: 0.0156\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.6105 - accuracy: 0.0147 - val_loss: 8.0715 - val_accuracy: 0.0146\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5687 - accuracy: 0.0177 - val_loss: 8.0866 - val_accuracy: 0.0201\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5826 - accuracy: 0.0152 - val_loss: 9.2122 - val_accuracy: 0.0136\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6042 - accuracy: 0.0155 - val_loss: 8.8398 - val_accuracy: 0.0156\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6092 - accuracy: 0.0163 - val_loss: 8.0934 - val_accuracy: 0.0136\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5755 - accuracy: 0.0144 - val_loss: 8.8600 - val_accuracy: 0.0156\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5725 - accuracy: 0.0157 - val_loss: 7.9895 - val_accuracy: 0.0141\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5610 - accuracy: 0.0134 - val_loss: 8.5694 - val_accuracy: 0.0151\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5878 - accuracy: 0.0176 - val_loss: 8.3314 - val_accuracy: 0.0136\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.6074 - accuracy: 0.0191 - val_loss: 7.5291 - val_accuracy: 0.0136\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.8128 - accuracy: 0.0163 - val_loss: 7.8554 - val_accuracy: 0.0141\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.7629 - accuracy: 0.0156 - val_loss: 7.7861 - val_accuracy: 0.0161\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6367 - accuracy: 0.0168 - val_loss: 7.9994 - val_accuracy: 0.0146\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.6172 - accuracy: 0.0157 - val_loss: 7.3401 - val_accuracy: 0.0181\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5664 - accuracy: 0.0152 - val_loss: 8.0984 - val_accuracy: 0.0141\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6119 - accuracy: 0.0156 - val_loss: 7.9206 - val_accuracy: 0.0176\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5698 - accuracy: 0.0172 - val_loss: 8.1583 - val_accuracy: 0.0141\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5843 - accuracy: 0.0137 - val_loss: 8.1520 - val_accuracy: 0.0176\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5364 - accuracy: 0.0147 - val_loss: 8.1745 - val_accuracy: 0.0141\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5460 - accuracy: 0.0149 - val_loss: 7.8689 - val_accuracy: 0.0156\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5419 - accuracy: 0.0152 - val_loss: 7.6733 - val_accuracy: 0.0166\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5570 - accuracy: 0.0160 - val_loss: 7.9999 - val_accuracy: 0.0156\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5477 - accuracy: 0.0151 - val_loss: 8.3173 - val_accuracy: 0.0141\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5526 - accuracy: 0.0149 - val_loss: 7.2265 - val_accuracy: 0.0166\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5489 - accuracy: 0.0153 - val_loss: 7.3241 - val_accuracy: 0.0166\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5656 - accuracy: 0.0153 - val_loss: 7.6912 - val_accuracy: 0.0156\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5348 - accuracy: 0.0153 - val_loss: 7.4779 - val_accuracy: 0.0156\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5612 - accuracy: 0.0181 - val_loss: 8.3832 - val_accuracy: 0.0156\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6062 - accuracy: 0.0146 - val_loss: 7.3620 - val_accuracy: 0.0141\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5502 - accuracy: 0.0136 - val_loss: 7.9620 - val_accuracy: 0.0141\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5479 - accuracy: 0.0165 - val_loss: 7.5008 - val_accuracy: 0.0146\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5339 - accuracy: 0.0161 - val_loss: 7.4473 - val_accuracy: 0.0156\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5412 - accuracy: 0.0172 - val_loss: 7.3838 - val_accuracy: 0.0161\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5526 - accuracy: 0.0156 - val_loss: 7.6190 - val_accuracy: 0.0151\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5422 - accuracy: 0.0168 - val_loss: 7.9711 - val_accuracy: 0.0176\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5331 - accuracy: 0.0148 - val_loss: 7.2361 - val_accuracy: 0.0141\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5326 - accuracy: 0.0149 - val_loss: 7.0315 - val_accuracy: 0.0166\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5365 - accuracy: 0.0158 - val_loss: 7.7651 - val_accuracy: 0.0136\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5552 - accuracy: 0.0152 - val_loss: 7.8698 - val_accuracy: 0.0166\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 12s 39ms/step - loss: 9.4897 - accuracy: 0.0162 - val_loss: 1.7291 - val_accuracy: 0.0156\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 2.1310 - accuracy: 0.0153 - val_loss: 1.9781 - val_accuracy: 0.0156\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.8711 - accuracy: 0.0161 - val_loss: 1.8071 - val_accuracy: 0.0116\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 2.0593 - accuracy: 0.0161 - val_loss: 1.8836 - val_accuracy: 0.0141\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6945 - accuracy: 0.0171 - val_loss: 1.3176 - val_accuracy: 0.0161\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.7592 - accuracy: 0.0165 - val_loss: 3.0737 - val_accuracy: 0.0136\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.6794 - accuracy: 0.0151 - val_loss: 1.3361 - val_accuracy: 0.0131\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.7620 - accuracy: 0.0153 - val_loss: 1.2621 - val_accuracy: 0.0141\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.6066 - accuracy: 0.0152 - val_loss: 1.2423 - val_accuracy: 0.0151\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.6120 - accuracy: 0.0173 - val_loss: 1.3000 - val_accuracy: 0.0171\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6631 - accuracy: 0.0161 - val_loss: 1.2646 - val_accuracy: 0.0161\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5678 - accuracy: 0.0160 - val_loss: 1.3452 - val_accuracy: 0.0171\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.6442 - accuracy: 0.0131 - val_loss: 1.2618 - val_accuracy: 0.0161\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5844 - accuracy: 0.0152 - val_loss: 1.2716 - val_accuracy: 0.0161\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.6627 - accuracy: 0.0147 - val_loss: 1.3337 - val_accuracy: 0.0141\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5946 - accuracy: 0.0161 - val_loss: 1.2399 - val_accuracy: 0.0166\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5654 - accuracy: 0.0158 - val_loss: 1.2333 - val_accuracy: 0.0151\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5460 - accuracy: 0.0148 - val_loss: 1.2744 - val_accuracy: 0.0166\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5618 - accuracy: 0.0137 - val_loss: 1.2320 - val_accuracy: 0.0146\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5783 - accuracy: 0.0149 - val_loss: 1.3866 - val_accuracy: 0.0156\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5602 - accuracy: 0.0156 - val_loss: 1.2779 - val_accuracy: 0.0166\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5716 - accuracy: 0.0137 - val_loss: 1.2472 - val_accuracy: 0.0166\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.6033 - accuracy: 0.0163 - val_loss: 1.2336 - val_accuracy: 0.0166\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5420 - accuracy: 0.0156 - val_loss: 1.2947 - val_accuracy: 0.0146\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5437 - accuracy: 0.0160 - val_loss: 1.2917 - val_accuracy: 0.0161\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5540 - accuracy: 0.0143 - val_loss: 1.2472 - val_accuracy: 0.0156\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5358 - accuracy: 0.0131 - val_loss: 1.2402 - val_accuracy: 0.0166\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5752 - accuracy: 0.0153 - val_loss: 1.2730 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5333 - accuracy: 0.0158 - val_loss: 1.2578 - val_accuracy: 0.0161\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5430 - accuracy: 0.0151 - val_loss: 1.2645 - val_accuracy: 0.0156\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5313 - accuracy: 0.0165 - val_loss: 1.2338 - val_accuracy: 0.0176\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5368 - accuracy: 0.0132 - val_loss: 1.2368 - val_accuracy: 0.0176\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5782 - accuracy: 0.0142 - val_loss: 1.2707 - val_accuracy: 0.0156\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5336 - accuracy: 0.0165 - val_loss: 1.2957 - val_accuracy: 0.0141\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5354 - accuracy: 0.0149 - val_loss: 1.3328 - val_accuracy: 0.0141\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5180 - accuracy: 0.0177 - val_loss: 1.2349 - val_accuracy: 0.0156\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5214 - accuracy: 0.0136 - val_loss: 1.5106 - val_accuracy: 0.0186\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5212 - accuracy: 0.0161 - val_loss: 1.2835 - val_accuracy: 0.0176\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5590 - accuracy: 0.0138 - val_loss: 1.2250 - val_accuracy: 0.0141\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5110 - accuracy: 0.0163 - val_loss: 1.2537 - val_accuracy: 0.0161\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5225 - accuracy: 0.0161 - val_loss: 1.2444 - val_accuracy: 0.0161\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5213 - accuracy: 0.0155 - val_loss: 1.2368 - val_accuracy: 0.0156\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5145 - accuracy: 0.0170 - val_loss: 1.3199 - val_accuracy: 0.0181\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 9s 35ms/step - loss: 1.5195 - accuracy: 0.0155 - val_loss: 1.2252 - val_accuracy: 0.0161\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5486 - accuracy: 0.0173 - val_loss: 1.2684 - val_accuracy: 0.0176\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 9s 36ms/step - loss: 1.5114 - accuracy: 0.0187 - val_loss: 1.2940 - val_accuracy: 0.0201\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5660 - accuracy: 0.0178 - val_loss: 1.2784 - val_accuracy: 0.0141\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5288 - accuracy: 0.0132 - val_loss: 1.2528 - val_accuracy: 0.0146\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5066 - accuracy: 0.0155 - val_loss: 1.2309 - val_accuracy: 0.0161\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5210 - accuracy: 0.0167 - val_loss: 1.2360 - val_accuracy: 0.0146\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 13s 41ms/step - loss: 13.8946 - accuracy: 0.0144 - val_loss: 2.5828 - val_accuracy: 0.0166\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.9510 - accuracy: 0.0152 - val_loss: 1.3230 - val_accuracy: 0.0151\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.7412 - accuracy: 0.0172 - val_loss: 1.3161 - val_accuracy: 0.0171\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5940 - accuracy: 0.0147 - val_loss: 1.5426 - val_accuracy: 0.0186\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.6172 - accuracy: 0.0183 - val_loss: 1.3188 - val_accuracy: 0.0156\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.6360 - accuracy: 0.0147 - val_loss: 1.3065 - val_accuracy: 0.0136\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5796 - accuracy: 0.0136 - val_loss: 1.3122 - val_accuracy: 0.0146\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5593 - accuracy: 0.0166 - val_loss: 1.2219 - val_accuracy: 0.0141\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5652 - accuracy: 0.0168 - val_loss: 1.2170 - val_accuracy: 0.0161\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5780 - accuracy: 0.0146 - val_loss: 1.2344 - val_accuracy: 0.0146\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5625 - accuracy: 0.0171 - val_loss: 1.2277 - val_accuracy: 0.0146\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5575 - accuracy: 0.0185 - val_loss: 1.3497 - val_accuracy: 0.0136\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5370 - accuracy: 0.0215 - val_loss: 1.2203 - val_accuracy: 0.0181\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5710 - accuracy: 0.0182 - val_loss: 1.5939 - val_accuracy: 0.0171\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5328 - accuracy: 0.0152 - val_loss: 1.2307 - val_accuracy: 0.0181\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5676 - accuracy: 0.0138 - val_loss: 1.2778 - val_accuracy: 0.0141\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5287 - accuracy: 0.0132 - val_loss: 1.2881 - val_accuracy: 0.0156\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5752 - accuracy: 0.0157 - val_loss: 1.2184 - val_accuracy: 0.0136\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5374 - accuracy: 0.0185 - val_loss: 1.2178 - val_accuracy: 0.0136\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5347 - accuracy: 0.0166 - val_loss: 1.2219 - val_accuracy: 0.0166\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 2.3640 - accuracy: 0.0160 - val_loss: 1.2770 - val_accuracy: 0.0171\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5519 - accuracy: 0.0139 - val_loss: 1.2561 - val_accuracy: 0.0161\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5265 - accuracy: 0.0147 - val_loss: 1.3524 - val_accuracy: 0.0161\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5231 - accuracy: 0.0136 - val_loss: 1.3437 - val_accuracy: 0.0166\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5201 - accuracy: 0.0180 - val_loss: 1.2643 - val_accuracy: 0.0156\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5230 - accuracy: 0.0180 - val_loss: 1.6453 - val_accuracy: 0.0136\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5303 - accuracy: 0.0148 - val_loss: 1.3807 - val_accuracy: 0.0181\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5264 - accuracy: 0.0158 - val_loss: 1.2501 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5186 - accuracy: 0.0168 - val_loss: 1.2314 - val_accuracy: 0.0166\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5236 - accuracy: 0.0148 - val_loss: 1.2601 - val_accuracy: 0.0156\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5279 - accuracy: 0.0166 - val_loss: 1.2407 - val_accuracy: 0.0161\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5137 - accuracy: 0.0134 - val_loss: 1.2293 - val_accuracy: 0.0166\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5196 - accuracy: 0.0172 - val_loss: 1.2692 - val_accuracy: 0.0156\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5300 - accuracy: 0.0148 - val_loss: 1.2135 - val_accuracy: 0.0136\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5299 - accuracy: 0.0176 - val_loss: 1.3443 - val_accuracy: 0.0166\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5164 - accuracy: 0.0156 - val_loss: 1.2632 - val_accuracy: 0.0156\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5078 - accuracy: 0.0176 - val_loss: 1.2597 - val_accuracy: 0.0181\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5083 - accuracy: 0.0156 - val_loss: 1.3513 - val_accuracy: 0.0136\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5143 - accuracy: 0.0172 - val_loss: 1.2157 - val_accuracy: 0.0161\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5478 - accuracy: 0.0185 - val_loss: 1.2602 - val_accuracy: 0.0176\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5389 - accuracy: 0.0186 - val_loss: 1.2228 - val_accuracy: 0.0146\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 10s 38ms/step - loss: 1.5304 - accuracy: 0.0175 - val_loss: 1.2778 - val_accuracy: 0.0181\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.4976 - accuracy: 0.0176 - val_loss: 1.2167 - val_accuracy: 0.0166\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5031 - accuracy: 0.0175 - val_loss: 1.2321 - val_accuracy: 0.0166\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.5138 - accuracy: 0.0187 - val_loss: 1.2250 - val_accuracy: 0.0181\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5256 - accuracy: 0.0197 - val_loss: 1.2243 - val_accuracy: 0.0191\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.4971 - accuracy: 0.0173 - val_loss: 1.2805 - val_accuracy: 0.0151\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 9s 37ms/step - loss: 1.5161 - accuracy: 0.0200 - val_loss: 1.2242 - val_accuracy: 0.0181\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.4868 - accuracy: 0.0171 - val_loss: 1.2122 - val_accuracy: 0.0166\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 9s 38ms/step - loss: 1.4943 - accuracy: 0.0205 - val_loss: 1.2191 - val_accuracy: 0.0176\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 13s 39ms/step - loss: 9.3158 - accuracy: 0.0178 - val_loss: 2.4656 - val_accuracy: 0.0156\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.9729 - accuracy: 0.0158 - val_loss: 1.5719 - val_accuracy: 0.0151\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.7617 - accuracy: 0.0147 - val_loss: 1.3970 - val_accuracy: 0.0161\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.7087 - accuracy: 0.0171 - val_loss: 1.7828 - val_accuracy: 0.0141\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.6475 - accuracy: 0.0166 - val_loss: 1.4057 - val_accuracy: 0.0136\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.7138 - accuracy: 0.0158 - val_loss: 1.4731 - val_accuracy: 0.0146\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6634 - accuracy: 0.0153 - val_loss: 1.2438 - val_accuracy: 0.0196\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.6195 - accuracy: 0.0146 - val_loss: 1.3353 - val_accuracy: 0.0151\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.6633 - accuracy: 0.0145 - val_loss: 1.2387 - val_accuracy: 0.0161\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.6058 - accuracy: 0.0162 - val_loss: 1.9639 - val_accuracy: 0.0156\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.6339 - accuracy: 0.0148 - val_loss: 1.7098 - val_accuracy: 0.0141\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5735 - accuracy: 0.0150 - val_loss: 1.3097 - val_accuracy: 0.0186\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5898 - accuracy: 0.0148 - val_loss: 1.2567 - val_accuracy: 0.0151\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5715 - accuracy: 0.0180 - val_loss: 1.3511 - val_accuracy: 0.0156\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5614 - accuracy: 0.0166 - val_loss: 1.2295 - val_accuracy: 0.0151\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5650 - accuracy: 0.0155 - val_loss: 1.2443 - val_accuracy: 0.0146\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5618 - accuracy: 0.0157 - val_loss: 1.3159 - val_accuracy: 0.0161\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5467 - accuracy: 0.0176 - val_loss: 1.3056 - val_accuracy: 0.0141\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5657 - accuracy: 0.0150 - val_loss: 1.4378 - val_accuracy: 0.0161\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5539 - accuracy: 0.0172 - val_loss: 1.2813 - val_accuracy: 0.0166\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5382 - accuracy: 0.0152 - val_loss: 1.2482 - val_accuracy: 0.0181\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5466 - accuracy: 0.0151 - val_loss: 1.2405 - val_accuracy: 0.0156\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5469 - accuracy: 0.0180 - val_loss: 1.3375 - val_accuracy: 0.0196\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5346 - accuracy: 0.0188 - val_loss: 1.2722 - val_accuracy: 0.0156\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5333 - accuracy: 0.0148 - val_loss: 1.3859 - val_accuracy: 0.0166\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5418 - accuracy: 0.0161 - val_loss: 1.2286 - val_accuracy: 0.0171\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5447 - accuracy: 0.0162 - val_loss: 1.2589 - val_accuracy: 0.0171\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.6618 - accuracy: 0.0158 - val_loss: 1.4286 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5495 - accuracy: 0.0153 - val_loss: 1.2610 - val_accuracy: 0.0156\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5826 - accuracy: 0.0151 - val_loss: 1.2343 - val_accuracy: 0.0126\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5554 - accuracy: 0.0136 - val_loss: 1.2408 - val_accuracy: 0.0151\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5184 - accuracy: 0.0156 - val_loss: 1.2142 - val_accuracy: 0.0151\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5280 - accuracy: 0.0151 - val_loss: 1.2520 - val_accuracy: 0.0156\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5325 - accuracy: 0.0172 - val_loss: 1.4079 - val_accuracy: 0.0146\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5343 - accuracy: 0.0155 - val_loss: 1.2456 - val_accuracy: 0.0146\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5313 - accuracy: 0.0155 - val_loss: 1.3276 - val_accuracy: 0.0156\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5240 - accuracy: 0.0142 - val_loss: 1.2350 - val_accuracy: 0.0166\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5259 - accuracy: 0.0161 - val_loss: 1.2565 - val_accuracy: 0.0161\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5186 - accuracy: 0.0170 - val_loss: 1.2598 - val_accuracy: 0.0136\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5260 - accuracy: 0.0143 - val_loss: 1.2243 - val_accuracy: 0.0166\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5193 - accuracy: 0.0131 - val_loss: 1.3662 - val_accuracy: 0.0146\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5172 - accuracy: 0.0139 - val_loss: 1.2468 - val_accuracy: 0.0136\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5351 - accuracy: 0.0134 - val_loss: 1.2996 - val_accuracy: 0.0181\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5383 - accuracy: 0.0146 - val_loss: 1.2362 - val_accuracy: 0.0166\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.5165 - accuracy: 0.0134 - val_loss: 1.2555 - val_accuracy: 0.0146\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5266 - accuracy: 0.0131 - val_loss: 1.2512 - val_accuracy: 0.0161\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5063 - accuracy: 0.0171 - val_loss: 1.3729 - val_accuracy: 0.0161\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5147 - accuracy: 0.0139 - val_loss: 1.2508 - val_accuracy: 0.0176\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5039 - accuracy: 0.0166 - val_loss: 1.2278 - val_accuracy: 0.0156\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5005 - accuracy: 0.0146 - val_loss: 1.2232 - val_accuracy: 0.0171\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 13s 44ms/step - loss: 151.5004 - accuracy: 0.0156 - val_loss: 5.8717 - val_accuracy: 0.0136\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.9417 - accuracy: 0.0158 - val_loss: 2.4245 - val_accuracy: 0.0176\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.8947 - accuracy: 0.0175 - val_loss: 1.7998 - val_accuracy: 0.0156\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.7586 - accuracy: 0.0163 - val_loss: 1.5137 - val_accuracy: 0.0151\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.7579 - accuracy: 0.0121 - val_loss: 1.4340 - val_accuracy: 0.0151\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.7124 - accuracy: 0.0165 - val_loss: 1.2805 - val_accuracy: 0.0156\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.6238 - accuracy: 0.0173 - val_loss: 1.2893 - val_accuracy: 0.0161\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.6771 - accuracy: 0.0167 - val_loss: 1.2747 - val_accuracy: 0.0176\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.6956 - accuracy: 0.0147 - val_loss: 1.2706 - val_accuracy: 0.0151\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5861 - accuracy: 0.0152 - val_loss: 1.4454 - val_accuracy: 0.0156\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6407 - accuracy: 0.0136 - val_loss: 1.2342 - val_accuracy: 0.0141\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 10s 39ms/step - loss: 1.6588 - accuracy: 0.0181 - val_loss: 1.3329 - val_accuracy: 0.0156\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.6174 - accuracy: 0.0145 - val_loss: 1.4771 - val_accuracy: 0.0131\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.6661 - accuracy: 0.0153 - val_loss: 1.2386 - val_accuracy: 0.0141\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5911 - accuracy: 0.0171 - val_loss: 1.2659 - val_accuracy: 0.0166\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5987 - accuracy: 0.0163 - val_loss: 1.5333 - val_accuracy: 0.0141\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5949 - accuracy: 0.0139 - val_loss: 1.6868 - val_accuracy: 0.0141\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.6035 - accuracy: 0.0152 - val_loss: 1.2339 - val_accuracy: 0.0141\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5897 - accuracy: 0.0181 - val_loss: 1.2716 - val_accuracy: 0.0156\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5574 - accuracy: 0.0153 - val_loss: 1.3998 - val_accuracy: 0.0161\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5828 - accuracy: 0.0181 - val_loss: 1.2930 - val_accuracy: 0.0151\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5638 - accuracy: 0.0161 - val_loss: 1.2434 - val_accuracy: 0.0136\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5732 - accuracy: 0.0162 - val_loss: 1.2311 - val_accuracy: 0.0136\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5667 - accuracy: 0.0150 - val_loss: 1.3386 - val_accuracy: 0.0136\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5803 - accuracy: 0.0156 - val_loss: 1.2369 - val_accuracy: 0.0156\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5788 - accuracy: 0.0156 - val_loss: 1.2590 - val_accuracy: 0.0141\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5420 - accuracy: 0.0170 - val_loss: 1.2682 - val_accuracy: 0.0146\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5445 - accuracy: 0.0152 - val_loss: 1.2451 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5414 - accuracy: 0.0146 - val_loss: 1.2403 - val_accuracy: 0.0176\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5481 - accuracy: 0.0151 - val_loss: 1.2308 - val_accuracy: 0.0161\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.5413 - accuracy: 0.0157 - val_loss: 1.2542 - val_accuracy: 0.0186\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5600 - accuracy: 0.0170 - val_loss: 1.6085 - val_accuracy: 0.0141\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5452 - accuracy: 0.0171 - val_loss: 1.2636 - val_accuracy: 0.0146\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5631 - accuracy: 0.0152 - val_loss: 1.3079 - val_accuracy: 0.0141\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5338 - accuracy: 0.0137 - val_loss: 1.3323 - val_accuracy: 0.0166\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5347 - accuracy: 0.0160 - val_loss: 1.2542 - val_accuracy: 0.0171\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5218 - accuracy: 0.0170 - val_loss: 1.2255 - val_accuracy: 0.0126\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5234 - accuracy: 0.0167 - val_loss: 1.2436 - val_accuracy: 0.0166\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5220 - accuracy: 0.0170 - val_loss: 1.2407 - val_accuracy: 0.0186\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5336 - accuracy: 0.0151 - val_loss: 1.2455 - val_accuracy: 0.0196\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5374 - accuracy: 0.0165 - val_loss: 1.2544 - val_accuracy: 0.0156\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 10s 40ms/step - loss: 1.5402 - accuracy: 0.0170 - val_loss: 1.2238 - val_accuracy: 0.0201\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5362 - accuracy: 0.0172 - val_loss: 1.3019 - val_accuracy: 0.0186\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5215 - accuracy: 0.0176 - val_loss: 1.2604 - val_accuracy: 0.0161\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5289 - accuracy: 0.0161 - val_loss: 1.2207 - val_accuracy: 0.0181\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5190 - accuracy: 0.0161 - val_loss: 1.2710 - val_accuracy: 0.0151\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5085 - accuracy: 0.0182 - val_loss: 1.4322 - val_accuracy: 0.0161\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5450 - accuracy: 0.0176 - val_loss: 1.3354 - val_accuracy: 0.0156\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5181 - accuracy: 0.0180 - val_loss: 1.2404 - val_accuracy: 0.0191\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5090 - accuracy: 0.0176 - val_loss: 1.3412 - val_accuracy: 0.0151\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 15s 47ms/step - loss: 11.2341 - accuracy: 0.0147 - val_loss: 2.9490 - val_accuracy: 0.0151\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.7917 - accuracy: 0.0147 - val_loss: 1.4882 - val_accuracy: 0.0171\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.7078 - accuracy: 0.0151 - val_loss: 1.3135 - val_accuracy: 0.0161\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.7090 - accuracy: 0.0171 - val_loss: 1.5960 - val_accuracy: 0.0141\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.7593 - accuracy: 0.0140 - val_loss: 1.8243 - val_accuracy: 0.0166\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.6868 - accuracy: 0.0160 - val_loss: 1.3811 - val_accuracy: 0.0161\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.6775 - accuracy: 0.0153 - val_loss: 1.3040 - val_accuracy: 0.0156\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.6675 - accuracy: 0.0134 - val_loss: 1.5337 - val_accuracy: 0.0146\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.6157 - accuracy: 0.0165 - val_loss: 1.4814 - val_accuracy: 0.0151\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6069 - accuracy: 0.0151 - val_loss: 1.2582 - val_accuracy: 0.0186\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.6114 - accuracy: 0.0161 - val_loss: 1.3318 - val_accuracy: 0.0156\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6215 - accuracy: 0.0151 - val_loss: 1.2921 - val_accuracy: 0.0171\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5984 - accuracy: 0.0166 - val_loss: 1.3092 - val_accuracy: 0.0161\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5878 - accuracy: 0.0138 - val_loss: 1.3283 - val_accuracy: 0.0156\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6326 - accuracy: 0.0147 - val_loss: 1.3595 - val_accuracy: 0.0166\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5891 - accuracy: 0.0140 - val_loss: 1.2882 - val_accuracy: 0.0166\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.6096 - accuracy: 0.0163 - val_loss: 1.2617 - val_accuracy: 0.0161\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5995 - accuracy: 0.0157 - val_loss: 1.3306 - val_accuracy: 0.0161\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.6033 - accuracy: 0.0129 - val_loss: 1.3397 - val_accuracy: 0.0136\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5788 - accuracy: 0.0172 - val_loss: 1.2810 - val_accuracy: 0.0141\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.5784 - accuracy: 0.0148 - val_loss: 1.3200 - val_accuracy: 0.0166\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5617 - accuracy: 0.0155 - val_loss: 1.2462 - val_accuracy: 0.0136\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5781 - accuracy: 0.0155 - val_loss: 1.2802 - val_accuracy: 0.0171\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5582 - accuracy: 0.0161 - val_loss: 1.2756 - val_accuracy: 0.0176\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5715 - accuracy: 0.0152 - val_loss: 1.2477 - val_accuracy: 0.0176\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5553 - accuracy: 0.0148 - val_loss: 1.3032 - val_accuracy: 0.0161\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5633 - accuracy: 0.0146 - val_loss: 1.6177 - val_accuracy: 0.0141\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5632 - accuracy: 0.0123 - val_loss: 1.2481 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5662 - accuracy: 0.0165 - val_loss: 1.2665 - val_accuracy: 0.0156\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5616 - accuracy: 0.0140 - val_loss: 1.3991 - val_accuracy: 0.0161\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5589 - accuracy: 0.0157 - val_loss: 1.2784 - val_accuracy: 0.0161\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5451 - accuracy: 0.0156 - val_loss: 1.3453 - val_accuracy: 0.0176\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 2.6282 - accuracy: 0.0162 - val_loss: 1.7814 - val_accuracy: 0.0151\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6683 - accuracy: 0.0155 - val_loss: 1.2503 - val_accuracy: 0.0136\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5937 - accuracy: 0.0165 - val_loss: 1.2454 - val_accuracy: 0.0141\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5668 - accuracy: 0.0155 - val_loss: 1.3655 - val_accuracy: 0.0151\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5657 - accuracy: 0.0166 - val_loss: 1.2440 - val_accuracy: 0.0151\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 10s 41ms/step - loss: 1.5623 - accuracy: 0.0163 - val_loss: 1.2903 - val_accuracy: 0.0141\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5496 - accuracy: 0.0127 - val_loss: 1.2798 - val_accuracy: 0.0166\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5632 - accuracy: 0.0162 - val_loss: 1.2765 - val_accuracy: 0.0166\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 1.5113 - accuracy: 0.0146 - val_loss: 1.2400 - val_accuracy: 0.0156\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5333 - accuracy: 0.0166 - val_loss: 1.2460 - val_accuracy: 0.0151\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5223 - accuracy: 0.0146 - val_loss: 1.3222 - val_accuracy: 0.0136\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5451 - accuracy: 0.0194 - val_loss: 1.2624 - val_accuracy: 0.0166\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.5284 - accuracy: 0.0162 - val_loss: 1.2391 - val_accuracy: 0.0161\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5188 - accuracy: 0.0150 - val_loss: 1.2662 - val_accuracy: 0.0166\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5189 - accuracy: 0.0145 - val_loss: 1.3293 - val_accuracy: 0.0166\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5303 - accuracy: 0.0166 - val_loss: 1.2773 - val_accuracy: 0.0156\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5174 - accuracy: 0.0133 - val_loss: 1.2180 - val_accuracy: 0.0166\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5230 - accuracy: 0.0167 - val_loss: 1.3115 - val_accuracy: 0.0136\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 13s 44ms/step - loss: 39.3548 - accuracy: 0.0156 - val_loss: 16.4467 - val_accuracy: 0.0136\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 11.1776 - accuracy: 0.0165 - val_loss: 9.7106 - val_accuracy: 0.0166\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 155.0783 - accuracy: 0.0170 - val_loss: 2.7865 - val_accuracy: 0.0171\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 3.3187 - accuracy: 0.0160 - val_loss: 1.8588 - val_accuracy: 0.0176\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 2.3399 - accuracy: 0.0163 - val_loss: 1.4902 - val_accuracy: 0.0141\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 2.0232 - accuracy: 0.0165 - val_loss: 1.6088 - val_accuracy: 0.0141\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.9882 - accuracy: 0.0141 - val_loss: 1.5537 - val_accuracy: 0.0136\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.8439 - accuracy: 0.0156 - val_loss: 1.6636 - val_accuracy: 0.0161\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.7717 - accuracy: 0.0161 - val_loss: 1.5441 - val_accuracy: 0.0136\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.7806 - accuracy: 0.0173 - val_loss: 1.7397 - val_accuracy: 0.0131\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.7221 - accuracy: 0.0172 - val_loss: 1.3489 - val_accuracy: 0.0136\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.7193 - accuracy: 0.0162 - val_loss: 1.3845 - val_accuracy: 0.0166\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6756 - accuracy: 0.0158 - val_loss: 1.3234 - val_accuracy: 0.0156\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6600 - accuracy: 0.0145 - val_loss: 1.4584 - val_accuracy: 0.0141\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.6371 - accuracy: 0.0176 - val_loss: 1.4031 - val_accuracy: 0.0161\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6442 - accuracy: 0.0128 - val_loss: 1.3952 - val_accuracy: 0.0151\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6336 - accuracy: 0.0158 - val_loss: 1.3625 - val_accuracy: 0.0156\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6391 - accuracy: 0.0147 - val_loss: 1.2976 - val_accuracy: 0.0176\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6328 - accuracy: 0.0162 - val_loss: 1.2826 - val_accuracy: 0.0171\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5946 - accuracy: 0.0168 - val_loss: 1.2890 - val_accuracy: 0.0136\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6072 - accuracy: 0.0184 - val_loss: 1.3802 - val_accuracy: 0.0141\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.6187 - accuracy: 0.0189 - val_loss: 1.5340 - val_accuracy: 0.0156\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6017 - accuracy: 0.0138 - val_loss: 1.2863 - val_accuracy: 0.0141\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.6167 - accuracy: 0.0156 - val_loss: 1.4972 - val_accuracy: 0.0176\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5830 - accuracy: 0.0156 - val_loss: 1.3056 - val_accuracy: 0.0161\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5756 - accuracy: 0.0137 - val_loss: 1.2756 - val_accuracy: 0.0166\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6546 - accuracy: 0.0151 - val_loss: 1.2474 - val_accuracy: 0.0156\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6090 - accuracy: 0.0181 - val_loss: 1.2653 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5704 - accuracy: 0.0157 - val_loss: 1.2525 - val_accuracy: 0.0141\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6853 - accuracy: 0.0170 - val_loss: 1.3407 - val_accuracy: 0.0176\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 10s 42ms/step - loss: 1.6195 - accuracy: 0.0166 - val_loss: 1.2398 - val_accuracy: 0.0131\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6052 - accuracy: 0.0157 - val_loss: 1.5456 - val_accuracy: 0.0166\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5801 - accuracy: 0.0161 - val_loss: 1.2601 - val_accuracy: 0.0166\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5802 - accuracy: 0.0153 - val_loss: 1.3801 - val_accuracy: 0.0151\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5819 - accuracy: 0.0124 - val_loss: 1.4854 - val_accuracy: 0.0166\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.6379 - accuracy: 0.0176 - val_loss: 1.2610 - val_accuracy: 0.0141\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5890 - accuracy: 0.0160 - val_loss: 1.3390 - val_accuracy: 0.0141\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.6024 - accuracy: 0.0162 - val_loss: 1.5284 - val_accuracy: 0.0176\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 11s 42ms/step - loss: 1.5800 - accuracy: 0.0160 - val_loss: 1.2703 - val_accuracy: 0.0146\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5855 - accuracy: 0.0153 - val_loss: 1.2504 - val_accuracy: 0.0141\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.6605 - accuracy: 0.0163 - val_loss: 1.3638 - val_accuracy: 0.0171\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6238 - accuracy: 0.0162 - val_loss: 1.2523 - val_accuracy: 0.0136\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5855 - accuracy: 0.0181 - val_loss: 1.3547 - val_accuracy: 0.0141\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5483 - accuracy: 0.0160 - val_loss: 1.3303 - val_accuracy: 0.0151\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.6804 - accuracy: 0.0156 - val_loss: 1.2425 - val_accuracy: 0.0176\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5608 - accuracy: 0.0162 - val_loss: 1.2564 - val_accuracy: 0.0151\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5362 - accuracy: 0.0155 - val_loss: 1.2981 - val_accuracy: 0.0161\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5638 - accuracy: 0.0165 - val_loss: 1.2461 - val_accuracy: 0.0141\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5537 - accuracy: 0.0148 - val_loss: 1.2606 - val_accuracy: 0.0166\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5567 - accuracy: 0.0173 - val_loss: 1.2718 - val_accuracy: 0.0156\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 15s 48ms/step - loss: 202.4981 - accuracy: 0.0145 - val_loss: 4.8782 - val_accuracy: 0.0171\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 4.3990 - accuracy: 0.0150 - val_loss: 3.5604 - val_accuracy: 0.0151\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 3.8954 - accuracy: 0.0145 - val_loss: 2.0634 - val_accuracy: 0.0171\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 2.8955 - accuracy: 0.0172 - val_loss: 2.6921 - val_accuracy: 0.0181\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 3.5468 - accuracy: 0.0163 - val_loss: 1.8927 - val_accuracy: 0.0141\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.9035 - accuracy: 0.0145 - val_loss: 1.3291 - val_accuracy: 0.0171\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.8281 - accuracy: 0.0157 - val_loss: 1.3544 - val_accuracy: 0.0156\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.6758 - accuracy: 0.0133 - val_loss: 1.3190 - val_accuracy: 0.0191\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.6606 - accuracy: 0.0167 - val_loss: 1.4374 - val_accuracy: 0.0146\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.7757 - accuracy: 0.0171 - val_loss: 1.2805 - val_accuracy: 0.0141\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6418 - accuracy: 0.0170 - val_loss: 1.5252 - val_accuracy: 0.0166\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.6547 - accuracy: 0.0173 - val_loss: 1.2697 - val_accuracy: 0.0166\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6225 - accuracy: 0.0165 - val_loss: 1.5358 - val_accuracy: 0.0161\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.6091 - accuracy: 0.0142 - val_loss: 1.2481 - val_accuracy: 0.0161\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5965 - accuracy: 0.0150 - val_loss: 1.2848 - val_accuracy: 0.0146\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.6249 - accuracy: 0.0165 - val_loss: 1.2606 - val_accuracy: 0.0181\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6140 - accuracy: 0.0143 - val_loss: 1.2946 - val_accuracy: 0.0141\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.6482 - accuracy: 0.0179 - val_loss: 1.2817 - val_accuracy: 0.0156\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 1.5975 - accuracy: 0.0136 - val_loss: 1.2521 - val_accuracy: 0.0156\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5970 - accuracy: 0.0145 - val_loss: 1.2387 - val_accuracy: 0.0161\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.6335 - accuracy: 0.0175 - val_loss: 1.9060 - val_accuracy: 0.0151\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.5744 - accuracy: 0.0153 - val_loss: 1.2464 - val_accuracy: 0.0156\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5427 - accuracy: 0.0158 - val_loss: 1.2737 - val_accuracy: 0.0141\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.5865 - accuracy: 0.0155 - val_loss: 1.2235 - val_accuracy: 0.0141\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5628 - accuracy: 0.0150 - val_loss: 1.3104 - val_accuracy: 0.0156\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5931 - accuracy: 0.0151 - val_loss: 1.2322 - val_accuracy: 0.0161\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5698 - accuracy: 0.0153 - val_loss: 1.3096 - val_accuracy: 0.0156\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5902 - accuracy: 0.0137 - val_loss: 1.2459 - val_accuracy: 0.0176\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5807 - accuracy: 0.0153 - val_loss: 1.6068 - val_accuracy: 0.0161\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.5850 - accuracy: 0.0146 - val_loss: 1.3731 - val_accuracy: 0.0176\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5725 - accuracy: 0.0153 - val_loss: 1.2325 - val_accuracy: 0.0136\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.5555 - accuracy: 0.0137 - val_loss: 1.2245 - val_accuracy: 0.0161\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5938 - accuracy: 0.0153 - val_loss: 1.2486 - val_accuracy: 0.0136\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5554 - accuracy: 0.0179 - val_loss: 1.2491 - val_accuracy: 0.0161\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.5654 - accuracy: 0.0161 - val_loss: 1.3401 - val_accuracy: 0.0161\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5441 - accuracy: 0.0126 - val_loss: 1.2189 - val_accuracy: 0.0151\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5496 - accuracy: 0.0160 - val_loss: 1.2623 - val_accuracy: 0.0136\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5756 - accuracy: 0.0141 - val_loss: 1.2478 - val_accuracy: 0.0141\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5563 - accuracy: 0.0145 - val_loss: 1.3806 - val_accuracy: 0.0151\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5436 - accuracy: 0.0151 - val_loss: 1.3076 - val_accuracy: 0.0176\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5412 - accuracy: 0.0156 - val_loss: 1.2246 - val_accuracy: 0.0156\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5343 - accuracy: 0.0175 - val_loss: 1.2261 - val_accuracy: 0.0171\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5269 - accuracy: 0.0156 - val_loss: 1.2427 - val_accuracy: 0.0161\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5371 - accuracy: 0.0161 - val_loss: 1.2261 - val_accuracy: 0.0166\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 11s 43ms/step - loss: 1.5284 - accuracy: 0.0140 - val_loss: 1.2307 - val_accuracy: 0.0151\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5367 - accuracy: 0.0165 - val_loss: 1.2518 - val_accuracy: 0.0136\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5390 - accuracy: 0.0140 - val_loss: 1.3210 - val_accuracy: 0.0136\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5715 - accuracy: 0.0150 - val_loss: 1.2273 - val_accuracy: 0.0166\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 1.5284 - accuracy: 0.0173 - val_loss: 1.2978 - val_accuracy: 0.0146\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 11s 44ms/step - loss: 1.5126 - accuracy: 0.0147 - val_loss: 1.3389 - val_accuracy: 0.0146\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 14s 49ms/step - loss: 1468.3668 - accuracy: 0.0151 - val_loss: 47.0422 - val_accuracy: 0.0151\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 12.5494 - accuracy: 0.0152 - val_loss: 5.0430 - val_accuracy: 0.0151\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 5.4809 - accuracy: 0.0171 - val_loss: 3.6664 - val_accuracy: 0.0146\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 3.3892 - accuracy: 0.0145 - val_loss: 2.4729 - val_accuracy: 0.0156\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 2.8049 - accuracy: 0.0177 - val_loss: 2.4540 - val_accuracy: 0.0151\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 2.5668 - accuracy: 0.0167 - val_loss: 2.5901 - val_accuracy: 0.0156\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 2.5275 - accuracy: 0.0147 - val_loss: 2.6220 - val_accuracy: 0.0161\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 2.1621 - accuracy: 0.0129 - val_loss: 1.8090 - val_accuracy: 0.0131\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.8600 - accuracy: 0.0140 - val_loss: 1.8397 - val_accuracy: 0.0131\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.7855 - accuracy: 0.0136 - val_loss: 1.4770 - val_accuracy: 0.0126\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.6824 - accuracy: 0.0143 - val_loss: 1.4193 - val_accuracy: 0.0136\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.6664 - accuracy: 0.0152 - val_loss: 1.2890 - val_accuracy: 0.0181\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.6152 - accuracy: 0.0168 - val_loss: 1.3254 - val_accuracy: 0.0161\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 13s 50ms/step - loss: 1.6409 - accuracy: 0.0124 - val_loss: 1.3417 - val_accuracy: 0.0136\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.6118 - accuracy: 0.0143 - val_loss: 1.2689 - val_accuracy: 0.0156\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.6005 - accuracy: 0.0147 - val_loss: 1.2880 - val_accuracy: 0.0176\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.6495 - accuracy: 0.0147 - val_loss: 1.3030 - val_accuracy: 0.0171\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.5921 - accuracy: 0.0153 - val_loss: 1.2613 - val_accuracy: 0.0171\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.5827 - accuracy: 0.0123 - val_loss: 1.2787 - val_accuracy: 0.0171\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.5972 - accuracy: 0.0146 - val_loss: 1.2982 - val_accuracy: 0.0131\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5850 - accuracy: 0.0157 - val_loss: 1.2579 - val_accuracy: 0.0161\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5778 - accuracy: 0.0142 - val_loss: 1.3785 - val_accuracy: 0.0146\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.5895 - accuracy: 0.0141 - val_loss: 1.3675 - val_accuracy: 0.0176\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 13s 50ms/step - loss: 1.5759 - accuracy: 0.0162 - val_loss: 1.2568 - val_accuracy: 0.0161\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.5877 - accuracy: 0.0140 - val_loss: 1.3097 - val_accuracy: 0.0161\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5557 - accuracy: 0.0158 - val_loss: 1.2459 - val_accuracy: 0.0151\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5665 - accuracy: 0.0140 - val_loss: 1.2655 - val_accuracy: 0.0146\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 13s 53ms/step - loss: 1.5527 - accuracy: 0.0180 - val_loss: 1.2450 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.5656 - accuracy: 0.0158 - val_loss: 1.2434 - val_accuracy: 0.0181\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5524 - accuracy: 0.0131 - val_loss: 1.2650 - val_accuracy: 0.0156\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 1.5542 - accuracy: 0.0145 - val_loss: 1.2343 - val_accuracy: 0.0156\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 11s 46ms/step - loss: 1.5523 - accuracy: 0.0137 - val_loss: 1.4355 - val_accuracy: 0.0166\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5291 - accuracy: 0.0145 - val_loss: 1.4121 - val_accuracy: 0.0211\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5585 - accuracy: 0.0133 - val_loss: 1.2304 - val_accuracy: 0.0176\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.5596 - accuracy: 0.0161 - val_loss: 1.2492 - val_accuracy: 0.0171\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 822.1941 - accuracy: 0.0127 - val_loss: 34.8757 - val_accuracy: 0.0146\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 13s 50ms/step - loss: 25566.8496 - accuracy: 0.0146 - val_loss: 8941.0098 - val_accuracy: 0.0151\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 7733.2222 - accuracy: 0.0156 - val_loss: 380.1134 - val_accuracy: 0.0126\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 13s 53ms/step - loss: 328.3943 - accuracy: 0.0145 - val_loss: 49.7197 - val_accuracy: 0.0141\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 140.3660 - accuracy: 0.0168 - val_loss: 33.8486 - val_accuracy: 0.0161\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 46.1158 - accuracy: 0.0160 - val_loss: 30.1751 - val_accuracy: 0.0181\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 97.5869 - accuracy: 0.0167 - val_loss: 34.1050 - val_accuracy: 0.0171\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 71.7381 - accuracy: 0.0153 - val_loss: 41.3978 - val_accuracy: 0.0191\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 56.3459 - accuracy: 0.0170 - val_loss: 28.7300 - val_accuracy: 0.0171\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 13s 50ms/step - loss: 44.0081 - accuracy: 0.0147 - val_loss: 26.3793 - val_accuracy: 0.0136\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 45.0158 - accuracy: 0.0155 - val_loss: 24.8116 - val_accuracy: 0.0151\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 39.1689 - accuracy: 0.0141 - val_loss: 23.4346 - val_accuracy: 0.0141\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 31.7970 - accuracy: 0.0135 - val_loss: 22.2557 - val_accuracy: 0.0176\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 29.2321 - accuracy: 0.0129 - val_loss: 18.4580 - val_accuracy: 0.0151\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 11s 45ms/step - loss: 24.7655 - accuracy: 0.0153 - val_loss: 16.7204 - val_accuracy: 0.0141\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 16s 53ms/step - loss: 59.9548 - accuracy: 0.0147 - val_loss: 5.2098 - val_accuracy: 0.0141\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.9149 - accuracy: 0.0158 - val_loss: 1.2894 - val_accuracy: 0.0136\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 13s 54ms/step - loss: 1.8844 - accuracy: 0.0152 - val_loss: 1.5468 - val_accuracy: 0.0146\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.6939 - accuracy: 0.0180 - val_loss: 1.3091 - val_accuracy: 0.0176\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.6184 - accuracy: 0.0174 - val_loss: 1.4028 - val_accuracy: 0.0136\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.6283 - accuracy: 0.0151 - val_loss: 1.5830 - val_accuracy: 0.0156\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.6098 - accuracy: 0.0184 - val_loss: 1.2914 - val_accuracy: 0.0181\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.6448 - accuracy: 0.0175 - val_loss: 1.3373 - val_accuracy: 0.0151\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 13s 53ms/step - loss: 1.6054 - accuracy: 0.0152 - val_loss: 1.5872 - val_accuracy: 0.0161\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 13s 53ms/step - loss: 1.5773 - accuracy: 0.0156 - val_loss: 1.2720 - val_accuracy: 0.0156\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.5987 - accuracy: 0.0163 - val_loss: 1.3738 - val_accuracy: 0.0156\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.5814 - accuracy: 0.0165 - val_loss: 1.3279 - val_accuracy: 0.0156\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5558 - accuracy: 0.0186 - val_loss: 1.2216 - val_accuracy: 0.0131\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.5454 - accuracy: 0.0146 - val_loss: 1.2396 - val_accuracy: 0.0186\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5372 - accuracy: 0.0147 - val_loss: 1.3058 - val_accuracy: 0.0136\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.5485 - accuracy: 0.0151 - val_loss: 1.2681 - val_accuracy: 0.0156\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5597 - accuracy: 0.0162 - val_loss: 1.2594 - val_accuracy: 0.0166\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.5326 - accuracy: 0.0158 - val_loss: 1.3087 - val_accuracy: 0.0131\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.5399 - accuracy: 0.0152 - val_loss: 1.2598 - val_accuracy: 0.0161\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 1.5417 - accuracy: 0.0167 - val_loss: 1.2336 - val_accuracy: 0.0181\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.5247 - accuracy: 0.0187 - val_loss: 1.2328 - val_accuracy: 0.0166\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5336 - accuracy: 0.0186 - val_loss: 1.2638 - val_accuracy: 0.0191\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5491 - accuracy: 0.0157 - val_loss: 1.2491 - val_accuracy: 0.0176\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5564 - accuracy: 0.0167 - val_loss: 1.3132 - val_accuracy: 0.0156\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.5818 - accuracy: 0.0170 - val_loss: 1.2298 - val_accuracy: 0.0146\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.5377 - accuracy: 0.0137 - val_loss: 1.2651 - val_accuracy: 0.0161\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5172 - accuracy: 0.0166 - val_loss: 1.2415 - val_accuracy: 0.0146\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.5312 - accuracy: 0.0185 - val_loss: 1.2296 - val_accuracy: 0.0161\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5451 - accuracy: 0.0157 - val_loss: 1.2781 - val_accuracy: 0.0186\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 1.5306 - accuracy: 0.0184 - val_loss: 1.2241 - val_accuracy: 0.0136\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 12s 46ms/step - loss: 1.5180 - accuracy: 0.0206 - val_loss: 1.2246 - val_accuracy: 0.0166\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.5205 - accuracy: 0.0160 - val_loss: 1.5007 - val_accuracy: 0.0146\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.5293 - accuracy: 0.0177 - val_loss: 1.2802 - val_accuracy: 0.0176\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.5196 - accuracy: 0.0158 - val_loss: 1.2645 - val_accuracy: 0.0156\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5069 - accuracy: 0.0181 - val_loss: 1.2308 - val_accuracy: 0.0156\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.5169 - accuracy: 0.0201 - val_loss: 1.2502 - val_accuracy: 0.0151\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.5106 - accuracy: 0.0175 - val_loss: 1.2546 - val_accuracy: 0.0161\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.5184 - accuracy: 0.0155 - val_loss: 1.2460 - val_accuracy: 0.0161\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.5063 - accuracy: 0.0192 - val_loss: 1.3054 - val_accuracy: 0.0211\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.5067 - accuracy: 0.0191 - val_loss: 1.2497 - val_accuracy: 0.0146\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.5096 - accuracy: 0.0209 - val_loss: 1.2416 - val_accuracy: 0.0186\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 13s 54ms/step - loss: 1.5044 - accuracy: 0.0221 - val_loss: 1.2439 - val_accuracy: 0.0171\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.4946 - accuracy: 0.0202 - val_loss: 1.3531 - val_accuracy: 0.0186\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5058 - accuracy: 0.0209 - val_loss: 1.2280 - val_accuracy: 0.0176\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.4989 - accuracy: 0.0201 - val_loss: 1.2188 - val_accuracy: 0.0166\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.4947 - accuracy: 0.0234 - val_loss: 1.2314 - val_accuracy: 0.0221\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.5015 - accuracy: 0.0204 - val_loss: 1.2181 - val_accuracy: 0.0191\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.4961 - accuracy: 0.0220 - val_loss: 1.2319 - val_accuracy: 0.0166\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.5725 - accuracy: 0.0189 - val_loss: 1.2954 - val_accuracy: 0.0181\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.5001 - accuracy: 0.0168 - val_loss: 1.2638 - val_accuracy: 0.0176\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "249/249 [==============================] - 16s 56ms/step - loss: 684.9036 - accuracy: 0.0155 - val_loss: 1.6723 - val_accuracy: 0.0156\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 14s 55ms/step - loss: 2.1915 - accuracy: 0.0163 - val_loss: 1.4190 - val_accuracy: 0.0126\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 13s 50ms/step - loss: 1.9708 - accuracy: 0.0145 - val_loss: 2.5982 - val_accuracy: 0.0156\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.8583 - accuracy: 0.0147 - val_loss: 1.3790 - val_accuracy: 0.0156\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.6600 - accuracy: 0.0162 - val_loss: 1.5542 - val_accuracy: 0.0206\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.6334 - accuracy: 0.0155 - val_loss: 1.3180 - val_accuracy: 0.0161\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.7623 - accuracy: 0.0145 - val_loss: 2.1647 - val_accuracy: 0.0176\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 12s 47ms/step - loss: 1.6820 - accuracy: 0.0152 - val_loss: 3.1012 - val_accuracy: 0.0161\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.7003 - accuracy: 0.0145 - val_loss: 1.2539 - val_accuracy: 0.0151\n",
      "Epoch 10/50\n",
      "249/249 [==============================] - 12s 48ms/step - loss: 1.6246 - accuracy: 0.0138 - val_loss: 1.6973 - val_accuracy: 0.0141\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 13s 50ms/step - loss: 1.7172 - accuracy: 0.0165 - val_loss: 1.2563 - val_accuracy: 0.0141\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.5859 - accuracy: 0.0152 - val_loss: 1.2481 - val_accuracy: 0.0161\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 12s 49ms/step - loss: 1.6090 - accuracy: 0.0166 - val_loss: 1.2503 - val_accuracy: 0.0131\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.5889 - accuracy: 0.0158 - val_loss: 1.2868 - val_accuracy: 0.0141\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 13s 52ms/step - loss: 1.6735 - accuracy: 0.0153 - val_loss: 1.3423 - val_accuracy: 0.0136\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 13s 54ms/step - loss: 1.6539 - accuracy: 0.0136 - val_loss: 1.3507 - val_accuracy: 0.0146\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 12s 50ms/step - loss: 1.5582 - accuracy: 0.0143 - val_loss: 1.2407 - val_accuracy: 0.0181\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 13s 54ms/step - loss: 1.9871 - accuracy: 0.0189 - val_loss: 1.6426 - val_accuracy: 0.0166\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 13s 51ms/step - loss: 1.5919 - accuracy: 0.0135 - val_loss: 1.2864 - val_accuracy: 0.0151\n",
      "Epoch 20/50\n",
      "193/249 [======================>.......] - ETA: 2s - loss: 1.5786 - accuracy: 0.0130"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-12cc8d84b880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mRnn_xtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRnn_ytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mRnn_xtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRnn_ytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mRnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRnn_xtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRnn_ytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mRnn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRnn_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRnn_xtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mRnn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRnn_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-6cbc5edd2a31>\u001b[0m in \u001b[0;36mLSTM_model\u001b[0;34m(input_X, input_Y, l, h, n_features)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nmaesdf = pd.DataFrame()\n",
    "for l in range(0, 65):\n",
    "    Rnn_xtrain, Rnn_ytrain = fetch_data(X_train, Y_train, 65, l+1)\n",
    "    Rnn_xtest, Rnn_ytest = fetch_data(X_test, Y_test, 65, l+1)\n",
    "    Rnn_model = LSTM_model(Rnn_xtrain, Rnn_ytrain, l+1, 65, 16)\n",
    "    Rnn_test = Rnn_reshape(Rnn_xtest, l+1, 16)\n",
    "    Rnn_pred = Rnn_model.predict(Rnn_test,verbose=0)\n",
    "    nmaes_l = nmaes_array(Rnn_ytest, Rnn_pred, 64)\n",
    "    nmaesdf['nmaes_l'+str(l)] = nmaes_l\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
